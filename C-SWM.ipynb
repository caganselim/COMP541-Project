{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C-SWM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libs\n",
    "import Base: iterate, length, GC\n",
    "using HDF5\n",
    "using Knet\n",
    "using Statistics: mean,std\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using Images\n",
    "using Plots\n",
    "\n",
    "#Datatype\n",
    "atype=KnetArray{Float32}\n",
    "\n",
    "#Includes\n",
    "include(\"datasets.jl\")\n",
    "include(\"cswm.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Params\n",
    "input_ch = 3\n",
    "hidden_dim = 512\n",
    "num_objects = 5\n",
    "embedding_dim = 2\n",
    "action_dim = 4\n",
    "sigma = 0.5\n",
    "hinge = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MersenneTwister(UInt32[0x0000002a], Random.DSFMT.DSFMT_state(Int32[964434469, 1073036706, 1860149520, 1073503458, 1687169063, 1073083486, -399267803, 1072983952, -909620556, 1072836235  …  -293054293, 1073002412, -1300127419, 1073642642, 1917177374, -666058738, -337596527, 1830741494, 382, 0]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], UInt128[0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000  …  0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000], 1002, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knet.seed!(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContrastiveSWM(EncoderCNNSmall(Any[P(KnetArray{Float32,4}(10,10,3,32)), P(KnetArray{Float32,4}(1,1,32,5))], Any[P(KnetArray{Float32,4}(1,1,32,1)), P(KnetArray{Float32,4}(1,1,5,1))], Any[Knet.BNMoments(0.1, nothing, nothing, zeros, ones), K32(64)[1.0⋯]], Knet.sigm, NNlib.relu), EncoderMLP(Param{KnetArray{Float32,2}}[P(KnetArray{Float32,2}(512,25)), P(KnetArray{Float32,2}(512,512)), P(KnetArray{Float32,2}(2,512))], Param{KnetArray{Float32,1}}[P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(2))], LayerNorm(P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), 1.0e-5), NNlib.relu), TransitionGNN(EdgeMLP(Param{KnetArray{Float32,2}}[P(KnetArray{Float32,2}(512,4)), P(KnetArray{Float32,2}(512,512)), P(KnetArray{Float32,2}(512,512))], Param{KnetArray{Float32,1}}[P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512))], LayerNorm(P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), 1.0e-5), NNlib.relu), NodeMLP(Param{KnetArray{Float32,2}}[P(KnetArray{Float32,2}(512,518)), P(KnetArray{Float32,2}(512,512)), P(KnetArray{Float32,2}(2,512))], Param{KnetArray{Float32,1}}[P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(2))], LayerNorm(P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), 1.0e-5), NNlib.relu), false, false, 4, 2, nothing, 0), 0.5, 1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = initContrastiveSWMSmall(input_ch, hidden_dim, num_objects, embedding_dim, action_dim, sigma, hinge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Building dataset indexing...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATASET_PATH = \"/home/cagan/dev/datasets/C-SWM/shapes_train.h5\"\n",
    "TRAIN_BATCH_SIZE = 1024\n",
    "dtrn = buildStateTransitionDataset(TRAIN_DATASET_PATH, true, TRAIN_BATCH_SIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(KnetArray{Float32,4}(10,10,3,32))\n",
      "P(KnetArray{Float32,4}(1,1,32,5))\n",
      "P(KnetArray{Float32,4}(1,1,32,1))\n",
      "P(KnetArray{Float32,4}(1,1,5,1))\n",
      "P(KnetArray{Float32,2}(512,25))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,2}(2,512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(2))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,2}(512,4))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,2}(512,518))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,2}(2,512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(2))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n"
     ]
    }
   ],
   "source": [
    "function initopt!(model::ContrastiveSWM)\n",
    "    \n",
    "    for par in params(model)\n",
    "        par.opt = Adam(;lr=0.005, gclip=0, beta1=0.9, beta2=0.999, eps=1e-8)\n",
    "        println(par)\n",
    "    end\n",
    "    end;\n",
    "initopt!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch: 1, Iter: 10240/100000, Loss: 1.2729872\n",
      "Epoch: 1, Iter: 20480/100000, Loss: 0.33176392\n",
      "Epoch: 1, Iter: 30720/100000, Loss: 0.21588787\n",
      "Epoch: 1, Iter: 40960/100000, Loss: 0.12814604\n",
      "Epoch: 1, Iter: 51200/100000, Loss: 0.11091716\n",
      "Epoch: 1, Iter: 61440/100000, Loss: 0.09546113\n",
      "Epoch: 1, Iter: 71680/100000, Loss: 0.09327096\n",
      "Epoch: 1, Iter: 81920/100000, Loss: 0.09457105\n",
      "Epoch: 1, Iter: 92160/100000, Loss: 0.0839488\n",
      "Avg loss: 1.4810186971708672\n",
      "Epoch: 2, Iter: 10240/100000, Loss: 0.08037728\n",
      "Epoch: 2, Iter: 20480/100000, Loss: 0.0748291\n",
      "Epoch: 2, Iter: 30720/100000, Loss: 0.075512275\n",
      "Epoch: 2, Iter: 40960/100000, Loss: 0.068265975\n",
      "Epoch: 2, Iter: 51200/100000, Loss: 0.06986205\n",
      "Epoch: 2, Iter: 61440/100000, Loss: 0.06875594\n",
      "Epoch: 2, Iter: 71680/100000, Loss: 0.069059744\n",
      "Epoch: 2, Iter: 81920/100000, Loss: 0.066677\n",
      "Epoch: 2, Iter: 92160/100000, Loss: 0.071466304\n",
      "Avg loss: 0.07233673165139463\n",
      "Epoch: 3, Iter: 10240/100000, Loss: 0.072230816\n",
      "Epoch: 3, Iter: 20480/100000, Loss: 0.06625329\n",
      "Epoch: 3, Iter: 30720/100000, Loss: 0.0681374\n",
      "Epoch: 3, Iter: 40960/100000, Loss: 0.06945694\n",
      "Epoch: 3, Iter: 51200/100000, Loss: 0.065998755\n",
      "Epoch: 3, Iter: 61440/100000, Loss: 0.059580214\n",
      "Epoch: 3, Iter: 71680/100000, Loss: 0.06486001\n",
      "Epoch: 3, Iter: 81920/100000, Loss: 0.06850259\n",
      "Epoch: 3, Iter: 92160/100000, Loss: 0.06139799\n",
      "Avg loss: 0.06623150001174395\n",
      "Epoch: 4, Iter: 10240/100000, Loss: 0.06351429\n",
      "Epoch: 4, Iter: 20480/100000, Loss: 0.06741783\n",
      "Epoch: 4, Iter: 30720/100000, Loss: 0.059738923\n",
      "Epoch: 4, Iter: 40960/100000, Loss: 0.065059155\n",
      "Epoch: 4, Iter: 51200/100000, Loss: 0.066977665\n",
      "Epoch: 4, Iter: 61440/100000, Loss: 0.06353493\n",
      "Epoch: 4, Iter: 71680/100000, Loss: 0.07085361\n",
      "Epoch: 4, Iter: 81920/100000, Loss: 0.0657325\n",
      "Epoch: 4, Iter: 92160/100000, Loss: 0.06301966\n",
      "Avg loss: 0.06590358098757636\n",
      "Epoch: 5, Iter: 10240/100000, Loss: 0.061113894\n",
      "Epoch: 5, Iter: 20480/100000, Loss: 0.0699395\n",
      "Epoch: 5, Iter: 30720/100000, Loss: 0.07313571\n",
      "Epoch: 5, Iter: 40960/100000, Loss: 0.067430675\n",
      "Epoch: 5, Iter: 51200/100000, Loss: 0.06708691\n",
      "Epoch: 5, Iter: 61440/100000, Loss: 0.06254344\n",
      "Epoch: 5, Iter: 71680/100000, Loss: 0.06271292\n",
      "Epoch: 5, Iter: 81920/100000, Loss: 0.065047145\n",
      "Epoch: 5, Iter: 92160/100000, Loss: 0.06061245\n",
      "Avg loss: 0.06517930670650963\n",
      "Epoch: 6, Iter: 10240/100000, Loss: 0.0638255\n",
      "Epoch: 6, Iter: 20480/100000, Loss: 0.066905126\n",
      "Epoch: 6, Iter: 30720/100000, Loss: 0.060539387\n",
      "Epoch: 6, Iter: 40960/100000, Loss: 0.071570784\n",
      "Epoch: 6, Iter: 51200/100000, Loss: 0.062227476\n",
      "Epoch: 6, Iter: 61440/100000, Loss: 0.06375713\n",
      "Epoch: 6, Iter: 71680/100000, Loss: 0.06579232\n",
      "Epoch: 6, Iter: 81920/100000, Loss: 0.06395985\n",
      "Epoch: 6, Iter: 92160/100000, Loss: 0.06209361\n",
      "Avg loss: 0.0646987400718571\n",
      "Epoch: 7, Iter: 10240/100000, Loss: 0.0630161\n",
      "Epoch: 7, Iter: 20480/100000, Loss: 0.06409595\n",
      "Epoch: 7, Iter: 30720/100000, Loss: 0.065404475\n",
      "Epoch: 7, Iter: 40960/100000, Loss: 0.06367177\n",
      "Epoch: 7, Iter: 51200/100000, Loss: 0.06418301\n",
      "Epoch: 7, Iter: 61440/100000, Loss: 0.06454869\n",
      "Epoch: 7, Iter: 71680/100000, Loss: 0.06296049\n",
      "Epoch: 7, Iter: 81920/100000, Loss: 0.06888646\n",
      "Epoch: 7, Iter: 92160/100000, Loss: 0.060250998\n",
      "Avg loss: 0.06498203948908246\n",
      "Epoch: 8, Iter: 10240/100000, Loss: 0.06207721\n",
      "Epoch: 8, Iter: 20480/100000, Loss: 0.06904781\n",
      "Epoch: 8, Iter: 30720/100000, Loss: 0.067827344\n",
      "Epoch: 8, Iter: 40960/100000, Loss: 0.06584706\n",
      "Epoch: 8, Iter: 51200/100000, Loss: 0.06625162\n",
      "Epoch: 8, Iter: 61440/100000, Loss: 0.066137716\n",
      "Epoch: 8, Iter: 71680/100000, Loss: 0.070150755\n",
      "Epoch: 8, Iter: 81920/100000, Loss: 0.06862861\n",
      "Epoch: 8, Iter: 92160/100000, Loss: 0.06372297\n",
      "Avg loss: 0.06494772921978813\n",
      "Epoch: 9, Iter: 10240/100000, Loss: 0.061462484\n",
      "Epoch: 9, Iter: 20480/100000, Loss: 0.062301945\n",
      "Epoch: 9, Iter: 30720/100000, Loss: 0.061428938\n",
      "Epoch: 9, Iter: 40960/100000, Loss: 0.069402464\n",
      "Epoch: 9, Iter: 51200/100000, Loss: 0.06461345\n",
      "Epoch: 9, Iter: 61440/100000, Loss: 0.06126056\n",
      "Epoch: 9, Iter: 71680/100000, Loss: 0.059639566\n",
      "Epoch: 9, Iter: 81920/100000, Loss: 0.0635572\n",
      "Epoch: 9, Iter: 92160/100000, Loss: 0.059748705\n",
      "Avg loss: 0.06417450785022422\n",
      "Epoch: 10, Iter: 10240/100000, Loss: 0.062862195\n",
      "Epoch: 10, Iter: 20480/100000, Loss: 0.064393386\n",
      "Epoch: 10, Iter: 30720/100000, Loss: 0.06416075\n",
      "Epoch: 10, Iter: 40960/100000, Loss: 0.066786535\n",
      "Epoch: 10, Iter: 51200/100000, Loss: 0.067770556\n",
      "Epoch: 10, Iter: 61440/100000, Loss: 0.06376751\n",
      "Epoch: 10, Iter: 71680/100000, Loss: 0.06339277\n",
      "Epoch: 10, Iter: 81920/100000, Loss: 0.07080286\n",
      "Epoch: 10, Iter: 92160/100000, Loss: 0.064702064\n",
      "Avg loss: 0.06404499402365733\n",
      "Epoch: 11, Iter: 10240/100000, Loss: 0.07015305\n",
      "Epoch: 11, Iter: 20480/100000, Loss: 0.06686459\n",
      "Epoch: 11, Iter: 30720/100000, Loss: 0.058343038\n",
      "Epoch: 11, Iter: 40960/100000, Loss: 0.06482844\n",
      "Epoch: 11, Iter: 51200/100000, Loss: 0.06624387\n",
      "Epoch: 11, Iter: 61440/100000, Loss: 0.0613287\n",
      "Epoch: 11, Iter: 71680/100000, Loss: 0.062408976\n",
      "Epoch: 11, Iter: 81920/100000, Loss: 0.06302214\n",
      "Epoch: 11, Iter: 92160/100000, Loss: 0.06461575\n",
      "Avg loss: 0.06454511075136588\n",
      "Epoch: 12, Iter: 10240/100000, Loss: 0.06364408\n",
      "Epoch: 12, Iter: 20480/100000, Loss: 0.068458766\n",
      "Epoch: 12, Iter: 30720/100000, Loss: 0.06484204\n",
      "Epoch: 12, Iter: 40960/100000, Loss: 0.06522048\n",
      "Epoch: 12, Iter: 51200/100000, Loss: 0.062341146\n",
      "Epoch: 12, Iter: 61440/100000, Loss: 0.061976884\n",
      "Epoch: 12, Iter: 71680/100000, Loss: 0.06347376\n",
      "Epoch: 12, Iter: 81920/100000, Loss: 0.06342152\n",
      "Epoch: 12, Iter: 92160/100000, Loss: 0.06006774\n",
      "Avg loss: 0.06387419000114362\n",
      "Epoch: 13, Iter: 10240/100000, Loss: 0.08064977\n",
      "Epoch: 13, Iter: 20480/100000, Loss: 0.06310281\n",
      "Epoch: 13, Iter: 30720/100000, Loss: 0.06241625\n",
      "Epoch: 13, Iter: 40960/100000, Loss: 0.066636354\n",
      "Epoch: 13, Iter: 51200/100000, Loss: 0.06313576\n",
      "Epoch: 13, Iter: 61440/100000, Loss: 0.05553633\n",
      "Epoch: 13, Iter: 71680/100000, Loss: 0.07527527\n",
      "Epoch: 13, Iter: 81920/100000, Loss: 0.06497417\n",
      "Epoch: 13, Iter: 92160/100000, Loss: 0.06435827\n",
      "Avg loss: 0.06806534732279089\n",
      "Epoch: 14, Iter: 10240/100000, Loss: 0.0568897\n",
      "Epoch: 14, Iter: 20480/100000, Loss: 0.06261422\n",
      "Epoch: 14, Iter: 30720/100000, Loss: 0.06611954\n",
      "Epoch: 14, Iter: 40960/100000, Loss: 0.061097912\n",
      "Epoch: 14, Iter: 51200/100000, Loss: 0.07183305\n",
      "Epoch: 14, Iter: 61440/100000, Loss: 0.08214836\n",
      "Epoch: 14, Iter: 71680/100000, Loss: 0.078142904\n",
      "Epoch: 14, Iter: 81920/100000, Loss: 0.07771334\n",
      "Epoch: 14, Iter: 92160/100000, Loss: 0.07377237\n",
      "Avg loss: 0.07302184449028723\n",
      "Epoch: 15, Iter: 10240/100000, Loss: 0.06740257\n",
      "Epoch: 15, Iter: 20480/100000, Loss: 0.08186997\n",
      "Epoch: 15, Iter: 30720/100000, Loss: 0.06657036\n",
      "Epoch: 15, Iter: 40960/100000, Loss: 0.07198987\n",
      "Epoch: 15, Iter: 51200/100000, Loss: 0.07280159\n",
      "Epoch: 15, Iter: 61440/100000, Loss: 0.06418836\n",
      "Epoch: 15, Iter: 71680/100000, Loss: 0.06337859\n",
      "Epoch: 15, Iter: 81920/100000, Loss: 0.08412267\n",
      "Epoch: 15, Iter: 92160/100000, Loss: 0.0646759\n",
      "Avg loss: 0.07058752524023204\n",
      "Epoch: 16, Iter: 10240/100000, Loss: 0.06418485\n",
      "Epoch: 16, Iter: 20480/100000, Loss: 0.11151695\n",
      "Epoch: 16, Iter: 30720/100000, Loss: 0.06728696\n",
      "Epoch: 16, Iter: 40960/100000, Loss: 0.08134112\n",
      "Epoch: 16, Iter: 51200/100000, Loss: 0.06539855\n",
      "Epoch: 16, Iter: 61440/100000, Loss: 0.06605049\n",
      "Epoch: 16, Iter: 71680/100000, Loss: 0.061883107\n",
      "Epoch: 16, Iter: 81920/100000, Loss: 0.10486653\n",
      "Epoch: 16, Iter: 92160/100000, Loss: 0.08797422\n",
      "Avg loss: 0.07385849004092905\n",
      "Epoch: 17, Iter: 10240/100000, Loss: 0.06449732\n",
      "Epoch: 17, Iter: 20480/100000, Loss: 0.0637352\n",
      "Epoch: 17, Iter: 30720/100000, Loss: 0.08766806\n",
      "Epoch: 17, Iter: 40960/100000, Loss: 0.07044659\n",
      "Epoch: 17, Iter: 51200/100000, Loss: 0.06893583\n",
      "Epoch: 17, Iter: 61440/100000, Loss: 0.06605783\n",
      "Epoch: 17, Iter: 71680/100000, Loss: 0.074561685\n",
      "Epoch: 17, Iter: 81920/100000, Loss: 0.07212192\n",
      "Epoch: 17, Iter: 92160/100000, Loss: 0.06547399\n",
      "Avg loss: 0.07126138320903189\n",
      "Epoch: 18, Iter: 10240/100000, Loss: 0.06460721\n",
      "Epoch: 18, Iter: 20480/100000, Loss: 0.07041601\n",
      "Epoch: 18, Iter: 30720/100000, Loss: 0.061946586\n",
      "Epoch: 18, Iter: 40960/100000, Loss: 0.06850602\n",
      "Epoch: 18, Iter: 51200/100000, Loss: 0.06920113\n",
      "Epoch: 18, Iter: 61440/100000, Loss: 0.076941036\n",
      "Epoch: 18, Iter: 71680/100000, Loss: 0.06546016\n",
      "Epoch: 18, Iter: 81920/100000, Loss: 0.06678056\n",
      "Epoch: 18, Iter: 92160/100000, Loss: 0.062155012\n",
      "Avg loss: 0.06816394968899255\n",
      "Epoch: 19, Iter: 10240/100000, Loss: 0.0803314\n",
      "Epoch: 19, Iter: 20480/100000, Loss: 0.0616832\n",
      "Epoch: 19, Iter: 30720/100000, Loss: 0.08599906\n",
      "Epoch: 19, Iter: 40960/100000, Loss: 0.07995959\n",
      "Epoch: 19, Iter: 51200/100000, Loss: 0.06501674\n",
      "Epoch: 19, Iter: 61440/100000, Loss: 0.058441516\n",
      "Epoch: 19, Iter: 71680/100000, Loss: 0.07131569\n",
      "Epoch: 19, Iter: 81920/100000, Loss: 0.07180409\n",
      "Epoch: 19, Iter: 92160/100000, Loss: 0.06267518\n",
      "Avg loss: 0.080567168398309\n",
      "Epoch: 20, Iter: 10240/100000, Loss: 0.058456678\n",
      "Epoch: 20, Iter: 20480/100000, Loss: 0.062468566\n",
      "Epoch: 20, Iter: 30720/100000, Loss: 0.061543718\n",
      "Epoch: 20, Iter: 40960/100000, Loss: 0.061422564\n",
      "Epoch: 20, Iter: 51200/100000, Loss: 0.06870134\n",
      "Epoch: 20, Iter: 61440/100000, Loss: 0.0797663\n",
      "Epoch: 20, Iter: 71680/100000, Loss: 0.06513283\n",
      "Epoch: 20, Iter: 81920/100000, Loss: 0.07237116\n",
      "Epoch: 20, Iter: 92160/100000, Loss: 0.059271142\n",
      "Avg loss: 0.06749639817580734\n",
      "Epoch: 21, Iter: 10240/100000, Loss: 0.055386662\n",
      "Epoch: 21, Iter: 20480/100000, Loss: 0.06476937\n",
      "Epoch: 21, Iter: 30720/100000, Loss: 0.06373213\n",
      "Epoch: 21, Iter: 40960/100000, Loss: 0.10637301\n",
      "Epoch: 21, Iter: 51200/100000, Loss: 0.07407375\n",
      "Epoch: 21, Iter: 61440/100000, Loss: 0.052933294\n",
      "Epoch: 21, Iter: 71680/100000, Loss: 0.062035125\n",
      "Epoch: 21, Iter: 81920/100000, Loss: 0.0634825\n",
      "Epoch: 21, Iter: 92160/100000, Loss: 0.060869403\n",
      "Avg loss: 0.06713429723203797\n",
      "Epoch: 22, Iter: 10240/100000, Loss: 0.06724851\n",
      "Epoch: 22, Iter: 20480/100000, Loss: 0.060561743\n",
      "Epoch: 22, Iter: 30720/100000, Loss: 0.088185444\n",
      "Epoch: 22, Iter: 40960/100000, Loss: 0.081039086\n",
      "Epoch: 22, Iter: 51200/100000, Loss: 0.07065744\n",
      "Epoch: 22, Iter: 61440/100000, Loss: 0.06968138\n",
      "Epoch: 22, Iter: 71680/100000, Loss: 0.077410564\n",
      "Epoch: 22, Iter: 81920/100000, Loss: 0.07619655\n",
      "Epoch: 22, Iter: 92160/100000, Loss: 0.06061877\n",
      "Avg loss: 0.06999496305265378\n",
      "Epoch: 23, Iter: 10240/100000, Loss: 0.07303465\n",
      "Epoch: 23, Iter: 20480/100000, Loss: 0.083628125\n",
      "Epoch: 23, Iter: 30720/100000, Loss: 0.08428856\n",
      "Epoch: 23, Iter: 40960/100000, Loss: 0.080443755\n",
      "Epoch: 23, Iter: 51200/100000, Loss: 0.086583376\n",
      "Epoch: 23, Iter: 61440/100000, Loss: 0.071702555\n",
      "Epoch: 23, Iter: 71680/100000, Loss: 0.14190233\n",
      "Epoch: 23, Iter: 81920/100000, Loss: 0.08663675\n",
      "Epoch: 23, Iter: 92160/100000, Loss: 0.05804889\n",
      "Avg loss: 0.0836653783917427\n",
      "Epoch: 24, Iter: 10240/100000, Loss: 0.09805608\n",
      "Epoch: 24, Iter: 20480/100000, Loss: 0.08461663\n",
      "Epoch: 24, Iter: 30720/100000, Loss: 0.09066436\n",
      "Epoch: 24, Iter: 40960/100000, Loss: 0.08670714\n",
      "Epoch: 24, Iter: 51200/100000, Loss: 0.08272491\n",
      "Epoch: 24, Iter: 61440/100000, Loss: 0.1929568\n",
      "Epoch: 24, Iter: 71680/100000, Loss: 0.066342235\n",
      "Epoch: 24, Iter: 81920/100000, Loss: 0.09790318\n",
      "Epoch: 24, Iter: 92160/100000, Loss: 0.069258235\n",
      "Avg loss: 0.09004560473960699\n",
      "Epoch: 25, Iter: 10240/100000, Loss: 0.06100034\n",
      "Epoch: 25, Iter: 20480/100000, Loss: 0.06744541\n",
      "Epoch: 25, Iter: 30720/100000, Loss: 0.056538127\n",
      "Epoch: 25, Iter: 40960/100000, Loss: 0.12610544\n",
      "Epoch: 25, Iter: 51200/100000, Loss: 0.08179662\n",
      "Epoch: 25, Iter: 61440/100000, Loss: 0.061447017\n",
      "Epoch: 25, Iter: 71680/100000, Loss: 0.057415605\n",
      "Epoch: 25, Iter: 81920/100000, Loss: 0.08766985\n",
      "Epoch: 25, Iter: 92160/100000, Loss: 0.07268333\n",
      "Avg loss: 0.07087108204813347\n",
      "Epoch: 26, Iter: 10240/100000, Loss: 0.09494533\n",
      "Epoch: 26, Iter: 20480/100000, Loss: 0.066488475\n",
      "Epoch: 26, Iter: 30720/100000, Loss: 0.061543096\n",
      "Epoch: 26, Iter: 40960/100000, Loss: 0.06667238\n",
      "Epoch: 26, Iter: 51200/100000, Loss: 0.07040117\n",
      "Epoch: 26, Iter: 61440/100000, Loss: 0.08149296\n",
      "Epoch: 26, Iter: 71680/100000, Loss: 0.09456674\n",
      "Epoch: 26, Iter: 81920/100000, Loss: 0.14345542\n",
      "Epoch: 26, Iter: 92160/100000, Loss: 0.05945597\n",
      "Avg loss: 0.0838675633764144\n",
      "Epoch: 27, Iter: 10240/100000, Loss: 0.11370983\n",
      "Epoch: 27, Iter: 20480/100000, Loss: 0.09715576\n",
      "Epoch: 27, Iter: 30720/100000, Loss: 0.051466458\n",
      "Epoch: 27, Iter: 40960/100000, Loss: 0.056821767\n",
      "Epoch: 27, Iter: 51200/100000, Loss: 0.07616665\n",
      "Epoch: 27, Iter: 61440/100000, Loss: 0.08182388\n",
      "Epoch: 27, Iter: 71680/100000, Loss: 0.08212958\n",
      "Epoch: 27, Iter: 81920/100000, Loss: 0.12565778\n",
      "Epoch: 27, Iter: 92160/100000, Loss: 0.08386247\n",
      "Avg loss: 0.09564004254709814\n",
      "Epoch: 28, Iter: 10240/100000, Loss: 0.091154024\n",
      "Epoch: 28, Iter: 20480/100000, Loss: 0.1005716\n",
      "Epoch: 28, Iter: 30720/100000, Loss: 0.092605\n",
      "Epoch: 28, Iter: 40960/100000, Loss: 0.06934897\n",
      "Epoch: 28, Iter: 51200/100000, Loss: 0.08081941\n",
      "Epoch: 28, Iter: 61440/100000, Loss: 0.04951665\n",
      "Epoch: 28, Iter: 71680/100000, Loss: 0.06415887\n",
      "Epoch: 28, Iter: 81920/100000, Loss: 0.066068895\n",
      "Epoch: 28, Iter: 92160/100000, Loss: 0.06857824\n",
      "Avg loss: 0.07504499204379995\n",
      "Epoch: 29, Iter: 10240/100000, Loss: 0.10652554\n",
      "Epoch: 29, Iter: 20480/100000, Loss: 0.09181614\n",
      "Epoch: 29, Iter: 30720/100000, Loss: 0.06833303\n",
      "Epoch: 29, Iter: 40960/100000, Loss: 0.062977284\n",
      "Epoch: 29, Iter: 51200/100000, Loss: 0.07950238\n",
      "Epoch: 29, Iter: 61440/100000, Loss: 0.1142422\n",
      "Epoch: 29, Iter: 71680/100000, Loss: 0.057787783\n",
      "Epoch: 29, Iter: 81920/100000, Loss: 0.0663346\n",
      "Epoch: 29, Iter: 92160/100000, Loss: 0.052187085\n",
      "Avg loss: 0.08380763493862349\n",
      "Epoch: 30, Iter: 10240/100000, Loss: 0.06832449\n",
      "Epoch: 30, Iter: 20480/100000, Loss: 0.05168646\n",
      "Epoch: 30, Iter: 30720/100000, Loss: 0.046507582\n",
      "Epoch: 30, Iter: 40960/100000, Loss: 0.052897967\n",
      "Epoch: 30, Iter: 51200/100000, Loss: 0.09817448\n",
      "Epoch: 30, Iter: 61440/100000, Loss: 0.04739523\n",
      "Epoch: 30, Iter: 71680/100000, Loss: 0.060657956\n",
      "Epoch: 30, Iter: 81920/100000, Loss: 0.057025567\n",
      "Epoch: 30, Iter: 92160/100000, Loss: 0.04564131\n",
      "Avg loss: 0.06426318293226134\n",
      "Epoch: 31, Iter: 10240/100000, Loss: 0.08320268\n",
      "Epoch: 31, Iter: 20480/100000, Loss: 0.15529113\n",
      "Epoch: 31, Iter: 30720/100000, Loss: 0.07878672\n",
      "Epoch: 31, Iter: 40960/100000, Loss: 0.05652465\n",
      "Epoch: 31, Iter: 51200/100000, Loss: 0.04391282\n",
      "Epoch: 31, Iter: 61440/100000, Loss: 0.04574935\n",
      "Epoch: 31, Iter: 71680/100000, Loss: 0.07846999\n",
      "Epoch: 31, Iter: 81920/100000, Loss: 0.05971649\n",
      "Epoch: 31, Iter: 92160/100000, Loss: 0.067539595\n",
      "Avg loss: 0.07055239095208571\n",
      "Epoch: 32, Iter: 10240/100000, Loss: 0.041950695\n",
      "Epoch: 32, Iter: 20480/100000, Loss: 0.051302847\n",
      "Epoch: 32, Iter: 30720/100000, Loss: 0.07138257\n",
      "Epoch: 32, Iter: 40960/100000, Loss: 0.049926516\n",
      "Epoch: 32, Iter: 51200/100000, Loss: 0.048453063\n",
      "Epoch: 32, Iter: 61440/100000, Loss: 0.10441971\n",
      "Epoch: 32, Iter: 71680/100000, Loss: 0.06831419\n",
      "Epoch: 32, Iter: 81920/100000, Loss: 0.06721515\n",
      "Epoch: 32, Iter: 92160/100000, Loss: 0.06607703\n",
      "Avg loss: 0.060096214189357365\n",
      "Epoch: 33, Iter: 10240/100000, Loss: 0.044821117\n",
      "Epoch: 33, Iter: 20480/100000, Loss: 0.048594024\n",
      "Epoch: 33, Iter: 30720/100000, Loss: 0.041082464\n",
      "Epoch: 33, Iter: 40960/100000, Loss: 0.054932766\n",
      "Epoch: 33, Iter: 51200/100000, Loss: 0.047886245\n",
      "Epoch: 33, Iter: 61440/100000, Loss: 0.043021277\n",
      "Epoch: 33, Iter: 71680/100000, Loss: 0.041354023\n",
      "Epoch: 33, Iter: 81920/100000, Loss: 0.07749374\n",
      "Epoch: 33, Iter: 92160/100000, Loss: 0.044563353\n",
      "Avg loss: 0.04979039836175663\n",
      "Epoch: 34, Iter: 10240/100000, Loss: 0.038071148\n",
      "Epoch: 34, Iter: 20480/100000, Loss: 0.04099007\n",
      "Epoch: 34, Iter: 30720/100000, Loss: 0.044295676\n",
      "Epoch: 34, Iter: 40960/100000, Loss: 0.07029165\n",
      "Epoch: 34, Iter: 51200/100000, Loss: 0.0604693\n",
      "Epoch: 34, Iter: 61440/100000, Loss: 0.037731316\n",
      "Epoch: 34, Iter: 71680/100000, Loss: 0.039546754\n",
      "Epoch: 34, Iter: 81920/100000, Loss: 0.042269617\n",
      "Epoch: 34, Iter: 92160/100000, Loss: 0.055417996\n",
      "Avg loss: 0.048388014096267445\n",
      "Epoch: 35, Iter: 10240/100000, Loss: 0.03389412\n",
      "Epoch: 35, Iter: 20480/100000, Loss: 0.037971407\n",
      "Epoch: 35, Iter: 30720/100000, Loss: 0.039476044\n",
      "Epoch: 35, Iter: 40960/100000, Loss: 0.03726598\n",
      "Epoch: 35, Iter: 51200/100000, Loss: 0.03295914\n",
      "Epoch: 35, Iter: 61440/100000, Loss: 0.034383282\n",
      "Epoch: 35, Iter: 71680/100000, Loss: 0.03176727\n",
      "Epoch: 35, Iter: 81920/100000, Loss: 0.03500743\n",
      "Epoch: 35, Iter: 92160/100000, Loss: 0.034375362\n",
      "Avg loss: 0.035951591951330915\n",
      "Epoch: 36, Iter: 10240/100000, Loss: 0.036279958\n",
      "Epoch: 36, Iter: 20480/100000, Loss: 0.03387081\n",
      "Epoch: 36, Iter: 30720/100000, Loss: 0.04134455\n",
      "Epoch: 36, Iter: 40960/100000, Loss: 0.034803472\n",
      "Epoch: 36, Iter: 51200/100000, Loss: 0.03148467\n",
      "Epoch: 36, Iter: 61440/100000, Loss: 0.03261587\n",
      "Epoch: 36, Iter: 71680/100000, Loss: 0.03464895\n",
      "Epoch: 36, Iter: 81920/100000, Loss: 0.035691272\n",
      "Epoch: 36, Iter: 92160/100000, Loss: 0.03207069\n",
      "Avg loss: 0.034594397070174365\n",
      "Epoch: 37, Iter: 10240/100000, Loss: 0.031560536\n",
      "Epoch: 37, Iter: 20480/100000, Loss: 0.032239437\n",
      "Epoch: 37, Iter: 30720/100000, Loss: 0.032143347\n",
      "Epoch: 37, Iter: 40960/100000, Loss: 0.0330923\n",
      "Epoch: 37, Iter: 51200/100000, Loss: 0.029924277\n",
      "Epoch: 37, Iter: 61440/100000, Loss: 0.03001802\n",
      "Epoch: 37, Iter: 71680/100000, Loss: 0.03328196\n",
      "Epoch: 37, Iter: 81920/100000, Loss: 0.032820433\n",
      "Epoch: 37, Iter: 92160/100000, Loss: 0.029805418\n",
      "Avg loss: 0.032052642387366784\n",
      "Epoch: 38, Iter: 10240/100000, Loss: 0.033760574\n",
      "Epoch: 38, Iter: 20480/100000, Loss: 0.030013839\n",
      "Epoch: 38, Iter: 30720/100000, Loss: 0.029934973\n",
      "Epoch: 38, Iter: 40960/100000, Loss: 0.030358292\n",
      "Epoch: 38, Iter: 51200/100000, Loss: 0.030925766\n",
      "Epoch: 38, Iter: 61440/100000, Loss: 0.033463\n",
      "Epoch: 38, Iter: 71680/100000, Loss: 0.03296851\n",
      "Epoch: 38, Iter: 81920/100000, Loss: 0.030326877\n",
      "Epoch: 38, Iter: 92160/100000, Loss: 0.033567548\n",
      "Avg loss: 0.03206141669418394\n",
      "Epoch: 39, Iter: 10240/100000, Loss: 0.032741006\n",
      "Epoch: 39, Iter: 20480/100000, Loss: 0.03216272\n",
      "Epoch: 39, Iter: 30720/100000, Loss: 0.031852193\n",
      "Epoch: 39, Iter: 40960/100000, Loss: 0.033020012\n",
      "Epoch: 39, Iter: 51200/100000, Loss: 0.033938013\n",
      "Epoch: 39, Iter: 61440/100000, Loss: 0.029207803\n",
      "Epoch: 39, Iter: 71680/100000, Loss: 0.032162722\n",
      "Epoch: 39, Iter: 81920/100000, Loss: 0.029719183\n",
      "Epoch: 39, Iter: 92160/100000, Loss: 0.030827677\n",
      "Avg loss: 0.031778292480817774\n",
      "Epoch: 40, Iter: 10240/100000, Loss: 0.03262037\n",
      "Epoch: 40, Iter: 20480/100000, Loss: 0.032250274\n",
      "Epoch: 40, Iter: 30720/100000, Loss: 0.02844742\n",
      "Epoch: 40, Iter: 40960/100000, Loss: 0.03444659\n",
      "Epoch: 40, Iter: 51200/100000, Loss: 0.02924037\n",
      "Epoch: 40, Iter: 61440/100000, Loss: 0.030695604\n",
      "Epoch: 40, Iter: 71680/100000, Loss: 0.033071563\n",
      "Epoch: 40, Iter: 81920/100000, Loss: 0.030417971\n",
      "Epoch: 40, Iter: 92160/100000, Loss: 0.030258633\n",
      "Avg loss: 0.03203760955444316\n",
      "Epoch: 41, Iter: 10240/100000, Loss: 0.030974694\n",
      "Epoch: 41, Iter: 20480/100000, Loss: 0.031847652\n",
      "Epoch: 41, Iter: 30720/100000, Loss: 0.03281516\n",
      "Epoch: 41, Iter: 40960/100000, Loss: 0.029194552\n",
      "Epoch: 41, Iter: 51200/100000, Loss: 0.030400906\n",
      "Epoch: 41, Iter: 61440/100000, Loss: 0.026928008\n",
      "Epoch: 41, Iter: 71680/100000, Loss: 0.030867446\n",
      "Epoch: 41, Iter: 81920/100000, Loss: 0.0317266\n",
      "Epoch: 41, Iter: 92160/100000, Loss: 0.03327077\n",
      "Avg loss: 0.031406941583629736\n",
      "Epoch: 42, Iter: 10240/100000, Loss: 0.033207968\n",
      "Epoch: 42, Iter: 20480/100000, Loss: 0.028001929\n",
      "Epoch: 42, Iter: 30720/100000, Loss: 0.031199062\n",
      "Epoch: 42, Iter: 40960/100000, Loss: 0.031280477\n",
      "Epoch: 42, Iter: 51200/100000, Loss: 0.03404226\n",
      "Epoch: 42, Iter: 61440/100000, Loss: 0.029907\n",
      "Epoch: 42, Iter: 71680/100000, Loss: 0.032661516\n",
      "Epoch: 42, Iter: 81920/100000, Loss: 0.034080833\n",
      "Epoch: 42, Iter: 92160/100000, Loss: 0.030629914\n",
      "Avg loss: 0.0315502205498747\n",
      "Epoch: 43, Iter: 10240/100000, Loss: 0.03137418\n",
      "Epoch: 43, Iter: 20480/100000, Loss: 0.031062385\n",
      "Epoch: 43, Iter: 30720/100000, Loss: 0.03269832\n",
      "Epoch: 43, Iter: 40960/100000, Loss: 0.028477821\n",
      "Epoch: 43, Iter: 51200/100000, Loss: 0.027329583\n",
      "Epoch: 43, Iter: 61440/100000, Loss: 0.031053482\n",
      "Epoch: 43, Iter: 71680/100000, Loss: 0.032204673\n",
      "Epoch: 43, Iter: 81920/100000, Loss: 0.030840669\n",
      "Epoch: 43, Iter: 92160/100000, Loss: 0.030913152\n",
      "Avg loss: 0.031523966451281124\n",
      "Epoch: 44, Iter: 10240/100000, Loss: 0.03119123\n",
      "Epoch: 44, Iter: 20480/100000, Loss: 0.029536193\n",
      "Epoch: 44, Iter: 30720/100000, Loss: 0.029388316\n",
      "Epoch: 44, Iter: 40960/100000, Loss: 0.030936603\n",
      "Epoch: 44, Iter: 51200/100000, Loss: 0.032878675\n",
      "Epoch: 44, Iter: 61440/100000, Loss: 0.029735502\n",
      "Epoch: 44, Iter: 71680/100000, Loss: 0.04010279\n",
      "Epoch: 44, Iter: 81920/100000, Loss: 0.033294365\n",
      "Epoch: 44, Iter: 92160/100000, Loss: 0.033861823\n",
      "Avg loss: 0.03202422324222388\n",
      "Epoch: 45, Iter: 10240/100000, Loss: 0.03465806\n",
      "Epoch: 45, Iter: 20480/100000, Loss: 0.029903978\n",
      "Epoch: 45, Iter: 30720/100000, Loss: 0.029133502\n",
      "Epoch: 45, Iter: 40960/100000, Loss: 0.03463289\n",
      "Epoch: 45, Iter: 51200/100000, Loss: 0.028519481\n",
      "Epoch: 45, Iter: 61440/100000, Loss: 0.03146627\n",
      "Epoch: 45, Iter: 71680/100000, Loss: 0.037388723\n",
      "Epoch: 45, Iter: 81920/100000, Loss: 0.0324729\n",
      "Epoch: 45, Iter: 92160/100000, Loss: 0.035500117\n",
      "Avg loss: 0.032031181162780094\n",
      "Epoch: 46, Iter: 10240/100000, Loss: 0.029987799\n",
      "Epoch: 46, Iter: 20480/100000, Loss: 0.03197883\n",
      "Epoch: 46, Iter: 30720/100000, Loss: 0.029647142\n",
      "Epoch: 46, Iter: 40960/100000, Loss: 0.031051904\n",
      "Epoch: 46, Iter: 51200/100000, Loss: 0.029942757\n",
      "Epoch: 46, Iter: 61440/100000, Loss: 0.032604326\n",
      "Epoch: 46, Iter: 71680/100000, Loss: 0.034539722\n",
      "Epoch: 46, Iter: 81920/100000, Loss: 0.032246683\n",
      "Epoch: 46, Iter: 92160/100000, Loss: 0.031402662\n",
      "Avg loss: 0.031404024028440114\n",
      "Epoch: 47, Iter: 10240/100000, Loss: 0.03136283\n",
      "Epoch: 47, Iter: 20480/100000, Loss: 0.029651567\n",
      "Epoch: 47, Iter: 30720/100000, Loss: 0.03150014\n",
      "Epoch: 47, Iter: 40960/100000, Loss: 0.035315875\n",
      "Epoch: 47, Iter: 51200/100000, Loss: 0.031364515\n",
      "Epoch: 47, Iter: 61440/100000, Loss: 0.032197695\n",
      "Epoch: 47, Iter: 71680/100000, Loss: 0.031394243\n",
      "Epoch: 47, Iter: 81920/100000, Loss: 0.029847737\n",
      "Epoch: 47, Iter: 92160/100000, Loss: 0.030848438\n",
      "Avg loss: 0.03124739640613192\n",
      "Epoch: 48, Iter: 10240/100000, Loss: 0.03216383\n",
      "Epoch: 48, Iter: 20480/100000, Loss: 0.030444141\n",
      "Epoch: 48, Iter: 30720/100000, Loss: 0.030922512\n",
      "Epoch: 48, Iter: 40960/100000, Loss: 0.032936573\n",
      "Epoch: 48, Iter: 51200/100000, Loss: 0.03139245\n",
      "Epoch: 48, Iter: 61440/100000, Loss: 0.029095488\n",
      "Epoch: 48, Iter: 71680/100000, Loss: 0.032454107\n",
      "Epoch: 48, Iter: 81920/100000, Loss: 0.029999053\n",
      "Epoch: 48, Iter: 92160/100000, Loss: 0.032927606\n",
      "Avg loss: 0.03160118257876524\n",
      "Epoch: 49, Iter: 10240/100000, Loss: 0.034958526\n",
      "Epoch: 49, Iter: 20480/100000, Loss: 0.03110522\n",
      "Epoch: 49, Iter: 30720/100000, Loss: 0.03554361\n",
      "Epoch: 49, Iter: 40960/100000, Loss: 0.030748114\n",
      "Epoch: 49, Iter: 51200/100000, Loss: 0.028854962\n",
      "Epoch: 49, Iter: 61440/100000, Loss: 0.03308108\n",
      "Epoch: 49, Iter: 71680/100000, Loss: 0.031768143\n",
      "Epoch: 49, Iter: 81920/100000, Loss: 0.031286728\n",
      "Epoch: 49, Iter: 92160/100000, Loss: 0.031261735\n",
      "Avg loss: 0.03186709694948393\n",
      "Epoch: 50, Iter: 10240/100000, Loss: 0.033577073\n",
      "Epoch: 50, Iter: 20480/100000, Loss: 0.03162017\n",
      "Epoch: 50, Iter: 30720/100000, Loss: 0.034395948\n",
      "Epoch: 50, Iter: 40960/100000, Loss: 0.03279509\n",
      "Epoch: 50, Iter: 51200/100000, Loss: 0.030740991\n",
      "Epoch: 50, Iter: 61440/100000, Loss: 0.028187577\n",
      "Epoch: 50, Iter: 71680/100000, Loss: 0.033159576\n",
      "Epoch: 50, Iter: 81920/100000, Loss: 0.03014171\n",
      "Epoch: 50, Iter: 92160/100000, Loss: 0.029284969\n",
      "Avg loss: 0.032148574008462355\n",
      "Epoch: 51, Iter: 10240/100000, Loss: 0.033078335\n",
      "Epoch: 51, Iter: 20480/100000, Loss: 0.03650831\n",
      "Epoch: 51, Iter: 30720/100000, Loss: 0.03509501\n",
      "Epoch: 51, Iter: 40960/100000, Loss: 0.031609513\n",
      "Epoch: 51, Iter: 51200/100000, Loss: 0.03192754\n",
      "Epoch: 51, Iter: 61440/100000, Loss: 0.03263352\n",
      "Epoch: 51, Iter: 71680/100000, Loss: 0.035281707\n",
      "Epoch: 51, Iter: 81920/100000, Loss: 0.03178348\n",
      "Epoch: 51, Iter: 92160/100000, Loss: 0.02942542\n",
      "Avg loss: 0.03436201493995091\n",
      "Epoch: 52, Iter: 10240/100000, Loss: 0.0352039\n",
      "Epoch: 52, Iter: 20480/100000, Loss: 0.030349974\n",
      "Epoch: 52, Iter: 30720/100000, Loss: 0.0311209\n",
      "Epoch: 52, Iter: 40960/100000, Loss: 0.033434216\n",
      "Epoch: 52, Iter: 51200/100000, Loss: 0.028991805\n",
      "Epoch: 52, Iter: 61440/100000, Loss: 0.029950336\n",
      "Epoch: 52, Iter: 71680/100000, Loss: 0.031071879\n",
      "Epoch: 52, Iter: 81920/100000, Loss: 0.034045074\n",
      "Epoch: 52, Iter: 92160/100000, Loss: 0.030988947\n",
      "Avg loss: 0.03181360681186017\n",
      "Epoch: 53, Iter: 10240/100000, Loss: 0.033392712\n",
      "Epoch: 53, Iter: 20480/100000, Loss: 0.03333064\n",
      "Epoch: 53, Iter: 30720/100000, Loss: 0.031504046\n",
      "Epoch: 53, Iter: 40960/100000, Loss: 0.0325926\n",
      "Epoch: 53, Iter: 51200/100000, Loss: 0.03006773\n",
      "Epoch: 53, Iter: 61440/100000, Loss: 0.031884633\n",
      "Epoch: 53, Iter: 71680/100000, Loss: 0.033209257\n",
      "Epoch: 53, Iter: 81920/100000, Loss: 0.03363952\n",
      "Epoch: 53, Iter: 92160/100000, Loss: 0.031471416\n",
      "Avg loss: 0.031915453541063774\n",
      "Epoch: 54, Iter: 10240/100000, Loss: 0.03331927\n",
      "Epoch: 54, Iter: 20480/100000, Loss: 0.0332959\n",
      "Epoch: 54, Iter: 30720/100000, Loss: 0.03557262\n",
      "Epoch: 54, Iter: 40960/100000, Loss: 0.034073647\n",
      "Epoch: 54, Iter: 51200/100000, Loss: 0.03605385\n",
      "Epoch: 54, Iter: 61440/100000, Loss: 0.031932995\n",
      "Epoch: 54, Iter: 71680/100000, Loss: 0.029516362\n",
      "Epoch: 54, Iter: 81920/100000, Loss: 0.032825824\n",
      "Epoch: 54, Iter: 92160/100000, Loss: 0.029470965\n",
      "Avg loss: 0.03218150703409284\n",
      "Epoch: 55, Iter: 10240/100000, Loss: 0.029387692\n",
      "Epoch: 55, Iter: 20480/100000, Loss: 0.031045016\n",
      "Epoch: 55, Iter: 30720/100000, Loss: 0.035631858\n",
      "Epoch: 55, Iter: 40960/100000, Loss: 0.036405694\n",
      "Epoch: 55, Iter: 51200/100000, Loss: 0.028761609\n",
      "Epoch: 55, Iter: 61440/100000, Loss: 0.028651472\n",
      "Epoch: 55, Iter: 71680/100000, Loss: 0.032778364\n",
      "Epoch: 55, Iter: 81920/100000, Loss: 0.03138585\n",
      "Epoch: 55, Iter: 92160/100000, Loss: 0.032966454\n",
      "Avg loss: 0.031967441753013845\n",
      "Epoch: 56, Iter: 10240/100000, Loss: 0.032969445\n",
      "Epoch: 56, Iter: 20480/100000, Loss: 0.033368178\n",
      "Epoch: 56, Iter: 30720/100000, Loss: 0.032609586\n",
      "Epoch: 56, Iter: 40960/100000, Loss: 0.03812103\n",
      "Epoch: 56, Iter: 51200/100000, Loss: 0.03445025\n",
      "Epoch: 56, Iter: 61440/100000, Loss: 0.032474063\n",
      "Epoch: 56, Iter: 71680/100000, Loss: 0.031235565\n",
      "Epoch: 56, Iter: 81920/100000, Loss: 0.033344653\n",
      "Epoch: 56, Iter: 92160/100000, Loss: 0.031287357\n",
      "Avg loss: 0.03326565553386187\n",
      "Epoch: 57, Iter: 10240/100000, Loss: 0.032207895\n",
      "Epoch: 57, Iter: 20480/100000, Loss: 0.030902455\n",
      "Epoch: 57, Iter: 30720/100000, Loss: 0.03480897\n",
      "Epoch: 57, Iter: 40960/100000, Loss: 0.032182433\n",
      "Epoch: 57, Iter: 51200/100000, Loss: 0.029853892\n",
      "Epoch: 57, Iter: 61440/100000, Loss: 0.029966304\n",
      "Epoch: 57, Iter: 71680/100000, Loss: 0.03212501\n",
      "Epoch: 57, Iter: 81920/100000, Loss: 0.035269797\n",
      "Epoch: 57, Iter: 92160/100000, Loss: 0.03169398\n",
      "Avg loss: 0.03227382009253674\n",
      "Epoch: 58, Iter: 10240/100000, Loss: 0.03031208\n",
      "Epoch: 58, Iter: 20480/100000, Loss: 0.031312138\n",
      "Epoch: 58, Iter: 30720/100000, Loss: 0.03302062\n",
      "Epoch: 58, Iter: 40960/100000, Loss: 0.036734935\n",
      "Epoch: 58, Iter: 51200/100000, Loss: 0.03351072\n",
      "Epoch: 58, Iter: 61440/100000, Loss: 0.027393224\n",
      "Epoch: 58, Iter: 71680/100000, Loss: 0.028893355\n",
      "Epoch: 58, Iter: 81920/100000, Loss: 0.04166755\n",
      "Epoch: 58, Iter: 92160/100000, Loss: 0.029741969\n",
      "Avg loss: 0.03304032217135135\n",
      "Epoch: 59, Iter: 10240/100000, Loss: 0.03269107\n",
      "Epoch: 59, Iter: 20480/100000, Loss: 0.029633919\n",
      "Epoch: 59, Iter: 30720/100000, Loss: 0.031039825\n",
      "Epoch: 59, Iter: 40960/100000, Loss: 0.037859507\n",
      "Epoch: 59, Iter: 51200/100000, Loss: 0.03289276\n",
      "Epoch: 59, Iter: 61440/100000, Loss: 0.032221735\n",
      "Epoch: 59, Iter: 71680/100000, Loss: 0.0321651\n",
      "Epoch: 59, Iter: 81920/100000, Loss: 0.034304634\n",
      "Epoch: 59, Iter: 92160/100000, Loss: 0.03196285\n",
      "Avg loss: 0.0322674079654143\n",
      "Epoch: 60, Iter: 10240/100000, Loss: 0.028313298\n",
      "Epoch: 60, Iter: 20480/100000, Loss: 0.028596472\n",
      "Epoch: 60, Iter: 30720/100000, Loss: 0.03162016\n",
      "Epoch: 60, Iter: 40960/100000, Loss: 0.03996124\n",
      "Epoch: 60, Iter: 51200/100000, Loss: 0.02860715\n",
      "Epoch: 60, Iter: 61440/100000, Loss: 0.032803003\n",
      "Epoch: 60, Iter: 71680/100000, Loss: 0.029743087\n",
      "Epoch: 60, Iter: 81920/100000, Loss: 0.034080744\n",
      "Epoch: 60, Iter: 92160/100000, Loss: 0.02539474\n",
      "Avg loss: 0.03225560054259816\n",
      "Epoch: 61, Iter: 10240/100000, Loss: 0.03386514\n",
      "Epoch: 61, Iter: 20480/100000, Loss: 0.029393645\n",
      "Epoch: 61, Iter: 30720/100000, Loss: 0.034210306\n",
      "Epoch: 61, Iter: 40960/100000, Loss: 0.035362303\n",
      "Epoch: 61, Iter: 51200/100000, Loss: 0.029692521\n",
      "Epoch: 61, Iter: 61440/100000, Loss: 0.035033733\n",
      "Epoch: 61, Iter: 71680/100000, Loss: 0.028455831\n",
      "Epoch: 61, Iter: 81920/100000, Loss: 0.038374234\n",
      "Epoch: 61, Iter: 92160/100000, Loss: 0.030928232\n",
      "Avg loss: 0.032458874233758324\n",
      "Epoch: 62, Iter: 10240/100000, Loss: 0.027760321\n",
      "Epoch: 62, Iter: 20480/100000, Loss: 0.031388298\n",
      "Epoch: 62, Iter: 30720/100000, Loss: 0.032362465\n",
      "Epoch: 62, Iter: 40960/100000, Loss: 0.03361722\n",
      "Epoch: 62, Iter: 51200/100000, Loss: 0.032379124\n",
      "Epoch: 62, Iter: 61440/100000, Loss: 0.033152606\n",
      "Epoch: 62, Iter: 71680/100000, Loss: 0.03277287\n",
      "Epoch: 62, Iter: 81920/100000, Loss: 0.034062397\n",
      "Epoch: 62, Iter: 92160/100000, Loss: 0.034051433\n",
      "Avg loss: 0.03210125093530748\n",
      "Epoch: 63, Iter: 10240/100000, Loss: 0.028848374\n",
      "Epoch: 63, Iter: 20480/100000, Loss: 0.0321151\n",
      "Epoch: 63, Iter: 30720/100000, Loss: 0.031178668\n",
      "Epoch: 63, Iter: 40960/100000, Loss: 0.036903076\n",
      "Epoch: 63, Iter: 51200/100000, Loss: 0.029935982\n",
      "Epoch: 63, Iter: 61440/100000, Loss: 0.029809486\n",
      "Epoch: 63, Iter: 71680/100000, Loss: 0.030432904\n",
      "Epoch: 63, Iter: 81920/100000, Loss: 0.03907967\n",
      "Epoch: 63, Iter: 92160/100000, Loss: 0.025862575\n",
      "Avg loss: 0.0314065076833226\n",
      "Epoch: 64, Iter: 10240/100000, Loss: 0.033918828\n",
      "Epoch: 64, Iter: 20480/100000, Loss: 0.0329553\n",
      "Epoch: 64, Iter: 30720/100000, Loss: 0.03193352\n",
      "Epoch: 64, Iter: 40960/100000, Loss: 0.032591477\n",
      "Epoch: 64, Iter: 51200/100000, Loss: 0.029663794\n",
      "Epoch: 64, Iter: 61440/100000, Loss: 0.03164317\n",
      "Epoch: 64, Iter: 71680/100000, Loss: 0.029688036\n",
      "Epoch: 64, Iter: 81920/100000, Loss: 0.036762986\n",
      "Epoch: 64, Iter: 92160/100000, Loss: 0.06397031\n",
      "Avg loss: 0.03879251381017498\n",
      "Epoch: 65, Iter: 10240/100000, Loss: 0.16966893\n",
      "Epoch: 65, Iter: 20480/100000, Loss: 0.0801068\n",
      "Epoch: 65, Iter: 30720/100000, Loss: 0.04991249\n",
      "Epoch: 65, Iter: 40960/100000, Loss: 0.09577255\n",
      "Epoch: 65, Iter: 51200/100000, Loss: 0.06726312\n",
      "Epoch: 65, Iter: 61440/100000, Loss: 0.06073131\n",
      "Epoch: 65, Iter: 71680/100000, Loss: 0.09414744\n",
      "Epoch: 65, Iter: 81920/100000, Loss: 0.6126542\n",
      "Epoch: 65, Iter: 92160/100000, Loss: 0.13697822\n",
      "Avg loss: 0.20191907364222192\n",
      "Epoch: 66, Iter: 10240/100000, Loss: 0.06832994\n",
      "Epoch: 66, Iter: 20480/100000, Loss: 0.07679764\n",
      "Epoch: 66, Iter: 30720/100000, Loss: 0.073164225\n",
      "Epoch: 66, Iter: 40960/100000, Loss: 0.06485274\n",
      "Epoch: 66, Iter: 51200/100000, Loss: 0.10842109\n",
      "Epoch: 66, Iter: 61440/100000, Loss: 0.110247284\n",
      "Epoch: 66, Iter: 71680/100000, Loss: 0.071248956\n",
      "Epoch: 66, Iter: 81920/100000, Loss: 0.077813804\n",
      "Epoch: 66, Iter: 92160/100000, Loss: 0.06461043\n",
      "Avg loss: 0.07932127432264004\n",
      "Epoch: 67, Iter: 10240/100000, Loss: 0.056548625\n",
      "Epoch: 67, Iter: 20480/100000, Loss: 0.055053964\n",
      "Epoch: 67, Iter: 30720/100000, Loss: 0.088884495\n",
      "Epoch: 67, Iter: 40960/100000, Loss: 0.059000917\n",
      "Epoch: 67, Iter: 51200/100000, Loss: 0.055046473\n",
      "Epoch: 67, Iter: 61440/100000, Loss: 0.054321162\n",
      "Epoch: 67, Iter: 71680/100000, Loss: 0.051029406\n",
      "Epoch: 67, Iter: 81920/100000, Loss: 0.05380317\n",
      "Epoch: 67, Iter: 92160/100000, Loss: 0.079454705\n",
      "Avg loss: 0.0649295536436371\n",
      "Epoch: 68, Iter: 10240/100000, Loss: 0.07403158\n",
      "Epoch: 68, Iter: 20480/100000, Loss: 0.068407945\n",
      "Epoch: 68, Iter: 30720/100000, Loss: 0.07834171\n",
      "Epoch: 68, Iter: 40960/100000, Loss: 0.085468724\n",
      "Epoch: 68, Iter: 51200/100000, Loss: 0.060691267\n",
      "Epoch: 68, Iter: 61440/100000, Loss: 0.04869465\n",
      "Epoch: 68, Iter: 71680/100000, Loss: 0.08390833\n",
      "Epoch: 68, Iter: 81920/100000, Loss: 0.059661034\n",
      "Epoch: 68, Iter: 92160/100000, Loss: 0.048683032\n",
      "Avg loss: 0.07117396681425497\n",
      "Epoch: 69, Iter: 10240/100000, Loss: 0.048692916\n",
      "Epoch: 69, Iter: 20480/100000, Loss: 0.059766583\n",
      "Epoch: 69, Iter: 30720/100000, Loss: 0.060551237\n",
      "Epoch: 69, Iter: 40960/100000, Loss: 0.067680456\n",
      "Epoch: 69, Iter: 51200/100000, Loss: 0.06519419\n",
      "Epoch: 69, Iter: 61440/100000, Loss: 0.052675273\n",
      "Epoch: 69, Iter: 71680/100000, Loss: 0.0610826\n",
      "Epoch: 69, Iter: 81920/100000, Loss: 0.09119849\n",
      "Epoch: 69, Iter: 92160/100000, Loss: 0.05266293\n",
      "Avg loss: 0.06106654907931987\n",
      "Epoch: 70, Iter: 10240/100000, Loss: 0.046486594\n",
      "Epoch: 70, Iter: 20480/100000, Loss: 0.050941188\n",
      "Epoch: 70, Iter: 30720/100000, Loss: 0.06275985\n",
      "Epoch: 70, Iter: 40960/100000, Loss: 0.057419382\n",
      "Epoch: 70, Iter: 51200/100000, Loss: 0.06109934\n",
      "Epoch: 70, Iter: 61440/100000, Loss: 0.05324996\n",
      "Epoch: 70, Iter: 71680/100000, Loss: 0.05273785\n",
      "Epoch: 70, Iter: 81920/100000, Loss: 0.054392263\n",
      "Epoch: 70, Iter: 92160/100000, Loss: 0.05177345\n",
      "Avg loss: 0.05489251067497067\n",
      "Epoch: 71, Iter: 10240/100000, Loss: 0.056913346\n",
      "Epoch: 71, Iter: 20480/100000, Loss: 0.0478213\n",
      "Epoch: 71, Iter: 30720/100000, Loss: 0.047146954\n",
      "Epoch: 71, Iter: 40960/100000, Loss: 0.070211604\n",
      "Epoch: 71, Iter: 51200/100000, Loss: 0.058404163\n",
      "Epoch: 71, Iter: 61440/100000, Loss: 0.067780636\n",
      "Epoch: 71, Iter: 71680/100000, Loss: 0.056434155\n",
      "Epoch: 71, Iter: 81920/100000, Loss: 0.049623698\n",
      "Epoch: 71, Iter: 92160/100000, Loss: 0.059133917\n",
      "Avg loss: 0.05912976462355594\n",
      "Epoch: 72, Iter: 10240/100000, Loss: 0.08010365\n",
      "Epoch: 72, Iter: 20480/100000, Loss: 0.049644314\n",
      "Epoch: 72, Iter: 30720/100000, Loss: 0.050261594\n",
      "Epoch: 72, Iter: 40960/100000, Loss: 0.048274275\n",
      "Epoch: 72, Iter: 51200/100000, Loss: 0.05535251\n",
      "Epoch: 72, Iter: 61440/100000, Loss: 0.049767684\n",
      "Epoch: 72, Iter: 71680/100000, Loss: 0.048259765\n",
      "Epoch: 72, Iter: 81920/100000, Loss: 0.05650793\n",
      "Epoch: 72, Iter: 92160/100000, Loss: 0.05035948\n",
      "Avg loss: 0.05379713238360956\n",
      "Epoch: 73, Iter: 10240/100000, Loss: 0.049097408\n",
      "Epoch: 73, Iter: 20480/100000, Loss: 0.048538215\n",
      "Epoch: 73, Iter: 30720/100000, Loss: 0.049335025\n",
      "Epoch: 73, Iter: 40960/100000, Loss: 0.047542613\n",
      "Epoch: 73, Iter: 51200/100000, Loss: 0.05272797\n",
      "Epoch: 73, Iter: 61440/100000, Loss: 0.052388456\n",
      "Epoch: 73, Iter: 71680/100000, Loss: 0.0490125\n",
      "Epoch: 73, Iter: 81920/100000, Loss: 0.046392784\n",
      "Epoch: 73, Iter: 92160/100000, Loss: 0.044705927\n",
      "Avg loss: 0.050159902609500685\n",
      "Epoch: 74, Iter: 10240/100000, Loss: 0.04596773\n",
      "Epoch: 74, Iter: 20480/100000, Loss: 0.043707386\n",
      "Epoch: 74, Iter: 30720/100000, Loss: 0.048008837\n",
      "Epoch: 74, Iter: 40960/100000, Loss: 0.045411415\n",
      "Epoch: 74, Iter: 51200/100000, Loss: 0.039973065\n",
      "Epoch: 74, Iter: 61440/100000, Loss: 0.03755061\n",
      "Epoch: 74, Iter: 71680/100000, Loss: 0.049337033\n",
      "Epoch: 74, Iter: 81920/100000, Loss: 0.25213563\n",
      "Epoch: 74, Iter: 92160/100000, Loss: 0.13718739\n",
      "Avg loss: 0.0785908494720754\n",
      "Epoch: 75, Iter: 10240/100000, Loss: 0.06754965\n",
      "Epoch: 75, Iter: 20480/100000, Loss: 0.06507924\n",
      "Epoch: 75, Iter: 30720/100000, Loss: 0.054068968\n",
      "Epoch: 75, Iter: 40960/100000, Loss: 0.05412589\n",
      "Epoch: 75, Iter: 51200/100000, Loss: 0.0576618\n",
      "Epoch: 75, Iter: 61440/100000, Loss: 0.05993724\n",
      "Epoch: 75, Iter: 71680/100000, Loss: 0.05324538\n",
      "Epoch: 75, Iter: 81920/100000, Loss: 0.055118054\n",
      "Epoch: 75, Iter: 92160/100000, Loss: 0.05000737\n",
      "Avg loss: 0.05833172798156738\n",
      "Epoch: 76, Iter: 10240/100000, Loss: 0.056074493\n",
      "Epoch: 76, Iter: 20480/100000, Loss: 0.048043452\n",
      "Epoch: 76, Iter: 30720/100000, Loss: 0.04999799\n",
      "Epoch: 76, Iter: 40960/100000, Loss: 0.053232316\n",
      "Epoch: 76, Iter: 51200/100000, Loss: 0.047899995\n",
      "Epoch: 76, Iter: 61440/100000, Loss: 0.06559516\n",
      "Epoch: 76, Iter: 71680/100000, Loss: 0.059306793\n",
      "Epoch: 76, Iter: 81920/100000, Loss: 0.059131265\n",
      "Epoch: 76, Iter: 92160/100000, Loss: 0.052087396\n",
      "Avg loss: 0.056031316979644225\n",
      "Epoch: 77, Iter: 10240/100000, Loss: 0.063016936\n",
      "Epoch: 77, Iter: 20480/100000, Loss: 0.05895522\n",
      "Epoch: 77, Iter: 30720/100000, Loss: 0.053913854\n",
      "Epoch: 77, Iter: 40960/100000, Loss: 0.050698426\n",
      "Epoch: 77, Iter: 51200/100000, Loss: 0.048852153\n",
      "Epoch: 77, Iter: 61440/100000, Loss: 0.051060293\n",
      "Epoch: 77, Iter: 71680/100000, Loss: 0.053400904\n",
      "Epoch: 77, Iter: 81920/100000, Loss: 0.053059213\n",
      "Epoch: 77, Iter: 92160/100000, Loss: 0.061777506\n",
      "Avg loss: 0.054930724434016906\n",
      "Epoch: 78, Iter: 10240/100000, Loss: 0.06102366\n",
      "Epoch: 78, Iter: 20480/100000, Loss: 0.06391774\n",
      "Epoch: 78, Iter: 30720/100000, Loss: 0.066359386\n",
      "Epoch: 78, Iter: 40960/100000, Loss: 0.05710874\n",
      "Epoch: 78, Iter: 51200/100000, Loss: 0.052523788\n",
      "Epoch: 78, Iter: 61440/100000, Loss: 0.0463242\n",
      "Epoch: 78, Iter: 71680/100000, Loss: 0.0496248\n",
      "Epoch: 78, Iter: 81920/100000, Loss: 0.04695426\n",
      "Epoch: 78, Iter: 92160/100000, Loss: 0.049662214\n",
      "Avg loss: 0.055155265807490986\n",
      "Epoch: 79, Iter: 10240/100000, Loss: 0.047189243\n",
      "Epoch: 79, Iter: 20480/100000, Loss: 0.057223827\n",
      "Epoch: 79, Iter: 30720/100000, Loss: 0.05727672\n",
      "Epoch: 79, Iter: 40960/100000, Loss: 0.05039306\n",
      "Epoch: 79, Iter: 51200/100000, Loss: 0.05307217\n",
      "Epoch: 79, Iter: 61440/100000, Loss: 0.061479807\n",
      "Epoch: 79, Iter: 71680/100000, Loss: 0.06213163\n",
      "Epoch: 79, Iter: 81920/100000, Loss: 0.04872916\n",
      "Epoch: 79, Iter: 92160/100000, Loss: 0.0492638\n",
      "Avg loss: 0.057379547160925325\n",
      "Epoch: 80, Iter: 10240/100000, Loss: 0.054154135\n",
      "Epoch: 80, Iter: 20480/100000, Loss: 0.049412668\n",
      "Epoch: 80, Iter: 30720/100000, Loss: 0.051062137\n",
      "Epoch: 80, Iter: 40960/100000, Loss: 0.05195588\n",
      "Epoch: 80, Iter: 51200/100000, Loss: 0.043758404\n",
      "Epoch: 80, Iter: 61440/100000, Loss: 0.08314136\n",
      "Epoch: 80, Iter: 71680/100000, Loss: 0.046722643\n",
      "Epoch: 80, Iter: 81920/100000, Loss: 0.043362074\n",
      "Epoch: 80, Iter: 92160/100000, Loss: 0.04447125\n",
      "Avg loss: 0.04723192409602637\n",
      "Epoch: 81, Iter: 10240/100000, Loss: 0.058535\n",
      "Epoch: 81, Iter: 20480/100000, Loss: 0.05361968\n",
      "Epoch: 81, Iter: 30720/100000, Loss: 0.058069095\n",
      "Epoch: 81, Iter: 40960/100000, Loss: 0.056391988\n",
      "Epoch: 81, Iter: 51200/100000, Loss: 0.050419554\n",
      "Epoch: 81, Iter: 61440/100000, Loss: 0.049649958\n",
      "Epoch: 81, Iter: 71680/100000, Loss: 0.05027576\n",
      "Epoch: 81, Iter: 81920/100000, Loss: 0.049085677\n",
      "Epoch: 81, Iter: 92160/100000, Loss: 0.04982256\n",
      "Avg loss: 0.05194871077678867\n",
      "Epoch: 82, Iter: 10240/100000, Loss: 0.04820206\n",
      "Epoch: 82, Iter: 20480/100000, Loss: 0.05470812\n",
      "Epoch: 82, Iter: 30720/100000, Loss: 0.047717012\n",
      "Epoch: 82, Iter: 40960/100000, Loss: 0.09104935\n",
      "Epoch: 82, Iter: 51200/100000, Loss: 0.058573708\n",
      "Epoch: 82, Iter: 61440/100000, Loss: 0.0534052\n",
      "Epoch: 82, Iter: 71680/100000, Loss: 0.06596846\n",
      "Epoch: 82, Iter: 81920/100000, Loss: 0.05658405\n",
      "Epoch: 82, Iter: 92160/100000, Loss: 0.08362794\n",
      "Avg loss: 0.05816859686651181\n",
      "Epoch: 83, Iter: 10240/100000, Loss: 0.048721347\n",
      "Epoch: 83, Iter: 20480/100000, Loss: 0.049968954\n",
      "Epoch: 83, Iter: 30720/100000, Loss: 0.04992327\n",
      "Epoch: 83, Iter: 40960/100000, Loss: 0.051885035\n",
      "Epoch: 83, Iter: 51200/100000, Loss: 0.042392783\n",
      "Epoch: 83, Iter: 61440/100000, Loss: 0.044409275\n",
      "Epoch: 83, Iter: 71680/100000, Loss: 0.0449454\n",
      "Epoch: 83, Iter: 81920/100000, Loss: 0.043565623\n",
      "Epoch: 83, Iter: 92160/100000, Loss: 0.050492574\n",
      "Avg loss: 0.051033310323339146\n",
      "Epoch: 84, Iter: 10240/100000, Loss: 0.0453784\n",
      "Epoch: 84, Iter: 20480/100000, Loss: 0.04671897\n",
      "Epoch: 84, Iter: 30720/100000, Loss: 0.046040963\n",
      "Epoch: 84, Iter: 40960/100000, Loss: 0.042446133\n",
      "Epoch: 84, Iter: 51200/100000, Loss: 0.05476057\n",
      "Epoch: 84, Iter: 61440/100000, Loss: 0.05195689\n",
      "Epoch: 84, Iter: 71680/100000, Loss: 0.04265337\n",
      "Epoch: 84, Iter: 81920/100000, Loss: 0.04284204\n",
      "Epoch: 84, Iter: 92160/100000, Loss: 0.040864587\n",
      "Avg loss: 0.04726540708203906\n",
      "Epoch: 85, Iter: 10240/100000, Loss: 0.0462022\n",
      "Epoch: 85, Iter: 20480/100000, Loss: 0.04252366\n",
      "Epoch: 85, Iter: 30720/100000, Loss: 0.04072566\n",
      "Epoch: 85, Iter: 40960/100000, Loss: 0.03648469\n",
      "Epoch: 85, Iter: 51200/100000, Loss: 0.03830617\n",
      "Epoch: 85, Iter: 61440/100000, Loss: 0.03340199\n",
      "Epoch: 85, Iter: 71680/100000, Loss: 0.04110611\n",
      "Epoch: 85, Iter: 81920/100000, Loss: 0.040031157\n",
      "Epoch: 85, Iter: 92160/100000, Loss: 0.036305714\n",
      "Avg loss: 0.039510219597939364\n",
      "Epoch: 86, Iter: 10240/100000, Loss: 0.038530733\n",
      "Epoch: 86, Iter: 20480/100000, Loss: 0.037695963\n",
      "Epoch: 86, Iter: 30720/100000, Loss: 0.03947813\n",
      "Epoch: 86, Iter: 40960/100000, Loss: 0.03393919\n",
      "Epoch: 86, Iter: 51200/100000, Loss: 0.042184107\n",
      "Epoch: 86, Iter: 61440/100000, Loss: 0.03444826\n",
      "Epoch: 86, Iter: 71680/100000, Loss: 0.03432856\n",
      "Epoch: 86, Iter: 81920/100000, Loss: 0.037646323\n",
      "Epoch: 86, Iter: 92160/100000, Loss: 0.034322534\n",
      "Avg loss: 0.0371379404491985\n",
      "Epoch: 87, Iter: 10240/100000, Loss: 0.03380023\n",
      "Epoch: 87, Iter: 20480/100000, Loss: 0.036636118\n",
      "Epoch: 87, Iter: 30720/100000, Loss: 0.041760415\n",
      "Epoch: 87, Iter: 40960/100000, Loss: 0.03676939\n",
      "Epoch: 87, Iter: 51200/100000, Loss: 0.035757028\n",
      "Epoch: 87, Iter: 61440/100000, Loss: 0.037644774\n",
      "Epoch: 87, Iter: 71680/100000, Loss: 0.033865094\n",
      "Epoch: 87, Iter: 81920/100000, Loss: 0.03303684\n",
      "Epoch: 87, Iter: 92160/100000, Loss: 0.03200177\n",
      "Avg loss: 0.03574035683473975\n",
      "Epoch: 88, Iter: 10240/100000, Loss: 0.03295975\n",
      "Epoch: 88, Iter: 20480/100000, Loss: 0.03373026\n",
      "Epoch: 88, Iter: 30720/100000, Loss: 0.035855483\n",
      "Epoch: 88, Iter: 40960/100000, Loss: 0.03420857\n",
      "Epoch: 88, Iter: 51200/100000, Loss: 0.031525206\n",
      "Epoch: 88, Iter: 61440/100000, Loss: 0.03174489\n",
      "Epoch: 88, Iter: 71680/100000, Loss: 0.035526443\n",
      "Epoch: 88, Iter: 81920/100000, Loss: 0.041547023\n",
      "Epoch: 88, Iter: 92160/100000, Loss: 0.03566703\n",
      "Avg loss: 0.03558058180299002\n",
      "Epoch: 89, Iter: 10240/100000, Loss: 0.03439096\n",
      "Epoch: 89, Iter: 20480/100000, Loss: 0.035276655\n",
      "Epoch: 89, Iter: 30720/100000, Loss: 0.03810627\n",
      "Epoch: 89, Iter: 40960/100000, Loss: 0.032595865\n",
      "Epoch: 89, Iter: 51200/100000, Loss: 0.029052496\n",
      "Epoch: 89, Iter: 61440/100000, Loss: 0.032834545\n",
      "Epoch: 89, Iter: 71680/100000, Loss: 0.030213807\n",
      "Epoch: 89, Iter: 81920/100000, Loss: 0.031679273\n",
      "Epoch: 89, Iter: 92160/100000, Loss: 0.033833906\n",
      "Avg loss: 0.03329677881730586\n",
      "Epoch: 90, Iter: 10240/100000, Loss: 0.041776896\n",
      "Epoch: 90, Iter: 20480/100000, Loss: 0.037462708\n",
      "Epoch: 90, Iter: 30720/100000, Loss: 0.032478184\n",
      "Epoch: 90, Iter: 40960/100000, Loss: 0.037230097\n",
      "Epoch: 90, Iter: 51200/100000, Loss: 0.030750945\n",
      "Epoch: 90, Iter: 61440/100000, Loss: 0.031136513\n",
      "Epoch: 90, Iter: 71680/100000, Loss: 0.031373493\n",
      "Epoch: 90, Iter: 81920/100000, Loss: 0.02928928\n",
      "Epoch: 90, Iter: 92160/100000, Loss: 0.030456781\n",
      "Avg loss: 0.03415461873501232\n",
      "Epoch: 91, Iter: 10240/100000, Loss: 0.028921116\n",
      "Epoch: 91, Iter: 20480/100000, Loss: 0.035794746\n",
      "Epoch: 91, Iter: 30720/100000, Loss: 0.03804723\n",
      "Epoch: 91, Iter: 40960/100000, Loss: 0.047836456\n",
      "Epoch: 91, Iter: 51200/100000, Loss: 0.036151607\n",
      "Epoch: 91, Iter: 61440/100000, Loss: 0.032242082\n",
      "Epoch: 91, Iter: 71680/100000, Loss: 0.032910127\n",
      "Epoch: 91, Iter: 81920/100000, Loss: 0.03292536\n",
      "Epoch: 91, Iter: 92160/100000, Loss: 0.030511003\n",
      "Avg loss: 0.033391849435481825\n",
      "Epoch: 92, Iter: 10240/100000, Loss: 0.029881906\n",
      "Epoch: 92, Iter: 20480/100000, Loss: 0.034227423\n",
      "Epoch: 92, Iter: 30720/100000, Loss: 0.03095818\n",
      "Epoch: 92, Iter: 40960/100000, Loss: 0.03141295\n",
      "Epoch: 92, Iter: 51200/100000, Loss: 0.033591233\n",
      "Epoch: 92, Iter: 61440/100000, Loss: 0.027928079\n",
      "Epoch: 92, Iter: 71680/100000, Loss: 0.03168541\n",
      "Epoch: 92, Iter: 81920/100000, Loss: 0.03082815\n",
      "Epoch: 92, Iter: 92160/100000, Loss: 0.029781235\n",
      "Avg loss: 0.03163223465923796\n",
      "Epoch: 93, Iter: 10240/100000, Loss: 0.03159917\n",
      "Epoch: 93, Iter: 20480/100000, Loss: 0.03392496\n",
      "Epoch: 93, Iter: 30720/100000, Loss: 0.034869593\n",
      "Epoch: 93, Iter: 40960/100000, Loss: 0.03126934\n",
      "Epoch: 93, Iter: 51200/100000, Loss: 0.031657565\n",
      "Epoch: 93, Iter: 61440/100000, Loss: 0.030511083\n",
      "Epoch: 93, Iter: 71680/100000, Loss: 0.03196587\n",
      "Epoch: 93, Iter: 81920/100000, Loss: 0.030499522\n",
      "Epoch: 93, Iter: 92160/100000, Loss: 0.033269532\n",
      "Avg loss: 0.031818157004326886\n",
      "Epoch: 94, Iter: 10240/100000, Loss: 0.030865828\n",
      "Epoch: 94, Iter: 20480/100000, Loss: 0.02955563\n",
      "Epoch: 94, Iter: 30720/100000, Loss: 0.033694655\n",
      "Epoch: 94, Iter: 40960/100000, Loss: 0.032900333\n",
      "Epoch: 94, Iter: 51200/100000, Loss: 0.03227446\n",
      "Epoch: 94, Iter: 61440/100000, Loss: 0.03126157\n",
      "Epoch: 94, Iter: 71680/100000, Loss: 0.03323297\n",
      "Epoch: 94, Iter: 81920/100000, Loss: 0.02990685\n",
      "Epoch: 94, Iter: 92160/100000, Loss: 0.032257386\n",
      "Avg loss: 0.031427113896178215\n",
      "Epoch: 95, Iter: 10240/100000, Loss: 0.030231494\n",
      "Epoch: 95, Iter: 20480/100000, Loss: 0.029673645\n",
      "Epoch: 95, Iter: 30720/100000, Loss: 0.028978266\n",
      "Epoch: 95, Iter: 40960/100000, Loss: 0.03068906\n",
      "Epoch: 95, Iter: 51200/100000, Loss: 0.029141448\n",
      "Epoch: 95, Iter: 61440/100000, Loss: 0.02780807\n",
      "Epoch: 95, Iter: 71680/100000, Loss: 0.029839749\n",
      "Epoch: 95, Iter: 81920/100000, Loss: 0.031195438\n",
      "Epoch: 95, Iter: 92160/100000, Loss: 0.033748403\n",
      "Avg loss: 0.030707195535609404\n",
      "Epoch: 96, Iter: 10240/100000, Loss: 0.03151819\n",
      "Epoch: 96, Iter: 20480/100000, Loss: 0.028455298\n",
      "Epoch: 96, Iter: 30720/100000, Loss: 0.032639634\n",
      "Epoch: 96, Iter: 40960/100000, Loss: 0.030330315\n",
      "Epoch: 96, Iter: 51200/100000, Loss: 0.028860405\n",
      "Epoch: 96, Iter: 61440/100000, Loss: 0.031670656\n",
      "Epoch: 96, Iter: 71680/100000, Loss: 0.030870255\n",
      "Epoch: 96, Iter: 81920/100000, Loss: 0.030400943\n",
      "Epoch: 96, Iter: 92160/100000, Loss: 0.031329468\n",
      "Avg loss: 0.030770102112563615\n",
      "Epoch: 97, Iter: 10240/100000, Loss: 0.02855118\n",
      "Epoch: 97, Iter: 20480/100000, Loss: 0.031494685\n",
      "Epoch: 97, Iter: 30720/100000, Loss: 0.030624626\n",
      "Epoch: 97, Iter: 40960/100000, Loss: 0.031727154\n",
      "Epoch: 97, Iter: 51200/100000, Loss: 0.029183311\n",
      "Epoch: 97, Iter: 61440/100000, Loss: 0.029394548\n",
      "Epoch: 97, Iter: 71680/100000, Loss: 0.028437968\n",
      "Epoch: 97, Iter: 81920/100000, Loss: 0.030256445\n",
      "Epoch: 97, Iter: 92160/100000, Loss: 0.031073619\n",
      "Avg loss: 0.03075697630182984\n",
      "Epoch: 98, Iter: 10240/100000, Loss: 0.03017883\n",
      "Epoch: 98, Iter: 20480/100000, Loss: 0.030889235\n",
      "Epoch: 98, Iter: 30720/100000, Loss: 0.030562144\n",
      "Epoch: 98, Iter: 40960/100000, Loss: 0.032139428\n",
      "Epoch: 98, Iter: 51200/100000, Loss: 0.02753453\n",
      "Epoch: 98, Iter: 61440/100000, Loss: 0.030050715\n",
      "Epoch: 98, Iter: 71680/100000, Loss: 0.032095034\n",
      "Epoch: 98, Iter: 81920/100000, Loss: 0.029709032\n",
      "Epoch: 98, Iter: 92160/100000, Loss: 0.031302355\n",
      "Avg loss: 0.030696793104109076\n",
      "Epoch: 99, Iter: 10240/100000, Loss: 0.027251812\n",
      "Epoch: 99, Iter: 20480/100000, Loss: 0.029544042\n",
      "Epoch: 99, Iter: 30720/100000, Loss: 0.030339528\n",
      "Epoch: 99, Iter: 40960/100000, Loss: 0.027169537\n",
      "Epoch: 99, Iter: 51200/100000, Loss: 0.028828505\n",
      "Epoch: 99, Iter: 61440/100000, Loss: 0.031472474\n",
      "Epoch: 99, Iter: 71680/100000, Loss: 0.031945437\n",
      "Epoch: 99, Iter: 81920/100000, Loss: 0.02958401\n",
      "Epoch: 99, Iter: 92160/100000, Loss: 0.028396126\n",
      "Avg loss: 0.030340766860652214\n",
      "Epoch: 100, Iter: 10240/100000, Loss: 0.030536175\n",
      "Epoch: 100, Iter: 20480/100000, Loss: 0.032382842\n",
      "Epoch: 100, Iter: 30720/100000, Loss: 0.027018704\n",
      "Epoch: 100, Iter: 40960/100000, Loss: 0.027923245\n",
      "Epoch: 100, Iter: 51200/100000, Loss: 0.03007308\n",
      "Epoch: 100, Iter: 61440/100000, Loss: 0.030464368\n",
      "Epoch: 100, Iter: 71680/100000, Loss: 0.028515853\n",
      "Epoch: 100, Iter: 81920/100000, Loss: 0.03186263\n",
      "Epoch: 100, Iter: 92160/100000, Loss: 0.030962566\n",
      "Avg loss: 0.030141792096888897\n"
     ]
    }
   ],
   "source": [
    "#Verbose after x batches\n",
    "VERBOSE =  10\n",
    "\n",
    "#Define number of epochs\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "println(\"Starting training...\")\n",
    "\n",
    "for i in 1:NUM_EPOCHS\n",
    "    \n",
    "    avg_loss = 0.0\n",
    "    it = 0\n",
    "    for  (k, (obs, action, next_obs)) in enumerate(dtrn)\n",
    "\n",
    "        #Train by using contrastive loss\n",
    "        J = @diff model(obs,action,next_obs)\n",
    "        \n",
    "        for par in params(model)\n",
    "            g = grad(J, par)\n",
    "            update!(value(par), g, par.opt)\n",
    "        end\n",
    "        \n",
    "        batch_size = size(obs,4)\n",
    "\n",
    "        if k % VERBOSE == 0\n",
    "            \n",
    "            println(\"Epoch: \", i , \", Iter: \" , k*batch_size, \"/\", dtrn.num_steps, \", Loss: \", value(J))\n",
    "\n",
    "        end\n",
    "        \n",
    "        avg_loss += value(J)\n",
    "        it = k\n",
    "        \n",
    "    end\n",
    "    \n",
    "    avg_loss /= it\n",
    "    \n",
    "    println(\"Avg loss: \" , avg_loss)\n",
    "end\n",
    "\n",
    "#dtrn = nothing\n",
    "#Knet.gc()\n",
    "#GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrn = nothing\n",
    "Knet.gc()\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Knet.save(\"model_2dshapes.jld2\", \"model\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Knet.load(\"model_2dshapes.jld2\", \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Params\n",
    "EVAL_DATASET_PATH = \"/home/cagan/dev/datasets/C-SWM/shapes_eval.h5\"\n",
    "EVAL_BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst = buildPathDataset(EVAL_DATASET_PATH, EVAL_BATCH_SIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, action,next_obs = first(dtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 batches\n",
      "Processed 20 batches\n",
      "Processed 30 batches\n",
      "Processed 40 batches\n",
      "Processed 50 batches\n",
      "Processed 60 batches\n",
      "Processed 70 batches\n",
      "Processed 80 batches\n",
      "Processed 90 batches\n",
      "Processed 100 batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000×10001 Array{Int64,2}:\n",
       " 1      2  8965  7190  6440  5990  …  8159  1743  6752  8857  7338  4951\n",
       " 1      3  9612  3738  2390  8390     8978  6776  3375  9555  8604   883\n",
       " 1      4  5277  1870  2475  8553     5061  4637  4265  4519  4821  7183\n",
       " 1      5  1189  3715  8081  6116     4769  2051  6642  7141  3900  5075\n",
       " 1      6  9560  4509  2771  6326      808  8877  8265   353  7263  3265\n",
       " 1      7  7404  9565   183  3358  …  3265  7580  6765  6642  6054  4643\n",
       " 1      8  5005   748  2635  5198     5759  1141  8589  1267  9708  1146\n",
       " 1      9  6304  5850  3592  5958     9118  8432  7093  3098  2735  4693\n",
       " 1     10  6050  4065  8034  1643     8000  9464  3297  6340  5301   392\n",
       " 1     11   495  7878  3159  4001     4258   786  4680  4218  6907  6898\n",
       " 1     12  2305  5498  6451  3559  …  2336  8681  2437  2796  2234  3390\n",
       " 1     13  7733  1995  1305  3850     3013  1425  5934   741  3802  2959\n",
       " 1     14  3446  8219  1219  3536     7690  5200  5555  5648  5767   612\n",
       " ⋮                              ⋮  ⋱     ⋮                             ⋮\n",
       " 1   9990  8551  9762  2563  9361     2330  8535  3914  1591  5823  7367\n",
       " 1   9991  2876  2373  9714  2454     3915  7804  7263  7141  6642  3265\n",
       " 1   9992   303  6327  5955  4188  …  2615  3098  4980  7354  2362  4693\n",
       " 1   9993  9073  2864  4370  1726      582  8579  6395   808   983  3463\n",
       " 1   9994   682  3831  1611  2136     2336  8496  3693  6423  9507  2796\n",
       " 1   9995   472  1200   585  4216     5236  4659  2040   346  1534  4193\n",
       " 1   9996  9557  3195  6205  2483     2027  8544  6733  3655  6723  9960\n",
       " 1   9997  5726  9374  3747   436  …  7338  4287  5898  4304  4193  5630\n",
       " 1   9998  9964  9852  1045  2716     9523  4720  2437  6907  2234  3390\n",
       " 1   9999  1318  1437  5569   977     6778  2476  1100  7716  9461  9768\n",
       " 1  10000  1176  4639  6420  6128     8052  4368  7119  7303  7103  2580\n",
       " 1  10001  6214  6895  8282  4331     8544  1615  3655  3013  7007  9867"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_states = Any[]\n",
    "next_states = Any[]\n",
    "\n",
    "num_samples = dtst.dataset_size\n",
    "\n",
    "for  (k, (obs, action, next_obs)) in enumerate(dtst)\n",
    "    \n",
    "    if k % 10 == 0\n",
    "        \n",
    "        println(\"Processed \", k ,\" batches\")\n",
    "        \n",
    "    end\n",
    "    #Obs => (50,50,3,100)\n",
    "    #Next obs => (50,50,3,100)\n",
    "    \n",
    "    pred_state = Array{Float32}(model(obs,action) + model(obs))\n",
    "    next_state = Array{Float32}(model(next_obs))\n",
    "    \n",
    "    #Pred-state => (2,5,100)\n",
    "    #Next state => (2,5,100)\n",
    "    #println(pred_state)\n",
    "    #println(next_state)\n",
    "    \n",
    "    push!(pred_states, pred_state)\n",
    "    push!(next_states, next_state)\n",
    "    \n",
    "end\n",
    "\n",
    "#Pred state cat => [2,5,10000]\n",
    "#Next state cat => [2,5,10000]\n",
    "pred_states = cat(pred_states...,dims=3)\n",
    "next_states = cat(next_states...,dims=3)\n",
    "    \n",
    "#Flatten object/feature dimensions\n",
    "pred_states = mat(pred_states)  #[10,10000]\n",
    "next_states = mat(next_states)  #[10,10000]\n",
    "\n",
    "#Calculate pairwise distances\n",
    "sizes_1 = (size(pred_states)...,1)\n",
    "sizes_2 = (sizes_1[1], sizes_1[3], sizes_1[2])\n",
    "\n",
    "pred_states = reshape(pred_states, sizes_1)\n",
    "next_states = reshape(next_states, sizes_2)\n",
    "pred_states = repeat(pred_states, outer=[1,1,10000])\n",
    "next_states = repeat(next_states, outer=[1,10000,1])\n",
    "\n",
    "pairwise_distance_matrix = sum((pred_states - next_states).^2, dims=1)[1,:,:]\n",
    "\n",
    "#Augment pairwise distance matrix\n",
    "diag_elements = diag(pairwise_distance_matrix)\n",
    "pairwise_distance_matrix = hcat(diag_elements, pairwise_distance_matrix)\n",
    "\n",
    "\n",
    "labels = ones(num_samples)\n",
    "hits_at_1 = 0\n",
    "\n",
    "indices = []\n",
    "\n",
    "for i=1:10000\n",
    "    \n",
    "    row = pairwise_distance_matrix[i,:]\n",
    "    ind = sortperm(row)\n",
    "    \n",
    "    push!(indices, ind)\n",
    "\n",
    "end\n",
    "\n",
    "indices = vcat(indices'...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits @ 1: 0.9997\n"
     ]
    }
   ],
   "source": [
    "num_matches = sum(labels .== indices[:,1])\n",
    "hits_at_1 += num_matches\n",
    "println(\"Hits @ 1: \", hits_at_1/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.99985\n"
     ]
    }
   ],
   "source": [
    "mxval, mxindx = findmax(indices .== labels,dims=2)\n",
    "ranks = [ i[2] for i in mxindx ]\n",
    "reciprocal_ranks = 1 ./ranks\n",
    "rr_sum = sum(reciprocal_ranks)\n",
    "println(\"MRR: \", rr_sum/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
