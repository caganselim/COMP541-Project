{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C-SWM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libs\n",
    "import Base: iterate, length, GC\n",
    "using HDF5\n",
    "using Knet\n",
    "using Statistics: mean,std\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using Images\n",
    "using Plots\n",
    "\n",
    "#Datatype\n",
    "atype=KnetArray{Float32}\n",
    "\n",
    "#Includes\n",
    "include(\"datasets.jl\")\n",
    "include(\"cswm.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Params\n",
    "input_ch = 3\n",
    "hidden_dim = 512\n",
    "num_objects = 5\n",
    "embedding_dim = 2\n",
    "action_dim = 4\n",
    "sigma = 0.5\n",
    "hinge = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MersenneTwister(UInt32[0x0000002a], Random.DSFMT.DSFMT_state(Int32[964434469, 1073036706, 1860149520, 1073503458, 1687169063, 1073083486, -399267803, 1072983952, -909620556, 1072836235  …  -293054293, 1073002412, -1300127419, 1073642642, 1917177374, -666058738, -337596527, 1830741494, 382, 0]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], UInt128[0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000  …  0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000], 1002, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knet.seed!(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContrastiveSWM(EncoderCNNSmall(Any[P(KnetArray{Float32,4}(10,10,3,32)), P(KnetArray{Float32,4}(1,1,32,5))], Any[P(KnetArray{Float32,4}(1,1,32,1)), P(KnetArray{Float32,4}(1,1,5,1))], Any[Knet.BNMoments(0.1, nothing, nothing, zeros, ones), K32(64)[1.0⋯]], Knet.sigm, NNlib.relu), EncoderMLP(Param{KnetArray{Float32,2}}[P(KnetArray{Float32,2}(512,25)), P(KnetArray{Float32,2}(512,512)), P(KnetArray{Float32,2}(2,512))], Param{KnetArray{Float32,1}}[P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(2))], LayerNorm(P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), 1.0e-5), NNlib.relu), TransitionGNN(EdgeMLP(Param{KnetArray{Float32,2}}[P(KnetArray{Float32,2}(512,4)), P(KnetArray{Float32,2}(512,512)), P(KnetArray{Float32,2}(512,512))], Param{KnetArray{Float32,1}}[P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512))], LayerNorm(P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), 1.0e-5), NNlib.relu), NodeMLP(Param{KnetArray{Float32,2}}[P(KnetArray{Float32,2}(512,518)), P(KnetArray{Float32,2}(512,512)), P(KnetArray{Float32,2}(2,512))], Param{KnetArray{Float32,1}}[P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(2))], LayerNorm(P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), 1.0e-5), NNlib.relu), false, false, 4, 2, nothing, 0), 0.5, 1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = initContrastiveSWMSmall(input_ch, hidden_dim, num_objects, embedding_dim, action_dim, sigma, hinge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Building dataset indexing...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATASET_PATH = \"/home/cagan/dev/datasets/C-SWM/shapes_train.h5\"\n",
    "TRAIN_BATCH_SIZE = 1024\n",
    "dtrn = buildStateTransitionDataset(TRAIN_DATASET_PATH, true, TRAIN_BATCH_SIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(KnetArray{Float32,4}(10,10,3,32))\n",
      "P(KnetArray{Float32,4}(1,1,32,5))\n",
      "P(KnetArray{Float32,4}(1,1,32,1))\n",
      "P(KnetArray{Float32,4}(1,1,5,1))\n",
      "P(KnetArray{Float32,2}(512,25))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,2}(2,512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(2))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,2}(512,4))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,2}(512,518))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,2}(2,512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(2))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n"
     ]
    }
   ],
   "source": [
    "function initopt!(model::ContrastiveSWM)\n",
    "    \n",
    "    for par in params(model)\n",
    "        par.opt = Adam(;lr=0.0005, gclip=0, beta1=0.9, beta2=0.999, eps=1e-8)\n",
    "        println(par)\n",
    "    end\n",
    "    end;\n",
    "initopt!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch: 1, Iter: 10240/100000, Loss: 0.42359978\n",
      "Epoch: 1, Iter: 20480/100000, Loss: 0.29025236\n",
      "Epoch: 1, Iter: 30720/100000, Loss: 0.20908357\n",
      "Epoch: 1, Iter: 40960/100000, Loss: 0.1706932\n",
      "Epoch: 1, Iter: 51200/100000, Loss: 0.1359646\n",
      "Epoch: 1, Iter: 61440/100000, Loss: 0.11933155\n",
      "Epoch: 1, Iter: 71680/100000, Loss: 0.11124304\n",
      "Epoch: 1, Iter: 81920/100000, Loss: 0.10445408\n",
      "Epoch: 1, Iter: 92160/100000, Loss: 0.09699994\n",
      "Avg loss: 0.5315361105136036\n",
      "Epoch: 2, Iter: 10240/100000, Loss: 0.09638713\n",
      "Epoch: 2, Iter: 20480/100000, Loss: 0.08142391\n",
      "Epoch: 2, Iter: 30720/100000, Loss: 0.075552\n",
      "Epoch: 2, Iter: 40960/100000, Loss: 0.074401855\n",
      "Epoch: 2, Iter: 51200/100000, Loss: 0.07540923\n",
      "Epoch: 2, Iter: 61440/100000, Loss: 0.06868971\n",
      "Epoch: 2, Iter: 71680/100000, Loss: 0.0648802\n",
      "Epoch: 2, Iter: 81920/100000, Loss: 0.068197325\n",
      "Epoch: 2, Iter: 92160/100000, Loss: 0.06900366\n",
      "Avg loss: 0.07468998228612635\n",
      "Epoch: 3, Iter: 10240/100000, Loss: 0.06557751\n",
      "Epoch: 3, Iter: 20480/100000, Loss: 0.06632106\n",
      "Epoch: 3, Iter: 30720/100000, Loss: 0.06359562\n",
      "Epoch: 3, Iter: 40960/100000, Loss: 0.063659824\n",
      "Epoch: 3, Iter: 51200/100000, Loss: 0.06303771\n",
      "Epoch: 3, Iter: 61440/100000, Loss: 0.06238798\n",
      "Epoch: 3, Iter: 71680/100000, Loss: 0.060923044\n",
      "Epoch: 3, Iter: 81920/100000, Loss: 0.065012924\n",
      "Epoch: 3, Iter: 92160/100000, Loss: 0.06024851\n",
      "Avg loss: 0.06462896265780803\n",
      "Epoch: 4, Iter: 10240/100000, Loss: 0.0577372\n",
      "Epoch: 4, Iter: 20480/100000, Loss: 0.06334135\n",
      "Epoch: 4, Iter: 30720/100000, Loss: 0.05390661\n",
      "Epoch: 4, Iter: 40960/100000, Loss: 0.05985088\n",
      "Epoch: 4, Iter: 51200/100000, Loss: 0.057864845\n",
      "Epoch: 4, Iter: 61440/100000, Loss: 0.052650757\n",
      "Epoch: 4, Iter: 71680/100000, Loss: 0.060493752\n",
      "Epoch: 4, Iter: 81920/100000, Loss: 0.056457542\n",
      "Epoch: 4, Iter: 92160/100000, Loss: 0.056466006\n",
      "Avg loss: 0.05876209099114556\n",
      "Epoch: 5, Iter: 10240/100000, Loss: 0.053344812\n",
      "Epoch: 5, Iter: 20480/100000, Loss: 0.05643429\n",
      "Epoch: 5, Iter: 30720/100000, Loss: 0.05822654\n",
      "Epoch: 5, Iter: 40960/100000, Loss: 0.054782033\n",
      "Epoch: 5, Iter: 51200/100000, Loss: 0.055968504\n",
      "Epoch: 5, Iter: 61440/100000, Loss: 0.04998087\n",
      "Epoch: 5, Iter: 71680/100000, Loss: 0.053341914\n",
      "Epoch: 5, Iter: 81920/100000, Loss: 0.04741239\n",
      "Epoch: 5, Iter: 92160/100000, Loss: 0.045790497\n",
      "Avg loss: 0.05157847648736128\n",
      "Epoch: 6, Iter: 10240/100000, Loss: 0.049176667\n",
      "Epoch: 6, Iter: 20480/100000, Loss: 0.043896936\n",
      "Epoch: 6, Iter: 30720/100000, Loss: 0.046557993\n",
      "Epoch: 6, Iter: 40960/100000, Loss: 0.047725935\n",
      "Epoch: 6, Iter: 51200/100000, Loss: 0.056266956\n",
      "Epoch: 6, Iter: 61440/100000, Loss: 0.047862425\n",
      "Epoch: 6, Iter: 71680/100000, Loss: 0.048406973\n",
      "Epoch: 6, Iter: 81920/100000, Loss: 0.043937877\n",
      "Epoch: 6, Iter: 92160/100000, Loss: 0.043004192\n",
      "Avg loss: 0.04763546701251846\n",
      "Epoch: 7, Iter: 10240/100000, Loss: 0.04339915\n",
      "Epoch: 7, Iter: 20480/100000, Loss: 0.04789818\n",
      "Epoch: 7, Iter: 30720/100000, Loss: 0.048273526\n",
      "Epoch: 7, Iter: 40960/100000, Loss: 0.0415762\n",
      "Epoch: 7, Iter: 51200/100000, Loss: 0.04545997\n",
      "Epoch: 7, Iter: 61440/100000, Loss: 0.041969724\n",
      "Epoch: 7, Iter: 71680/100000, Loss: 0.045003884\n",
      "Epoch: 7, Iter: 81920/100000, Loss: 0.04041748\n",
      "Epoch: 7, Iter: 92160/100000, Loss: 0.04406766\n",
      "Avg loss: 0.042525574027263015\n",
      "Epoch: 8, Iter: 10240/100000, Loss: 0.03953701\n",
      "Epoch: 8, Iter: 20480/100000, Loss: 0.04213915\n",
      "Epoch: 8, Iter: 30720/100000, Loss: 0.043997485\n",
      "Epoch: 8, Iter: 40960/100000, Loss: 0.043433487\n",
      "Epoch: 8, Iter: 51200/100000, Loss: 0.036024712\n",
      "Epoch: 8, Iter: 61440/100000, Loss: 0.038953137\n",
      "Epoch: 8, Iter: 71680/100000, Loss: 0.045431904\n",
      "Epoch: 8, Iter: 81920/100000, Loss: 0.041298002\n",
      "Epoch: 8, Iter: 92160/100000, Loss: 0.039133146\n",
      "Avg loss: 0.04101454270715566\n",
      "Epoch: 9, Iter: 10240/100000, Loss: 0.045619927\n",
      "Epoch: 9, Iter: 20480/100000, Loss: 0.045235924\n",
      "Epoch: 9, Iter: 30720/100000, Loss: 0.037399974\n",
      "Epoch: 9, Iter: 40960/100000, Loss: 0.038553856\n",
      "Epoch: 9, Iter: 51200/100000, Loss: 0.039933026\n",
      "Epoch: 9, Iter: 61440/100000, Loss: 0.035167653\n",
      "Epoch: 9, Iter: 71680/100000, Loss: 0.04332993\n",
      "Epoch: 9, Iter: 81920/100000, Loss: 0.03604754\n",
      "Epoch: 9, Iter: 92160/100000, Loss: 0.03930593\n",
      "Avg loss: 0.0399673817314438\n",
      "Epoch: 10, Iter: 10240/100000, Loss: 0.037192203\n",
      "Epoch: 10, Iter: 20480/100000, Loss: 0.038191233\n",
      "Epoch: 10, Iter: 30720/100000, Loss: 0.040423185\n",
      "Epoch: 10, Iter: 40960/100000, Loss: 0.03809683\n",
      "Epoch: 10, Iter: 51200/100000, Loss: 0.041050524\n",
      "Epoch: 10, Iter: 61440/100000, Loss: 0.039768264\n",
      "Epoch: 10, Iter: 71680/100000, Loss: 0.040890932\n",
      "Epoch: 10, Iter: 81920/100000, Loss: 0.040018506\n",
      "Epoch: 10, Iter: 92160/100000, Loss: 0.04170292\n",
      "Avg loss: 0.03925622028020239\n",
      "Epoch: 11, Iter: 10240/100000, Loss: 0.043978374\n",
      "Epoch: 11, Iter: 20480/100000, Loss: 0.041238934\n",
      "Epoch: 11, Iter: 30720/100000, Loss: 0.038439892\n",
      "Epoch: 11, Iter: 40960/100000, Loss: 0.040662237\n",
      "Epoch: 11, Iter: 51200/100000, Loss: 0.039649926\n",
      "Epoch: 11, Iter: 61440/100000, Loss: 0.037763152\n",
      "Epoch: 11, Iter: 71680/100000, Loss: 0.039781734\n",
      "Epoch: 11, Iter: 81920/100000, Loss: 0.030839553\n",
      "Epoch: 11, Iter: 92160/100000, Loss: 0.04174784\n",
      "Avg loss: 0.03997607869048094\n",
      "Epoch: 12, Iter: 10240/100000, Loss: 0.038694482\n",
      "Epoch: 12, Iter: 20480/100000, Loss: 0.038920056\n",
      "Epoch: 12, Iter: 30720/100000, Loss: 0.037777405\n",
      "Epoch: 12, Iter: 40960/100000, Loss: 0.038589727\n",
      "Epoch: 12, Iter: 51200/100000, Loss: 0.03830213\n",
      "Epoch: 12, Iter: 61440/100000, Loss: 0.037654247\n",
      "Epoch: 12, Iter: 71680/100000, Loss: 0.043029804\n",
      "Epoch: 12, Iter: 81920/100000, Loss: 0.036156148\n",
      "Epoch: 12, Iter: 92160/100000, Loss: 0.037332647\n",
      "Avg loss: 0.037608933241404206\n",
      "Epoch: 13, Iter: 10240/100000, Loss: 0.031661537\n",
      "Epoch: 13, Iter: 20480/100000, Loss: 0.03803663\n",
      "Epoch: 13, Iter: 30720/100000, Loss: 0.03453387\n",
      "Epoch: 13, Iter: 40960/100000, Loss: 0.03736753\n",
      "Epoch: 13, Iter: 51200/100000, Loss: 0.03654173\n",
      "Epoch: 13, Iter: 61440/100000, Loss: 0.0330683\n",
      "Epoch: 13, Iter: 71680/100000, Loss: 0.038798798\n",
      "Epoch: 13, Iter: 81920/100000, Loss: 0.034185216\n",
      "Epoch: 13, Iter: 92160/100000, Loss: 0.035132043\n",
      "Avg loss: 0.03621961093824549\n",
      "Epoch: 14, Iter: 10240/100000, Loss: 0.034350842\n",
      "Epoch: 14, Iter: 20480/100000, Loss: 0.040779047\n",
      "Epoch: 14, Iter: 30720/100000, Loss: 0.036778927\n",
      "Epoch: 14, Iter: 40960/100000, Loss: 0.03744329\n",
      "Epoch: 14, Iter: 51200/100000, Loss: 0.036560677\n",
      "Epoch: 14, Iter: 61440/100000, Loss: 0.037057348\n",
      "Epoch: 14, Iter: 71680/100000, Loss: 0.040038437\n",
      "Epoch: 14, Iter: 81920/100000, Loss: 0.036557768\n",
      "Epoch: 14, Iter: 92160/100000, Loss: 0.036939457\n",
      "Avg loss: 0.03547166462642016\n",
      "Epoch: 15, Iter: 10240/100000, Loss: 0.032671586\n",
      "Epoch: 15, Iter: 20480/100000, Loss: 0.037673954\n",
      "Epoch: 15, Iter: 30720/100000, Loss: 0.031284932\n",
      "Epoch: 15, Iter: 40960/100000, Loss: 0.033818763\n",
      "Epoch: 15, Iter: 51200/100000, Loss: 0.034888238\n",
      "Epoch: 15, Iter: 61440/100000, Loss: 0.032038216\n",
      "Epoch: 15, Iter: 71680/100000, Loss: 0.037921093\n",
      "Epoch: 15, Iter: 81920/100000, Loss: 0.03589234\n",
      "Epoch: 15, Iter: 92160/100000, Loss: 0.029260876\n",
      "Avg loss: 0.034230695979804104\n",
      "Epoch: 16, Iter: 10240/100000, Loss: 0.036806915\n",
      "Epoch: 16, Iter: 20480/100000, Loss: 0.032745752\n",
      "Epoch: 16, Iter: 30720/100000, Loss: 0.031245474\n",
      "Epoch: 16, Iter: 40960/100000, Loss: 0.03424337\n",
      "Epoch: 16, Iter: 51200/100000, Loss: 0.03672644\n",
      "Epoch: 16, Iter: 61440/100000, Loss: 0.035374887\n",
      "Epoch: 16, Iter: 71680/100000, Loss: 0.039142482\n",
      "Epoch: 16, Iter: 81920/100000, Loss: 0.034678664\n",
      "Epoch: 16, Iter: 92160/100000, Loss: 0.03805752\n",
      "Avg loss: 0.03396095364287342\n",
      "Epoch: 17, Iter: 10240/100000, Loss: 0.031706385\n",
      "Epoch: 17, Iter: 20480/100000, Loss: 0.03470666\n",
      "Epoch: 17, Iter: 30720/100000, Loss: 0.031494156\n",
      "Epoch: 17, Iter: 40960/100000, Loss: 0.03648895\n",
      "Epoch: 17, Iter: 51200/100000, Loss: 0.033364996\n",
      "Epoch: 17, Iter: 61440/100000, Loss: 0.03062769\n",
      "Epoch: 17, Iter: 71680/100000, Loss: 0.037873436\n",
      "Epoch: 17, Iter: 81920/100000, Loss: 0.03352166\n",
      "Epoch: 17, Iter: 92160/100000, Loss: 0.031553388\n",
      "Avg loss: 0.033731138756133844\n",
      "Epoch: 18, Iter: 10240/100000, Loss: 0.027907465\n",
      "Epoch: 18, Iter: 20480/100000, Loss: 0.030265974\n",
      "Epoch: 18, Iter: 30720/100000, Loss: 0.031505793\n",
      "Epoch: 18, Iter: 40960/100000, Loss: 0.029473018\n",
      "Epoch: 18, Iter: 51200/100000, Loss: 0.03435396\n",
      "Epoch: 18, Iter: 61440/100000, Loss: 0.031613156\n",
      "Epoch: 18, Iter: 71680/100000, Loss: 0.035328377\n",
      "Epoch: 18, Iter: 81920/100000, Loss: 0.035889566\n",
      "Epoch: 18, Iter: 92160/100000, Loss: 0.030368894\n",
      "Avg loss: 0.03280090709629747\n",
      "Epoch: 19, Iter: 10240/100000, Loss: 0.031798825\n",
      "Epoch: 19, Iter: 20480/100000, Loss: 0.031107016\n",
      "Epoch: 19, Iter: 30720/100000, Loss: 0.031480346\n",
      "Epoch: 19, Iter: 40960/100000, Loss: 0.032937318\n",
      "Epoch: 19, Iter: 51200/100000, Loss: 0.029728094\n",
      "Epoch: 19, Iter: 61440/100000, Loss: 0.033330455\n",
      "Epoch: 19, Iter: 71680/100000, Loss: 0.03466438\n",
      "Epoch: 19, Iter: 81920/100000, Loss: 0.031679094\n",
      "Epoch: 19, Iter: 92160/100000, Loss: 0.035675596\n",
      "Avg loss: 0.031936689231967186\n",
      "Epoch: 20, Iter: 10240/100000, Loss: 0.03032662\n",
      "Epoch: 20, Iter: 20480/100000, Loss: 0.032044735\n",
      "Epoch: 20, Iter: 30720/100000, Loss: 0.029801277\n",
      "Epoch: 20, Iter: 40960/100000, Loss: 0.02720626\n",
      "Epoch: 20, Iter: 51200/100000, Loss: 0.032697078\n",
      "Epoch: 20, Iter: 61440/100000, Loss: 0.028504238\n",
      "Epoch: 20, Iter: 71680/100000, Loss: 0.032411277\n",
      "Epoch: 20, Iter: 81920/100000, Loss: 0.032476455\n",
      "Epoch: 20, Iter: 92160/100000, Loss: 0.030346807\n",
      "Avg loss: 0.031153991703212876\n",
      "Epoch: 21, Iter: 10240/100000, Loss: 0.03217429\n",
      "Epoch: 21, Iter: 20480/100000, Loss: 0.036247946\n",
      "Epoch: 21, Iter: 30720/100000, Loss: 0.036536854\n",
      "Epoch: 21, Iter: 40960/100000, Loss: 0.027766215\n",
      "Epoch: 21, Iter: 51200/100000, Loss: 0.030247696\n",
      "Epoch: 21, Iter: 61440/100000, Loss: 0.028363781\n",
      "Epoch: 21, Iter: 71680/100000, Loss: 0.036390267\n",
      "Epoch: 21, Iter: 81920/100000, Loss: 0.1004203\n",
      "Epoch: 21, Iter: 92160/100000, Loss: 0.048754\n",
      "Avg loss: 0.038550188169651424\n",
      "Epoch: 22, Iter: 10240/100000, Loss: 0.039045252\n",
      "Epoch: 22, Iter: 20480/100000, Loss: 0.04007651\n",
      "Epoch: 22, Iter: 30720/100000, Loss: 0.03196004\n",
      "Epoch: 22, Iter: 40960/100000, Loss: 0.03722792\n",
      "Epoch: 22, Iter: 51200/100000, Loss: 0.04419945\n",
      "Epoch: 22, Iter: 61440/100000, Loss: 0.037259124\n",
      "Epoch: 22, Iter: 71680/100000, Loss: 0.0347332\n",
      "Epoch: 22, Iter: 81920/100000, Loss: 0.032928076\n",
      "Epoch: 22, Iter: 92160/100000, Loss: 0.02869322\n",
      "Avg loss: 0.036249157022108736\n",
      "Epoch: 23, Iter: 10240/100000, Loss: 0.030471433\n",
      "Epoch: 23, Iter: 20480/100000, Loss: 0.030912729\n",
      "Epoch: 23, Iter: 30720/100000, Loss: 0.033759736\n",
      "Epoch: 23, Iter: 40960/100000, Loss: 0.036065817\n",
      "Epoch: 23, Iter: 51200/100000, Loss: 0.036119536\n",
      "Epoch: 23, Iter: 61440/100000, Loss: 0.034827746\n",
      "Epoch: 23, Iter: 71680/100000, Loss: 0.03050083\n",
      "Epoch: 23, Iter: 81920/100000, Loss: 0.03444569\n",
      "Epoch: 23, Iter: 92160/100000, Loss: 0.030747231\n",
      "Avg loss: 0.03289976625789687\n",
      "Epoch: 24, Iter: 10240/100000, Loss: 0.030338662\n",
      "Epoch: 24, Iter: 20480/100000, Loss: 0.035141617\n",
      "Epoch: 24, Iter: 30720/100000, Loss: 0.028319519\n",
      "Epoch: 24, Iter: 40960/100000, Loss: 0.03055382\n",
      "Epoch: 24, Iter: 51200/100000, Loss: 0.030709548\n",
      "Epoch: 24, Iter: 61440/100000, Loss: 0.034199703\n",
      "Epoch: 24, Iter: 71680/100000, Loss: 0.033440016\n",
      "Epoch: 24, Iter: 81920/100000, Loss: 0.031354167\n",
      "Epoch: 24, Iter: 92160/100000, Loss: 0.035351425\n",
      "Avg loss: 0.0315853334464056\n",
      "Epoch: 25, Iter: 10240/100000, Loss: 0.028837636\n",
      "Epoch: 25, Iter: 20480/100000, Loss: 0.03564924\n",
      "Epoch: 25, Iter: 30720/100000, Loss: 0.030934248\n",
      "Epoch: 25, Iter: 40960/100000, Loss: 0.03727099\n",
      "Epoch: 25, Iter: 51200/100000, Loss: 0.028624136\n",
      "Epoch: 25, Iter: 61440/100000, Loss: 0.032111768\n",
      "Epoch: 25, Iter: 71680/100000, Loss: 0.03467609\n",
      "Epoch: 25, Iter: 81920/100000, Loss: 0.0338006\n",
      "Epoch: 25, Iter: 92160/100000, Loss: 0.031644486\n",
      "Avg loss: 0.030635919575531457\n",
      "Epoch: 26, Iter: 10240/100000, Loss: 0.02880999\n",
      "Epoch: 26, Iter: 20480/100000, Loss: 0.029571513\n",
      "Epoch: 26, Iter: 30720/100000, Loss: 0.023585636\n",
      "Epoch: 26, Iter: 40960/100000, Loss: 0.031535313\n",
      "Epoch: 26, Iter: 51200/100000, Loss: 0.032536678\n",
      "Epoch: 26, Iter: 61440/100000, Loss: 0.031938404\n",
      "Epoch: 26, Iter: 71680/100000, Loss: 0.033088095\n",
      "Epoch: 26, Iter: 81920/100000, Loss: 0.029809512\n",
      "Epoch: 26, Iter: 92160/100000, Loss: 0.03174916\n",
      "Avg loss: 0.030191882196621795\n",
      "Epoch: 27, Iter: 10240/100000, Loss: 0.028655551\n",
      "Epoch: 27, Iter: 20480/100000, Loss: 0.028776933\n",
      "Epoch: 27, Iter: 30720/100000, Loss: 0.028553389\n",
      "Epoch: 27, Iter: 40960/100000, Loss: 0.029776549\n",
      "Epoch: 27, Iter: 51200/100000, Loss: 0.03140789\n",
      "Epoch: 27, Iter: 61440/100000, Loss: 0.029190686\n",
      "Epoch: 27, Iter: 71680/100000, Loss: 0.02774546\n",
      "Epoch: 27, Iter: 81920/100000, Loss: 0.030174721\n",
      "Epoch: 27, Iter: 92160/100000, Loss: 0.031445496\n",
      "Avg loss: 0.0294677031984956\n",
      "Epoch: 28, Iter: 10240/100000, Loss: 0.02973967\n",
      "Epoch: 28, Iter: 20480/100000, Loss: 0.0265642\n",
      "Epoch: 28, Iter: 30720/100000, Loss: 0.027623678\n",
      "Epoch: 28, Iter: 40960/100000, Loss: 0.029494226\n",
      "Epoch: 28, Iter: 51200/100000, Loss: 0.03184004\n",
      "Epoch: 28, Iter: 61440/100000, Loss: 0.030670825\n",
      "Epoch: 28, Iter: 71680/100000, Loss: 0.02757201\n",
      "Epoch: 28, Iter: 81920/100000, Loss: 0.029035857\n",
      "Epoch: 28, Iter: 92160/100000, Loss: 0.031585068\n",
      "Avg loss: 0.029413177257346122\n",
      "Epoch: 29, Iter: 10240/100000, Loss: 0.027812757\n",
      "Epoch: 29, Iter: 20480/100000, Loss: 0.033029675\n",
      "Epoch: 29, Iter: 30720/100000, Loss: 0.028138284\n",
      "Epoch: 29, Iter: 40960/100000, Loss: 0.029927015\n",
      "Epoch: 29, Iter: 51200/100000, Loss: 0.031550135\n",
      "Epoch: 29, Iter: 61440/100000, Loss: 0.027283192\n",
      "Epoch: 29, Iter: 71680/100000, Loss: 0.025203342\n",
      "Epoch: 29, Iter: 81920/100000, Loss: 0.025962375\n",
      "Epoch: 29, Iter: 92160/100000, Loss: 0.028095186\n",
      "Avg loss: 0.02864098798522015\n",
      "Epoch: 30, Iter: 10240/100000, Loss: 0.026475765\n",
      "Epoch: 30, Iter: 20480/100000, Loss: 0.026000902\n",
      "Epoch: 30, Iter: 30720/100000, Loss: 0.026379894\n",
      "Epoch: 30, Iter: 40960/100000, Loss: 0.028971944\n",
      "Epoch: 30, Iter: 51200/100000, Loss: 0.02685273\n",
      "Epoch: 30, Iter: 61440/100000, Loss: 0.02708929\n",
      "Epoch: 30, Iter: 71680/100000, Loss: 0.027582347\n",
      "Epoch: 30, Iter: 81920/100000, Loss: 0.026650747\n",
      "Epoch: 30, Iter: 92160/100000, Loss: 0.028470844\n",
      "Avg loss: 0.027433210177366267\n",
      "Epoch: 31, Iter: 10240/100000, Loss: 0.027337795\n",
      "Epoch: 31, Iter: 20480/100000, Loss: 0.026218683\n",
      "Epoch: 31, Iter: 30720/100000, Loss: 0.027442764\n",
      "Epoch: 31, Iter: 40960/100000, Loss: 0.02874292\n",
      "Epoch: 31, Iter: 51200/100000, Loss: 0.02765128\n",
      "Epoch: 31, Iter: 61440/100000, Loss: 0.02631479\n",
      "Epoch: 31, Iter: 71680/100000, Loss: 0.029182674\n",
      "Epoch: 31, Iter: 81920/100000, Loss: 0.027286343\n",
      "Epoch: 31, Iter: 92160/100000, Loss: 0.028033447\n",
      "Avg loss: 0.027729960254479928\n",
      "Epoch: 32, Iter: 10240/100000, Loss: 0.025257958\n",
      "Epoch: 32, Iter: 20480/100000, Loss: 0.028514687\n",
      "Epoch: 32, Iter: 30720/100000, Loss: 0.02893612\n",
      "Epoch: 32, Iter: 40960/100000, Loss: 0.027516467\n",
      "Epoch: 32, Iter: 51200/100000, Loss: 0.028044943\n",
      "Epoch: 32, Iter: 61440/100000, Loss: 0.029256899\n",
      "Epoch: 32, Iter: 71680/100000, Loss: 0.02736041\n",
      "Epoch: 32, Iter: 81920/100000, Loss: 0.023106411\n",
      "Epoch: 32, Iter: 92160/100000, Loss: 0.024912912\n",
      "Avg loss: 0.027155949762955156\n",
      "Epoch: 33, Iter: 10240/100000, Loss: 0.027804656\n",
      "Epoch: 33, Iter: 20480/100000, Loss: 0.0273712\n",
      "Epoch: 33, Iter: 30720/100000, Loss: 0.024689496\n",
      "Epoch: 33, Iter: 40960/100000, Loss: 0.028347405\n",
      "Epoch: 33, Iter: 51200/100000, Loss: 0.027862452\n",
      "Epoch: 33, Iter: 61440/100000, Loss: 0.027775606\n",
      "Epoch: 33, Iter: 71680/100000, Loss: 0.024827704\n",
      "Epoch: 33, Iter: 81920/100000, Loss: 0.028668096\n",
      "Epoch: 33, Iter: 92160/100000, Loss: 0.02560069\n",
      "Avg loss: 0.02662655870554988\n",
      "Epoch: 34, Iter: 10240/100000, Loss: 0.023856424\n",
      "Epoch: 34, Iter: 20480/100000, Loss: 0.028768431\n",
      "Epoch: 34, Iter: 30720/100000, Loss: 0.025898576\n",
      "Epoch: 34, Iter: 40960/100000, Loss: 0.026953518\n",
      "Epoch: 34, Iter: 51200/100000, Loss: 0.02724668\n",
      "Epoch: 34, Iter: 61440/100000, Loss: 0.026118316\n",
      "Epoch: 34, Iter: 71680/100000, Loss: 0.027739698\n",
      "Epoch: 34, Iter: 81920/100000, Loss: 0.023827704\n",
      "Epoch: 34, Iter: 92160/100000, Loss: 0.024506979\n",
      "Avg loss: 0.02648901995079419\n",
      "Epoch: 35, Iter: 10240/100000, Loss: 0.024535472\n",
      "Epoch: 35, Iter: 20480/100000, Loss: 0.025574613\n",
      "Epoch: 35, Iter: 30720/100000, Loss: 0.030482948\n",
      "Epoch: 35, Iter: 40960/100000, Loss: 0.025388502\n",
      "Epoch: 35, Iter: 51200/100000, Loss: 0.02680097\n",
      "Epoch: 35, Iter: 61440/100000, Loss: 0.026262749\n",
      "Epoch: 35, Iter: 71680/100000, Loss: 0.022451434\n",
      "Epoch: 35, Iter: 81920/100000, Loss: 0.025345663\n",
      "Epoch: 35, Iter: 92160/100000, Loss: 0.02365861\n",
      "Avg loss: 0.025760576705035475\n",
      "Epoch: 36, Iter: 10240/100000, Loss: 0.02395256\n",
      "Epoch: 36, Iter: 20480/100000, Loss: 0.024929745\n",
      "Epoch: 36, Iter: 30720/100000, Loss: 0.02552128\n",
      "Epoch: 36, Iter: 40960/100000, Loss: 0.02642459\n",
      "Epoch: 36, Iter: 51200/100000, Loss: 0.028402623\n",
      "Epoch: 36, Iter: 61440/100000, Loss: 0.024622045\n",
      "Epoch: 36, Iter: 71680/100000, Loss: 0.026300225\n",
      "Epoch: 36, Iter: 81920/100000, Loss: 0.025533333\n",
      "Epoch: 36, Iter: 92160/100000, Loss: 0.021904452\n",
      "Avg loss: 0.02537085469236079\n",
      "Epoch: 37, Iter: 10240/100000, Loss: 0.020797167\n",
      "Epoch: 37, Iter: 20480/100000, Loss: 0.027767558\n",
      "Epoch: 37, Iter: 30720/100000, Loss: 0.028043915\n",
      "Epoch: 37, Iter: 40960/100000, Loss: 0.028740782\n",
      "Epoch: 37, Iter: 51200/100000, Loss: 0.021937493\n",
      "Epoch: 37, Iter: 61440/100000, Loss: 0.024701562\n",
      "Epoch: 37, Iter: 71680/100000, Loss: 0.029052211\n",
      "Epoch: 37, Iter: 81920/100000, Loss: 0.02405003\n",
      "Epoch: 37, Iter: 92160/100000, Loss: 0.023628902\n",
      "Avg loss: 0.024744664021220403\n",
      "Epoch: 38, Iter: 10240/100000, Loss: 0.022903066\n",
      "Epoch: 38, Iter: 20480/100000, Loss: 0.021262899\n",
      "Epoch: 38, Iter: 30720/100000, Loss: 0.022621045\n",
      "Epoch: 38, Iter: 40960/100000, Loss: 0.026647642\n",
      "Epoch: 38, Iter: 51200/100000, Loss: 0.022788301\n",
      "Epoch: 38, Iter: 61440/100000, Loss: 0.023958266\n",
      "Epoch: 38, Iter: 71680/100000, Loss: 0.022625852\n",
      "Epoch: 38, Iter: 81920/100000, Loss: 0.024207175\n",
      "Epoch: 38, Iter: 92160/100000, Loss: 0.027771324\n",
      "Avg loss: 0.024029460783625386\n",
      "Epoch: 39, Iter: 10240/100000, Loss: 0.02500195\n",
      "Epoch: 39, Iter: 20480/100000, Loss: 0.023414487\n",
      "Epoch: 39, Iter: 30720/100000, Loss: 0.025140379\n",
      "Epoch: 39, Iter: 40960/100000, Loss: 0.026081502\n",
      "Epoch: 39, Iter: 51200/100000, Loss: 0.02639443\n",
      "Epoch: 39, Iter: 61440/100000, Loss: 0.02445075\n",
      "Epoch: 39, Iter: 71680/100000, Loss: 0.023463491\n",
      "Epoch: 39, Iter: 81920/100000, Loss: 0.020470541\n",
      "Epoch: 39, Iter: 92160/100000, Loss: 0.02280587\n",
      "Avg loss: 0.02339224158258168\n",
      "Epoch: 40, Iter: 10240/100000, Loss: 0.025544962\n",
      "Epoch: 40, Iter: 20480/100000, Loss: 0.027433727\n",
      "Epoch: 40, Iter: 30720/100000, Loss: 0.022506155\n",
      "Epoch: 40, Iter: 40960/100000, Loss: 0.024911018\n",
      "Epoch: 40, Iter: 51200/100000, Loss: 0.023861002\n",
      "Epoch: 40, Iter: 61440/100000, Loss: 0.023516059\n",
      "Epoch: 40, Iter: 71680/100000, Loss: 0.022487443\n",
      "Epoch: 40, Iter: 81920/100000, Loss: 0.019510105\n",
      "Epoch: 40, Iter: 92160/100000, Loss: 0.020932969\n",
      "Avg loss: 0.023108094853838693\n",
      "Epoch: 41, Iter: 10240/100000, Loss: 0.022734927\n",
      "Epoch: 41, Iter: 20480/100000, Loss: 0.022851188\n",
      "Epoch: 41, Iter: 30720/100000, Loss: 0.022013279\n",
      "Epoch: 41, Iter: 40960/100000, Loss: 0.0226843\n",
      "Epoch: 41, Iter: 51200/100000, Loss: 0.023873297\n",
      "Epoch: 41, Iter: 61440/100000, Loss: 0.01956214\n",
      "Epoch: 41, Iter: 71680/100000, Loss: 0.021633472\n",
      "Epoch: 41, Iter: 81920/100000, Loss: 0.024357894\n",
      "Epoch: 41, Iter: 92160/100000, Loss: 0.021602996\n",
      "Avg loss: 0.02261087102527471\n",
      "Epoch: 42, Iter: 10240/100000, Loss: 0.02210097\n",
      "Epoch: 42, Iter: 20480/100000, Loss: 0.018915152\n",
      "Epoch: 42, Iter: 30720/100000, Loss: 0.021874018\n",
      "Epoch: 42, Iter: 40960/100000, Loss: 0.02448133\n",
      "Epoch: 42, Iter: 51200/100000, Loss: 0.023190541\n",
      "Epoch: 42, Iter: 61440/100000, Loss: 0.02221548\n",
      "Epoch: 42, Iter: 71680/100000, Loss: 0.02459629\n",
      "Epoch: 42, Iter: 81920/100000, Loss: 0.023157055\n",
      "Epoch: 42, Iter: 92160/100000, Loss: 0.020556167\n",
      "Avg loss: 0.022376507693498405\n",
      "Epoch: 43, Iter: 10240/100000, Loss: 0.020886693\n",
      "Epoch: 43, Iter: 20480/100000, Loss: 0.022169854\n",
      "Epoch: 43, Iter: 30720/100000, Loss: 0.023023244\n",
      "Epoch: 43, Iter: 40960/100000, Loss: 0.019923408\n",
      "Epoch: 43, Iter: 51200/100000, Loss: 0.020693265\n",
      "Epoch: 43, Iter: 61440/100000, Loss: 0.02314598\n",
      "Epoch: 43, Iter: 71680/100000, Loss: 0.02132633\n",
      "Epoch: 43, Iter: 81920/100000, Loss: 0.021266695\n",
      "Epoch: 43, Iter: 92160/100000, Loss: 0.019045414\n",
      "Avg loss: 0.021859459502180826\n",
      "Epoch: 44, Iter: 10240/100000, Loss: 0.019479655\n",
      "Epoch: 44, Iter: 20480/100000, Loss: 0.022630919\n",
      "Epoch: 44, Iter: 30720/100000, Loss: 0.020227717\n",
      "Epoch: 44, Iter: 40960/100000, Loss: 0.02374701\n",
      "Epoch: 44, Iter: 51200/100000, Loss: 0.025665991\n",
      "Epoch: 44, Iter: 61440/100000, Loss: 0.022036303\n",
      "Epoch: 44, Iter: 71680/100000, Loss: 0.024200737\n",
      "Epoch: 44, Iter: 81920/100000, Loss: 0.01889712\n",
      "Epoch: 44, Iter: 92160/100000, Loss: 0.020711072\n",
      "Avg loss: 0.02217926411438234\n",
      "Epoch: 45, Iter: 10240/100000, Loss: 0.021383423\n",
      "Epoch: 45, Iter: 20480/100000, Loss: 0.021024162\n",
      "Epoch: 45, Iter: 30720/100000, Loss: 0.017998802\n",
      "Epoch: 45, Iter: 40960/100000, Loss: 0.024612026\n",
      "Epoch: 45, Iter: 51200/100000, Loss: 0.0227506\n",
      "Epoch: 45, Iter: 61440/100000, Loss: 0.022431761\n",
      "Epoch: 45, Iter: 71680/100000, Loss: 0.02075581\n",
      "Epoch: 45, Iter: 81920/100000, Loss: 0.020341678\n",
      "Epoch: 45, Iter: 92160/100000, Loss: 0.021590794\n",
      "Avg loss: 0.021586731556303723\n",
      "Epoch: 46, Iter: 10240/100000, Loss: 0.021232713\n",
      "Epoch: 46, Iter: 20480/100000, Loss: 0.023503875\n",
      "Epoch: 46, Iter: 30720/100000, Loss: 0.019386591\n",
      "Epoch: 46, Iter: 40960/100000, Loss: 0.023979414\n",
      "Epoch: 46, Iter: 51200/100000, Loss: 0.023676943\n",
      "Epoch: 46, Iter: 61440/100000, Loss: 0.022919329\n",
      "Epoch: 46, Iter: 71680/100000, Loss: 0.020781456\n",
      "Epoch: 46, Iter: 81920/100000, Loss: 0.021521248\n",
      "Epoch: 46, Iter: 92160/100000, Loss: 0.02115348\n",
      "Avg loss: 0.02165372018731132\n",
      "Epoch: 47, Iter: 10240/100000, Loss: 0.021827474\n",
      "Epoch: 47, Iter: 20480/100000, Loss: 0.0218972\n",
      "Epoch: 47, Iter: 30720/100000, Loss: 0.021667138\n",
      "Epoch: 47, Iter: 40960/100000, Loss: 0.027083626\n",
      "Epoch: 47, Iter: 51200/100000, Loss: 0.02293789\n",
      "Epoch: 47, Iter: 61440/100000, Loss: 0.020192124\n",
      "Epoch: 47, Iter: 71680/100000, Loss: 0.022019796\n",
      "Epoch: 47, Iter: 81920/100000, Loss: 0.017783873\n",
      "Epoch: 47, Iter: 92160/100000, Loss: 0.022621145\n",
      "Avg loss: 0.02122650545128842\n",
      "Epoch: 48, Iter: 10240/100000, Loss: 0.026467476\n",
      "Epoch: 48, Iter: 20480/100000, Loss: 0.024021644\n",
      "Epoch: 48, Iter: 30720/100000, Loss: 0.019435791\n",
      "Epoch: 48, Iter: 40960/100000, Loss: 0.022106647\n",
      "Epoch: 48, Iter: 51200/100000, Loss: 0.022031978\n",
      "Epoch: 48, Iter: 61440/100000, Loss: 0.019098768\n",
      "Epoch: 48, Iter: 71680/100000, Loss: 0.020589158\n",
      "Epoch: 48, Iter: 81920/100000, Loss: 0.020444734\n",
      "Epoch: 48, Iter: 92160/100000, Loss: 0.023324966\n",
      "Avg loss: 0.02155085896938732\n",
      "Epoch: 49, Iter: 10240/100000, Loss: 0.01914787\n",
      "Epoch: 49, Iter: 20480/100000, Loss: 0.025570925\n",
      "Epoch: 49, Iter: 30720/100000, Loss: 0.02378288\n",
      "Epoch: 49, Iter: 40960/100000, Loss: 0.019650701\n",
      "Epoch: 49, Iter: 51200/100000, Loss: 0.020514555\n",
      "Epoch: 49, Iter: 61440/100000, Loss: 0.023295619\n",
      "Epoch: 49, Iter: 71680/100000, Loss: 0.016973387\n",
      "Epoch: 49, Iter: 81920/100000, Loss: 0.020378001\n",
      "Epoch: 49, Iter: 92160/100000, Loss: 0.020140784\n",
      "Avg loss: 0.020779506447388955\n",
      "Epoch: 50, Iter: 10240/100000, Loss: 0.018814348\n",
      "Epoch: 50, Iter: 20480/100000, Loss: 0.021398645\n",
      "Epoch: 50, Iter: 30720/100000, Loss: 0.021105856\n",
      "Epoch: 50, Iter: 40960/100000, Loss: 0.021279436\n",
      "Epoch: 50, Iter: 51200/100000, Loss: 0.022670735\n",
      "Epoch: 50, Iter: 61440/100000, Loss: 0.01917933\n",
      "Epoch: 50, Iter: 71680/100000, Loss: 0.018779304\n",
      "Epoch: 50, Iter: 81920/100000, Loss: 0.020752877\n",
      "Epoch: 50, Iter: 92160/100000, Loss: 0.018504314\n",
      "Avg loss: 0.020475076569109848\n",
      "Epoch: 51, Iter: 10240/100000, Loss: 0.020337008\n",
      "Epoch: 51, Iter: 20480/100000, Loss: 0.020717127\n",
      "Epoch: 51, Iter: 30720/100000, Loss: 0.021114878\n",
      "Epoch: 51, Iter: 40960/100000, Loss: 0.02211275\n",
      "Epoch: 51, Iter: 51200/100000, Loss: 0.024515867\n",
      "Epoch: 51, Iter: 61440/100000, Loss: 0.022463456\n",
      "Epoch: 51, Iter: 71680/100000, Loss: 0.019386899\n",
      "Epoch: 51, Iter: 81920/100000, Loss: 0.01821666\n",
      "Epoch: 51, Iter: 92160/100000, Loss: 0.019386668\n",
      "Avg loss: 0.020525845036525086\n",
      "Epoch: 52, Iter: 10240/100000, Loss: 0.022180803\n",
      "Epoch: 52, Iter: 20480/100000, Loss: 0.019963562\n",
      "Epoch: 52, Iter: 30720/100000, Loss: 0.018930243\n",
      "Epoch: 52, Iter: 40960/100000, Loss: 0.021882799\n",
      "Epoch: 52, Iter: 51200/100000, Loss: 0.020573366\n",
      "Epoch: 52, Iter: 61440/100000, Loss: 0.020355467\n",
      "Epoch: 52, Iter: 71680/100000, Loss: 0.017387416\n",
      "Epoch: 52, Iter: 81920/100000, Loss: 0.019736394\n",
      "Epoch: 52, Iter: 92160/100000, Loss: 0.019014735\n",
      "Avg loss: 0.02021999079158011\n",
      "Epoch: 53, Iter: 10240/100000, Loss: 0.019365186\n",
      "Epoch: 53, Iter: 20480/100000, Loss: 0.021833355\n",
      "Epoch: 53, Iter: 30720/100000, Loss: 0.019556157\n",
      "Epoch: 53, Iter: 40960/100000, Loss: 0.020592107\n",
      "Epoch: 53, Iter: 51200/100000, Loss: 0.019446898\n",
      "Epoch: 53, Iter: 61440/100000, Loss: 0.022046916\n",
      "Epoch: 53, Iter: 71680/100000, Loss: 0.019328685\n",
      "Epoch: 53, Iter: 81920/100000, Loss: 0.018482666\n",
      "Epoch: 53, Iter: 92160/100000, Loss: 0.01915706\n",
      "Avg loss: 0.02040491456684378\n",
      "Epoch: 54, Iter: 10240/100000, Loss: 0.021069206\n",
      "Epoch: 54, Iter: 20480/100000, Loss: 0.02109151\n",
      "Epoch: 54, Iter: 30720/100000, Loss: 0.022959419\n",
      "Epoch: 54, Iter: 40960/100000, Loss: 0.022630256\n",
      "Epoch: 54, Iter: 51200/100000, Loss: 0.02430623\n",
      "Epoch: 54, Iter: 61440/100000, Loss: 0.01857659\n",
      "Epoch: 54, Iter: 71680/100000, Loss: 0.016263684\n",
      "Epoch: 54, Iter: 81920/100000, Loss: 0.018067852\n",
      "Epoch: 54, Iter: 92160/100000, Loss: 0.016619876\n",
      "Avg loss: 0.019923133871604486\n",
      "Epoch: 55, Iter: 10240/100000, Loss: 0.01872047\n",
      "Epoch: 55, Iter: 20480/100000, Loss: 0.021079162\n",
      "Epoch: 55, Iter: 30720/100000, Loss: 0.020926692\n",
      "Epoch: 55, Iter: 40960/100000, Loss: 0.02223296\n",
      "Epoch: 55, Iter: 51200/100000, Loss: 0.021308044\n",
      "Epoch: 55, Iter: 61440/100000, Loss: 0.019904781\n",
      "Epoch: 55, Iter: 71680/100000, Loss: 0.02200012\n",
      "Epoch: 55, Iter: 81920/100000, Loss: 0.021931898\n",
      "Epoch: 55, Iter: 92160/100000, Loss: 0.024425842\n",
      "Avg loss: 0.01983736228850699\n",
      "Epoch: 56, Iter: 10240/100000, Loss: 0.016382976\n",
      "Epoch: 56, Iter: 20480/100000, Loss: 0.019782985\n",
      "Epoch: 56, Iter: 30720/100000, Loss: 0.020755935\n",
      "Epoch: 56, Iter: 40960/100000, Loss: 0.020623732\n",
      "Epoch: 56, Iter: 51200/100000, Loss: 0.022811113\n",
      "Epoch: 56, Iter: 61440/100000, Loss: 0.02383792\n",
      "Epoch: 56, Iter: 71680/100000, Loss: 0.019016493\n",
      "Epoch: 56, Iter: 81920/100000, Loss: 0.021321364\n",
      "Epoch: 56, Iter: 92160/100000, Loss: 0.021178948\n",
      "Avg loss: 0.01980133640781506\n",
      "Epoch: 57, Iter: 10240/100000, Loss: 0.022126747\n",
      "Epoch: 57, Iter: 20480/100000, Loss: 0.016257297\n",
      "Epoch: 57, Iter: 30720/100000, Loss: 0.019153252\n",
      "Epoch: 57, Iter: 40960/100000, Loss: 0.020057894\n",
      "Epoch: 57, Iter: 51200/100000, Loss: 0.019536078\n",
      "Epoch: 57, Iter: 61440/100000, Loss: 0.02298025\n",
      "Epoch: 57, Iter: 71680/100000, Loss: 0.020593835\n",
      "Epoch: 57, Iter: 81920/100000, Loss: 0.022539783\n",
      "Epoch: 57, Iter: 92160/100000, Loss: 0.018469766\n",
      "Avg loss: 0.019395261657299455\n",
      "Epoch: 58, Iter: 10240/100000, Loss: 0.019521903\n",
      "Epoch: 58, Iter: 20480/100000, Loss: 0.015941836\n",
      "Epoch: 58, Iter: 30720/100000, Loss: 0.01762037\n",
      "Epoch: 58, Iter: 40960/100000, Loss: 0.022638895\n",
      "Epoch: 58, Iter: 51200/100000, Loss: 0.01959939\n",
      "Epoch: 58, Iter: 61440/100000, Loss: 0.01935163\n",
      "Epoch: 58, Iter: 71680/100000, Loss: 0.016934432\n",
      "Epoch: 58, Iter: 81920/100000, Loss: 0.021096833\n",
      "Epoch: 58, Iter: 92160/100000, Loss: 0.01595641\n",
      "Avg loss: 0.01960317096336908\n",
      "Epoch: 59, Iter: 10240/100000, Loss: 0.018741805\n",
      "Epoch: 59, Iter: 20480/100000, Loss: 0.018559186\n",
      "Epoch: 59, Iter: 30720/100000, Loss: 0.017267458\n",
      "Epoch: 59, Iter: 40960/100000, Loss: 0.022234363\n",
      "Epoch: 59, Iter: 51200/100000, Loss: 0.022262864\n",
      "Epoch: 59, Iter: 61440/100000, Loss: 0.022973046\n",
      "Epoch: 59, Iter: 71680/100000, Loss: 0.019056853\n",
      "Epoch: 59, Iter: 81920/100000, Loss: 0.019880522\n",
      "Epoch: 59, Iter: 92160/100000, Loss: 0.020295996\n",
      "Avg loss: 0.01952141089384089\n",
      "Epoch: 60, Iter: 10240/100000, Loss: 0.01705213\n",
      "Epoch: 60, Iter: 20480/100000, Loss: 0.017864496\n",
      "Epoch: 60, Iter: 30720/100000, Loss: 0.017727654\n",
      "Epoch: 60, Iter: 40960/100000, Loss: 0.0235349\n",
      "Epoch: 60, Iter: 51200/100000, Loss: 0.019140013\n",
      "Epoch: 60, Iter: 61440/100000, Loss: 0.0194889\n",
      "Epoch: 60, Iter: 71680/100000, Loss: 0.018499047\n",
      "Epoch: 60, Iter: 81920/100000, Loss: 0.014859999\n",
      "Epoch: 60, Iter: 92160/100000, Loss: 0.014877159\n",
      "Avg loss: 0.019315105469263707\n",
      "Epoch: 61, Iter: 10240/100000, Loss: 0.0199929\n",
      "Epoch: 61, Iter: 20480/100000, Loss: 0.016250972\n",
      "Epoch: 61, Iter: 30720/100000, Loss: 0.020045204\n",
      "Epoch: 61, Iter: 40960/100000, Loss: 0.019510511\n",
      "Epoch: 61, Iter: 51200/100000, Loss: 0.019950368\n",
      "Epoch: 61, Iter: 61440/100000, Loss: 0.019806154\n",
      "Epoch: 61, Iter: 71680/100000, Loss: 0.017806787\n",
      "Epoch: 61, Iter: 81920/100000, Loss: 0.024151053\n",
      "Epoch: 61, Iter: 92160/100000, Loss: 0.018882161\n",
      "Avg loss: 0.019249338695068948\n",
      "Epoch: 62, Iter: 10240/100000, Loss: 0.015779912\n",
      "Epoch: 62, Iter: 20480/100000, Loss: 0.017397594\n",
      "Epoch: 62, Iter: 30720/100000, Loss: 0.019424522\n",
      "Epoch: 62, Iter: 40960/100000, Loss: 0.018883636\n",
      "Epoch: 62, Iter: 51200/100000, Loss: 0.02115671\n",
      "Epoch: 62, Iter: 61440/100000, Loss: 0.019359719\n",
      "Epoch: 62, Iter: 71680/100000, Loss: 0.019807585\n",
      "Epoch: 62, Iter: 81920/100000, Loss: 0.018927265\n",
      "Epoch: 62, Iter: 92160/100000, Loss: 0.019817661\n",
      "Avg loss: 0.019283195698307345\n",
      "Epoch: 63, Iter: 10240/100000, Loss: 0.018166132\n",
      "Epoch: 63, Iter: 20480/100000, Loss: 0.030905288\n",
      "Epoch: 63, Iter: 30720/100000, Loss: 0.019311555\n",
      "Epoch: 63, Iter: 40960/100000, Loss: 0.023724202\n",
      "Epoch: 63, Iter: 51200/100000, Loss: 0.024123257\n",
      "Epoch: 63, Iter: 61440/100000, Loss: 0.017691301\n",
      "Epoch: 63, Iter: 71680/100000, Loss: 0.021500112\n",
      "Epoch: 63, Iter: 81920/100000, Loss: 0.020022962\n",
      "Epoch: 63, Iter: 92160/100000, Loss: 0.017356303\n",
      "Avg loss: 0.02023142130719018\n",
      "Epoch: 64, Iter: 10240/100000, Loss: 0.019561838\n",
      "Epoch: 64, Iter: 20480/100000, Loss: 0.019368097\n",
      "Epoch: 64, Iter: 30720/100000, Loss: 0.02086801\n",
      "Epoch: 64, Iter: 40960/100000, Loss: 0.020854518\n",
      "Epoch: 64, Iter: 51200/100000, Loss: 0.020444723\n",
      "Epoch: 64, Iter: 61440/100000, Loss: 0.020868968\n",
      "Epoch: 64, Iter: 71680/100000, Loss: 0.021086019\n",
      "Epoch: 64, Iter: 81920/100000, Loss: 0.017838225\n",
      "Epoch: 64, Iter: 92160/100000, Loss: 0.021060873\n",
      "Avg loss: 0.01911933995668114\n",
      "Epoch: 65, Iter: 10240/100000, Loss: 0.018060727\n",
      "Epoch: 65, Iter: 20480/100000, Loss: 0.017503895\n",
      "Epoch: 65, Iter: 30720/100000, Loss: 0.01550399\n",
      "Epoch: 65, Iter: 40960/100000, Loss: 0.023738982\n",
      "Epoch: 65, Iter: 51200/100000, Loss: 0.019916167\n",
      "Epoch: 65, Iter: 61440/100000, Loss: 0.021991406\n",
      "Epoch: 65, Iter: 71680/100000, Loss: 0.017595887\n",
      "Epoch: 65, Iter: 81920/100000, Loss: 0.019768544\n",
      "Epoch: 65, Iter: 92160/100000, Loss: 0.01946562\n",
      "Avg loss: 0.01858251190446701\n",
      "Epoch: 66, Iter: 10240/100000, Loss: 0.017717473\n",
      "Epoch: 66, Iter: 20480/100000, Loss: 0.018141463\n",
      "Epoch: 66, Iter: 30720/100000, Loss: 0.016103815\n",
      "Epoch: 66, Iter: 40960/100000, Loss: 0.019326594\n",
      "Epoch: 66, Iter: 51200/100000, Loss: 0.0202733\n",
      "Epoch: 66, Iter: 61440/100000, Loss: 0.017330281\n",
      "Epoch: 66, Iter: 71680/100000, Loss: 0.01649105\n",
      "Epoch: 66, Iter: 81920/100000, Loss: 0.019771773\n",
      "Epoch: 66, Iter: 92160/100000, Loss: 0.014969457\n",
      "Avg loss: 0.018921452315197776\n",
      "Epoch: 67, Iter: 10240/100000, Loss: 0.017895231\n",
      "Epoch: 67, Iter: 20480/100000, Loss: 0.017809799\n",
      "Epoch: 67, Iter: 30720/100000, Loss: 0.017855052\n",
      "Epoch: 67, Iter: 40960/100000, Loss: 0.019975696\n",
      "Epoch: 67, Iter: 51200/100000, Loss: 0.021343533\n",
      "Epoch: 67, Iter: 61440/100000, Loss: 0.018694162\n",
      "Epoch: 67, Iter: 71680/100000, Loss: 0.017925069\n",
      "Epoch: 67, Iter: 81920/100000, Loss: 0.020603098\n",
      "Epoch: 67, Iter: 92160/100000, Loss: 0.019754\n",
      "Avg loss: 0.01871602411007451\n",
      "Epoch: 68, Iter: 10240/100000, Loss: 0.020612905\n",
      "Epoch: 68, Iter: 20480/100000, Loss: 0.019377952\n",
      "Epoch: 68, Iter: 30720/100000, Loss: 0.019289609\n",
      "Epoch: 68, Iter: 40960/100000, Loss: 0.019729633\n",
      "Epoch: 68, Iter: 51200/100000, Loss: 0.019309692\n",
      "Epoch: 68, Iter: 61440/100000, Loss: 0.019100856\n",
      "Epoch: 68, Iter: 71680/100000, Loss: 0.01992594\n",
      "Epoch: 68, Iter: 81920/100000, Loss: 0.01863141\n",
      "Epoch: 68, Iter: 92160/100000, Loss: 0.015579596\n",
      "Avg loss: 0.01825632772302812\n",
      "Epoch: 69, Iter: 10240/100000, Loss: 0.018253526\n",
      "Epoch: 69, Iter: 20480/100000, Loss: 0.017702155\n",
      "Epoch: 69, Iter: 30720/100000, Loss: 0.017929457\n",
      "Epoch: 69, Iter: 40960/100000, Loss: 0.020347267\n",
      "Epoch: 69, Iter: 51200/100000, Loss: 0.02097565\n",
      "Epoch: 69, Iter: 61440/100000, Loss: 0.018252905\n",
      "Epoch: 69, Iter: 71680/100000, Loss: 0.016219491\n",
      "Epoch: 69, Iter: 81920/100000, Loss: 0.020883866\n",
      "Epoch: 69, Iter: 92160/100000, Loss: 0.017618768\n",
      "Avg loss: 0.018328737477128654\n",
      "Epoch: 70, Iter: 10240/100000, Loss: 0.014720137\n",
      "Epoch: 70, Iter: 20480/100000, Loss: 0.019729482\n",
      "Epoch: 70, Iter: 30720/100000, Loss: 0.015523989\n",
      "Epoch: 70, Iter: 40960/100000, Loss: 0.02157683\n",
      "Epoch: 70, Iter: 51200/100000, Loss: 0.022018565\n",
      "Epoch: 70, Iter: 61440/100000, Loss: 0.020042188\n",
      "Epoch: 70, Iter: 71680/100000, Loss: 0.017578006\n",
      "Epoch: 70, Iter: 81920/100000, Loss: 0.017801594\n",
      "Epoch: 70, Iter: 92160/100000, Loss: 0.017171642\n",
      "Avg loss: 0.018174484525759194\n",
      "Epoch: 71, Iter: 10240/100000, Loss: 0.02125404\n",
      "Epoch: 71, Iter: 20480/100000, Loss: 0.01664873\n",
      "Epoch: 71, Iter: 30720/100000, Loss: 0.017714486\n",
      "Epoch: 71, Iter: 40960/100000, Loss: 0.021025974\n",
      "Epoch: 71, Iter: 51200/100000, Loss: 0.017026443\n",
      "Epoch: 71, Iter: 61440/100000, Loss: 0.018769188\n",
      "Epoch: 71, Iter: 71680/100000, Loss: 0.017855074\n",
      "Epoch: 71, Iter: 81920/100000, Loss: 0.018535756\n",
      "Epoch: 71, Iter: 92160/100000, Loss: 0.017522365\n",
      "Avg loss: 0.018310816334464502\n",
      "Epoch: 72, Iter: 10240/100000, Loss: 0.019043386\n",
      "Epoch: 72, Iter: 20480/100000, Loss: 0.018785272\n",
      "Epoch: 72, Iter: 30720/100000, Loss: 0.019095968\n",
      "Epoch: 72, Iter: 40960/100000, Loss: 0.018698234\n",
      "Epoch: 72, Iter: 51200/100000, Loss: 0.022134032\n",
      "Epoch: 72, Iter: 61440/100000, Loss: 0.018547894\n",
      "Epoch: 72, Iter: 71680/100000, Loss: 0.016660117\n",
      "Epoch: 72, Iter: 81920/100000, Loss: 0.013531102\n",
      "Epoch: 72, Iter: 92160/100000, Loss: 0.015636627\n",
      "Avg loss: 0.018116634166271416\n",
      "Epoch: 73, Iter: 10240/100000, Loss: 0.014250369\n",
      "Epoch: 73, Iter: 20480/100000, Loss: 0.020275578\n",
      "Epoch: 73, Iter: 30720/100000, Loss: 0.018353662\n",
      "Epoch: 73, Iter: 40960/100000, Loss: 0.019408079\n",
      "Epoch: 73, Iter: 51200/100000, Loss: 0.018242696\n",
      "Epoch: 73, Iter: 61440/100000, Loss: 0.016798204\n",
      "Epoch: 73, Iter: 71680/100000, Loss: 0.01922673\n",
      "Epoch: 73, Iter: 81920/100000, Loss: 0.016208913\n",
      "Epoch: 73, Iter: 92160/100000, Loss: 0.016610092\n",
      "Avg loss: 0.018060159187802335\n",
      "Epoch: 74, Iter: 10240/100000, Loss: 0.017367454\n",
      "Epoch: 74, Iter: 20480/100000, Loss: 0.018196879\n",
      "Epoch: 74, Iter: 30720/100000, Loss: 0.017073112\n",
      "Epoch: 74, Iter: 40960/100000, Loss: 0.020273015\n",
      "Epoch: 74, Iter: 51200/100000, Loss: 0.018090038\n",
      "Epoch: 74, Iter: 61440/100000, Loss: 0.015789086\n",
      "Epoch: 74, Iter: 71680/100000, Loss: 0.017765477\n",
      "Epoch: 74, Iter: 81920/100000, Loss: 0.014798757\n",
      "Epoch: 74, Iter: 92160/100000, Loss: 0.015006375\n",
      "Avg loss: 0.017918808904198027\n",
      "Epoch: 75, Iter: 10240/100000, Loss: 0.017539525\n",
      "Epoch: 75, Iter: 20480/100000, Loss: 0.019789595\n",
      "Epoch: 75, Iter: 30720/100000, Loss: 0.01674973\n",
      "Epoch: 75, Iter: 40960/100000, Loss: 0.017085064\n",
      "Epoch: 75, Iter: 51200/100000, Loss: 0.021753188\n",
      "Epoch: 75, Iter: 61440/100000, Loss: 0.01794717\n",
      "Epoch: 75, Iter: 71680/100000, Loss: 0.019205488\n",
      "Epoch: 75, Iter: 81920/100000, Loss: 0.015362736\n",
      "Epoch: 75, Iter: 92160/100000, Loss: 0.018252127\n",
      "Avg loss: 0.017960604097809373\n",
      "Epoch: 76, Iter: 10240/100000, Loss: 0.018633507\n",
      "Epoch: 76, Iter: 20480/100000, Loss: 0.016272878\n",
      "Epoch: 76, Iter: 30720/100000, Loss: 0.01600286\n",
      "Epoch: 76, Iter: 40960/100000, Loss: 0.020855237\n",
      "Epoch: 76, Iter: 51200/100000, Loss: 0.018649349\n",
      "Epoch: 76, Iter: 61440/100000, Loss: 0.017193403\n",
      "Epoch: 76, Iter: 71680/100000, Loss: 0.016715618\n",
      "Epoch: 76, Iter: 81920/100000, Loss: 0.01578391\n",
      "Epoch: 76, Iter: 92160/100000, Loss: 0.016633542\n",
      "Avg loss: 0.017792665610838795\n",
      "Epoch: 77, Iter: 10240/100000, Loss: 0.018271092\n",
      "Epoch: 77, Iter: 20480/100000, Loss: 0.017071936\n",
      "Epoch: 77, Iter: 30720/100000, Loss: 0.016913652\n",
      "Epoch: 77, Iter: 40960/100000, Loss: 0.018612735\n",
      "Epoch: 77, Iter: 51200/100000, Loss: 0.019673802\n",
      "Epoch: 77, Iter: 61440/100000, Loss: 0.020295313\n",
      "Epoch: 77, Iter: 71680/100000, Loss: 0.019426484\n",
      "Epoch: 77, Iter: 81920/100000, Loss: 0.017747086\n",
      "Epoch: 77, Iter: 92160/100000, Loss: 0.016996382\n",
      "Avg loss: 0.01771131299013637\n",
      "Epoch: 78, Iter: 10240/100000, Loss: 0.017154671\n",
      "Epoch: 78, Iter: 20480/100000, Loss: 0.01726566\n",
      "Epoch: 78, Iter: 30720/100000, Loss: 0.018656116\n",
      "Epoch: 78, Iter: 40960/100000, Loss: 0.020869648\n",
      "Epoch: 78, Iter: 51200/100000, Loss: 0.020450152\n",
      "Epoch: 78, Iter: 61440/100000, Loss: 0.017811177\n",
      "Epoch: 78, Iter: 71680/100000, Loss: 0.01758013\n",
      "Epoch: 78, Iter: 81920/100000, Loss: 0.015877819\n",
      "Epoch: 78, Iter: 92160/100000, Loss: 0.017177286\n",
      "Avg loss: 0.017687567471305735\n",
      "Epoch: 79, Iter: 10240/100000, Loss: 0.017173465\n",
      "Epoch: 79, Iter: 20480/100000, Loss: 0.017723793\n",
      "Epoch: 79, Iter: 30720/100000, Loss: 0.019710971\n",
      "Epoch: 79, Iter: 40960/100000, Loss: 0.019431882\n",
      "Epoch: 79, Iter: 51200/100000, Loss: 0.020369334\n",
      "Epoch: 79, Iter: 61440/100000, Loss: 0.017756267\n",
      "Epoch: 79, Iter: 71680/100000, Loss: 0.01745026\n",
      "Epoch: 79, Iter: 81920/100000, Loss: 0.019369941\n",
      "Epoch: 79, Iter: 92160/100000, Loss: 0.01587587\n",
      "Avg loss: 0.018364322698223835\n",
      "Epoch: 80, Iter: 10240/100000, Loss: 0.018005744\n",
      "Epoch: 80, Iter: 20480/100000, Loss: 0.015684202\n",
      "Epoch: 80, Iter: 30720/100000, Loss: 0.021382282\n",
      "Epoch: 80, Iter: 40960/100000, Loss: 0.019913096\n",
      "Epoch: 80, Iter: 51200/100000, Loss: 0.017156906\n",
      "Epoch: 80, Iter: 61440/100000, Loss: 0.023264458\n",
      "Epoch: 80, Iter: 71680/100000, Loss: 0.01593028\n",
      "Epoch: 80, Iter: 81920/100000, Loss: 0.017912596\n",
      "Epoch: 80, Iter: 92160/100000, Loss: 0.018232713\n",
      "Avg loss: 0.017725259142438162\n",
      "Epoch: 81, Iter: 10240/100000, Loss: 0.014129771\n",
      "Epoch: 81, Iter: 20480/100000, Loss: 0.017236179\n",
      "Epoch: 81, Iter: 30720/100000, Loss: 0.01966037\n",
      "Epoch: 81, Iter: 40960/100000, Loss: 0.023879632\n",
      "Epoch: 81, Iter: 51200/100000, Loss: 0.017359408\n",
      "Epoch: 81, Iter: 61440/100000, Loss: 0.016015226\n",
      "Epoch: 81, Iter: 71680/100000, Loss: 0.01668918\n",
      "Epoch: 81, Iter: 81920/100000, Loss: 0.018011685\n",
      "Epoch: 81, Iter: 92160/100000, Loss: 0.016413912\n",
      "Avg loss: 0.017289912500946792\n",
      "Epoch: 82, Iter: 10240/100000, Loss: 0.01684404\n",
      "Epoch: 82, Iter: 20480/100000, Loss: 0.020087872\n",
      "Epoch: 82, Iter: 30720/100000, Loss: 0.01782296\n",
      "Epoch: 82, Iter: 40960/100000, Loss: 0.018869646\n",
      "Epoch: 82, Iter: 51200/100000, Loss: 0.021216355\n",
      "Epoch: 82, Iter: 61440/100000, Loss: 0.018510735\n",
      "Epoch: 82, Iter: 71680/100000, Loss: 0.016441552\n",
      "Epoch: 82, Iter: 81920/100000, Loss: 0.018073484\n",
      "Epoch: 82, Iter: 92160/100000, Loss: 0.018823499\n",
      "Avg loss: 0.017683233249663692\n",
      "Epoch: 83, Iter: 10240/100000, Loss: 0.015884\n",
      "Epoch: 83, Iter: 20480/100000, Loss: 0.01581112\n",
      "Epoch: 83, Iter: 30720/100000, Loss: 0.019432295\n",
      "Epoch: 83, Iter: 40960/100000, Loss: 0.018572714\n",
      "Epoch: 83, Iter: 51200/100000, Loss: 0.016421195\n",
      "Epoch: 83, Iter: 61440/100000, Loss: 0.014864824\n",
      "Epoch: 83, Iter: 71680/100000, Loss: 0.016814224\n",
      "Epoch: 83, Iter: 81920/100000, Loss: 0.016263884\n",
      "Epoch: 83, Iter: 92160/100000, Loss: 0.018342655\n",
      "Avg loss: 0.017626234810300095\n",
      "Epoch: 84, Iter: 10240/100000, Loss: 0.016518205\n",
      "Epoch: 84, Iter: 20480/100000, Loss: 0.017739234\n",
      "Epoch: 84, Iter: 30720/100000, Loss: 0.01798066\n",
      "Epoch: 84, Iter: 40960/100000, Loss: 0.017343532\n",
      "Epoch: 84, Iter: 51200/100000, Loss: 0.024222165\n",
      "Epoch: 84, Iter: 61440/100000, Loss: 0.020508\n",
      "Epoch: 84, Iter: 71680/100000, Loss: 0.015473774\n",
      "Epoch: 84, Iter: 81920/100000, Loss: 0.015729185\n",
      "Epoch: 84, Iter: 92160/100000, Loss: 0.016916556\n",
      "Avg loss: 0.017609232767801925\n",
      "Epoch: 85, Iter: 10240/100000, Loss: 0.018376935\n",
      "Epoch: 85, Iter: 20480/100000, Loss: 0.018259352\n",
      "Epoch: 85, Iter: 30720/100000, Loss: 0.01610647\n",
      "Epoch: 85, Iter: 40960/100000, Loss: 0.01729688\n",
      "Epoch: 85, Iter: 51200/100000, Loss: 0.015621934\n",
      "Epoch: 85, Iter: 61440/100000, Loss: 0.016234893\n",
      "Epoch: 85, Iter: 71680/100000, Loss: 0.017721087\n",
      "Epoch: 85, Iter: 81920/100000, Loss: 0.015777973\n",
      "Epoch: 85, Iter: 92160/100000, Loss: 0.018834412\n",
      "Avg loss: 0.017068855358844566\n",
      "Epoch: 86, Iter: 10240/100000, Loss: 0.018681213\n",
      "Epoch: 86, Iter: 20480/100000, Loss: 0.01600952\n",
      "Epoch: 86, Iter: 30720/100000, Loss: 0.017946742\n",
      "Epoch: 86, Iter: 40960/100000, Loss: 0.01727403\n",
      "Epoch: 86, Iter: 51200/100000, Loss: 0.02193023\n",
      "Epoch: 86, Iter: 61440/100000, Loss: 0.018314827\n",
      "Epoch: 86, Iter: 71680/100000, Loss: 0.015196323\n",
      "Epoch: 86, Iter: 81920/100000, Loss: 0.018489277\n",
      "Epoch: 86, Iter: 92160/100000, Loss: 0.019125663\n",
      "Avg loss: 0.017094122754774756\n",
      "Epoch: 87, Iter: 10240/100000, Loss: 0.01648798\n",
      "Epoch: 87, Iter: 20480/100000, Loss: 0.017103218\n",
      "Epoch: 87, Iter: 30720/100000, Loss: 0.02019215\n",
      "Epoch: 87, Iter: 40960/100000, Loss: 0.018925715\n",
      "Epoch: 87, Iter: 51200/100000, Loss: 0.019077871\n",
      "Epoch: 87, Iter: 61440/100000, Loss: 0.020490378\n",
      "Epoch: 87, Iter: 71680/100000, Loss: 0.016907984\n",
      "Epoch: 87, Iter: 81920/100000, Loss: 0.013566182\n",
      "Epoch: 87, Iter: 92160/100000, Loss: 0.01752244\n",
      "Avg loss: 0.016780641352392964\n",
      "Epoch: 88, Iter: 10240/100000, Loss: 0.019127278\n",
      "Epoch: 88, Iter: 20480/100000, Loss: 0.015190542\n",
      "Epoch: 88, Iter: 30720/100000, Loss: 0.016814558\n",
      "Epoch: 88, Iter: 40960/100000, Loss: 0.019078247\n",
      "Epoch: 88, Iter: 51200/100000, Loss: 0.018570239\n",
      "Epoch: 88, Iter: 61440/100000, Loss: 0.01614896\n",
      "Epoch: 88, Iter: 71680/100000, Loss: 0.01579037\n",
      "Epoch: 88, Iter: 81920/100000, Loss: 0.016919807\n",
      "Epoch: 88, Iter: 92160/100000, Loss: 0.01648156\n",
      "Avg loss: 0.016853185149735397\n",
      "Epoch: 89, Iter: 10240/100000, Loss: 0.016545065\n",
      "Epoch: 89, Iter: 20480/100000, Loss: 0.015398434\n",
      "Epoch: 89, Iter: 30720/100000, Loss: 0.020157572\n",
      "Epoch: 89, Iter: 40960/100000, Loss: 0.019436598\n",
      "Epoch: 89, Iter: 51200/100000, Loss: 0.016628953\n",
      "Epoch: 89, Iter: 61440/100000, Loss: 0.019602858\n",
      "Epoch: 89, Iter: 71680/100000, Loss: 0.01700402\n",
      "Epoch: 89, Iter: 81920/100000, Loss: 0.014193515\n",
      "Epoch: 89, Iter: 92160/100000, Loss: 0.016106257\n",
      "Avg loss: 0.01716631862152483\n",
      "Epoch: 90, Iter: 10240/100000, Loss: 0.01600621\n",
      "Epoch: 90, Iter: 20480/100000, Loss: 0.017428854\n",
      "Epoch: 90, Iter: 30720/100000, Loss: 0.015541182\n",
      "Epoch: 90, Iter: 40960/100000, Loss: 0.019282445\n",
      "Epoch: 90, Iter: 51200/100000, Loss: 0.018400477\n",
      "Epoch: 90, Iter: 61440/100000, Loss: 0.01828726\n",
      "Epoch: 90, Iter: 71680/100000, Loss: 0.017465074\n",
      "Epoch: 90, Iter: 81920/100000, Loss: 0.015620218\n",
      "Epoch: 90, Iter: 92160/100000, Loss: 0.016258027\n",
      "Avg loss: 0.017001170204165056\n",
      "Epoch: 91, Iter: 10240/100000, Loss: 0.014868492\n",
      "Epoch: 91, Iter: 20480/100000, Loss: 0.0150546245\n",
      "Epoch: 91, Iter: 30720/100000, Loss: 0.019072987\n",
      "Epoch: 91, Iter: 40960/100000, Loss: 0.021644015\n",
      "Epoch: 91, Iter: 51200/100000, Loss: 0.019205077\n",
      "Epoch: 91, Iter: 61440/100000, Loss: 0.020318728\n",
      "Epoch: 91, Iter: 71680/100000, Loss: 0.017893756\n",
      "Epoch: 91, Iter: 81920/100000, Loss: 0.015430981\n",
      "Epoch: 91, Iter: 92160/100000, Loss: 0.016820531\n",
      "Avg loss: 0.01685104507607283\n",
      "Epoch: 92, Iter: 10240/100000, Loss: 0.016651396\n",
      "Epoch: 92, Iter: 20480/100000, Loss: 0.017104559\n",
      "Epoch: 92, Iter: 30720/100000, Loss: 0.018225065\n",
      "Epoch: 92, Iter: 40960/100000, Loss: 0.017486075\n",
      "Epoch: 92, Iter: 51200/100000, Loss: 0.018006248\n",
      "Epoch: 92, Iter: 61440/100000, Loss: 0.018517708\n",
      "Epoch: 92, Iter: 71680/100000, Loss: 0.01868801\n",
      "Epoch: 92, Iter: 81920/100000, Loss: 0.015947113\n",
      "Epoch: 92, Iter: 92160/100000, Loss: 0.016944274\n",
      "Avg loss: 0.017006078658183824\n",
      "Epoch: 93, Iter: 10240/100000, Loss: 0.018832114\n",
      "Epoch: 93, Iter: 20480/100000, Loss: 0.018968375\n",
      "Epoch: 93, Iter: 30720/100000, Loss: 0.017527044\n",
      "Epoch: 93, Iter: 40960/100000, Loss: 0.018292826\n",
      "Epoch: 93, Iter: 51200/100000, Loss: 0.020438978\n",
      "Epoch: 93, Iter: 61440/100000, Loss: 0.017299704\n",
      "Epoch: 93, Iter: 71680/100000, Loss: 0.015891986\n",
      "Epoch: 93, Iter: 81920/100000, Loss: 0.020196762\n",
      "Epoch: 93, Iter: 92160/100000, Loss: 0.018103492\n",
      "Avg loss: 0.01710466420297156\n",
      "Epoch: 94, Iter: 10240/100000, Loss: 0.014450979\n",
      "Epoch: 94, Iter: 20480/100000, Loss: 0.014803657\n",
      "Epoch: 94, Iter: 30720/100000, Loss: 0.016637709\n",
      "Epoch: 94, Iter: 40960/100000, Loss: 0.018345023\n",
      "Epoch: 94, Iter: 51200/100000, Loss: 0.016798262\n",
      "Epoch: 94, Iter: 61440/100000, Loss: 0.01824509\n",
      "Epoch: 94, Iter: 71680/100000, Loss: 0.019633647\n",
      "Epoch: 94, Iter: 81920/100000, Loss: 0.015925985\n",
      "Epoch: 94, Iter: 92160/100000, Loss: 0.016366865\n",
      "Avg loss: 0.016789167812190104\n",
      "Epoch: 95, Iter: 10240/100000, Loss: 0.015758215\n",
      "Epoch: 95, Iter: 20480/100000, Loss: 0.014143823\n",
      "Epoch: 95, Iter: 30720/100000, Loss: 0.014166868\n",
      "Epoch: 95, Iter: 40960/100000, Loss: 0.01721631\n",
      "Epoch: 95, Iter: 51200/100000, Loss: 0.017903574\n",
      "Epoch: 95, Iter: 61440/100000, Loss: 0.015338296\n",
      "Epoch: 95, Iter: 71680/100000, Loss: 0.014315909\n",
      "Epoch: 95, Iter: 81920/100000, Loss: 0.01670919\n",
      "Epoch: 95, Iter: 92160/100000, Loss: 0.02017268\n",
      "Avg loss: 0.016779700630181228\n",
      "Epoch: 96, Iter: 10240/100000, Loss: 0.017967094\n",
      "Epoch: 96, Iter: 20480/100000, Loss: 0.013742605\n",
      "Epoch: 96, Iter: 30720/100000, Loss: 0.016288916\n",
      "Epoch: 96, Iter: 40960/100000, Loss: 0.017867021\n",
      "Epoch: 96, Iter: 51200/100000, Loss: 0.0158698\n",
      "Epoch: 96, Iter: 61440/100000, Loss: 0.01828793\n",
      "Epoch: 96, Iter: 71680/100000, Loss: 0.019007854\n",
      "Epoch: 96, Iter: 81920/100000, Loss: 0.016994718\n",
      "Epoch: 96, Iter: 92160/100000, Loss: 0.016809104\n",
      "Avg loss: 0.016449124897955004\n",
      "Epoch: 97, Iter: 10240/100000, Loss: 0.014190458\n",
      "Epoch: 97, Iter: 20480/100000, Loss: 0.018645367\n",
      "Epoch: 97, Iter: 30720/100000, Loss: 0.01570401\n",
      "Epoch: 97, Iter: 40960/100000, Loss: 0.018202754\n",
      "Epoch: 97, Iter: 51200/100000, Loss: 0.018603235\n",
      "Epoch: 97, Iter: 61440/100000, Loss: 0.016493758\n",
      "Epoch: 97, Iter: 71680/100000, Loss: 0.016882855\n",
      "Epoch: 97, Iter: 81920/100000, Loss: 0.017522356\n",
      "Epoch: 97, Iter: 92160/100000, Loss: 0.01585567\n",
      "Avg loss: 0.016580376380420838\n",
      "Epoch: 98, Iter: 10240/100000, Loss: 0.014550362\n",
      "Epoch: 98, Iter: 20480/100000, Loss: 0.016092641\n",
      "Epoch: 98, Iter: 30720/100000, Loss: 0.015941937\n",
      "Epoch: 98, Iter: 40960/100000, Loss: 0.020949408\n",
      "Epoch: 98, Iter: 51200/100000, Loss: 0.017626004\n",
      "Epoch: 98, Iter: 61440/100000, Loss: 0.017932665\n",
      "Epoch: 98, Iter: 71680/100000, Loss: 0.016315527\n",
      "Epoch: 98, Iter: 81920/100000, Loss: 0.016200999\n",
      "Epoch: 98, Iter: 92160/100000, Loss: 0.017403511\n",
      "Avg loss: 0.016503562161833355\n",
      "Epoch: 99, Iter: 10240/100000, Loss: 0.014422129\n",
      "Epoch: 99, Iter: 20480/100000, Loss: 0.015465528\n",
      "Epoch: 99, Iter: 30720/100000, Loss: 0.016926154\n",
      "Epoch: 99, Iter: 40960/100000, Loss: 0.016371924\n",
      "Epoch: 99, Iter: 51200/100000, Loss: 0.016898688\n",
      "Epoch: 99, Iter: 61440/100000, Loss: 0.017953249\n",
      "Epoch: 99, Iter: 71680/100000, Loss: 0.01768338\n",
      "Epoch: 99, Iter: 81920/100000, Loss: 0.014292205\n",
      "Epoch: 99, Iter: 92160/100000, Loss: 0.014779538\n",
      "Avg loss: 0.016459472947897985\n",
      "Epoch: 100, Iter: 10240/100000, Loss: 0.016392797\n",
      "Epoch: 100, Iter: 20480/100000, Loss: 0.017636597\n",
      "Epoch: 100, Iter: 30720/100000, Loss: 0.015891712\n",
      "Epoch: 100, Iter: 40960/100000, Loss: 0.015322692\n",
      "Epoch: 100, Iter: 51200/100000, Loss: 0.017490033\n",
      "Epoch: 100, Iter: 61440/100000, Loss: 0.01698088\n",
      "Epoch: 100, Iter: 71680/100000, Loss: 0.017561056\n",
      "Epoch: 100, Iter: 81920/100000, Loss: 0.017840192\n",
      "Epoch: 100, Iter: 92160/100000, Loss: 0.0140994815\n",
      "Avg loss: 0.01622092455011053\n"
     ]
    }
   ],
   "source": [
    "#Verbose after x batches\n",
    "VERBOSE =  10\n",
    "\n",
    "#Define number of epochs\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "println(\"Starting training...\")\n",
    "\n",
    "for i in 1:NUM_EPOCHS\n",
    "    \n",
    "    avg_loss = 0.0\n",
    "    it = 0\n",
    "    for  (k, (obs, action, next_obs)) in enumerate(dtrn)\n",
    "\n",
    "        #Train by using contrastive loss\n",
    "        J = @diff model(obs,action,next_obs)\n",
    "        \n",
    "        for par in params(model)\n",
    "            g = grad(J, par)\n",
    "            update!(value(par), g, par.opt)\n",
    "        end\n",
    "        \n",
    "        batch_size = size(obs,4)\n",
    "\n",
    "        if k % VERBOSE == 0\n",
    "            \n",
    "            println(\"Epoch: \", i , \", Iter: \" , k*batch_size, \"/\", dtrn.num_steps, \", Loss: \", value(J))\n",
    "\n",
    "        end\n",
    "        \n",
    "        avg_loss += value(J)\n",
    "        it = k\n",
    "        \n",
    "    end\n",
    "    \n",
    "    avg_loss /= it\n",
    "    \n",
    "    println(\"Avg loss: \" , avg_loss)\n",
    "end\n",
    "\n",
    "#dtrn = nothing\n",
    "#Knet.gc()\n",
    "#GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrn = nothing\n",
    "Knet.gc()\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Knet.save(\"model_2dshapes_lr.jld2\", \"model\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Knet.load(\"model_2dshapes_lr.jld2\", \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Params\n",
    "EVAL_DATASET_PATH = \"/home/cagan/dev/datasets/C-SWM/shapes_eval.h5\"\n",
    "EVAL_BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst = buildPathDataset(EVAL_DATASET_PATH, EVAL_BATCH_SIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, action,next_obs = first(dtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 batches\n",
      "Processed 20 batches\n",
      "Processed 30 batches\n",
      "Processed 40 batches\n",
      "Processed 50 batches\n",
      "Processed 60 batches\n",
      "Processed 70 batches\n",
      "Processed 80 batches\n",
      "Processed 90 batches\n",
      "Processed 100 batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000×10001 Array{Int64,2}:\n",
       " 1      2  4355  8965  7675  9196  …  8159  1966  9199  9315   740  6317\n",
       " 1      3  1889  9950  8907  5423     8604  5395  6355  8400  8579  8404\n",
       " 1      4  4659  7942  5277  7009     4265  7183  7865  3606   244  4821\n",
       " 1      5  6116   909  6402  4143     5473   612  7376  9736  6204  1936\n",
       " 1      6  9560  8208  5517  2771     9175  7741  3335  9742  8877  3265\n",
       " 1      7  3358  5548  8098  8483  …  1774  2792  6054  5338  8832  4539\n",
       " 1      8  3234  4958  5005  9685     8052  6469  5459  2035  6786  1267\n",
       " 1      9  9993  2864  8466  2183     2615  6202  4693  7354  4781  2735\n",
       " 1     10  7045  7532  8034  3476     6209  6340  8000  8817  5301   392\n",
       " 1     11  8945  1587  9878  5156     1301  7085  9736  4612   612  1936\n",
       " 1     12  3919  6580  3036  3455  …  8870  7327  9319  3259  1741  9526\n",
       " 1     13  1305  7733  6270  2377     7236  5400  9337  1637  6762  2856\n",
       " 1     14  4812  9072  9926  1189     6728  5767  2904  7376  6204  1936\n",
       " ⋮                              ⋮  ⋱     ⋮                             ⋮\n",
       " 1   9990  1549  1607  9691   485     9358   472  1200  4821  2688  7367\n",
       " 1   9991  4208  9714   644  1695     8877  6930  7354  2735  3265  9413\n",
       " 1   9992  2672  8447  3601  8624  …  8851  4367  4980  3098  3303  4693\n",
       " 1   9993  2196  2864     9  5181     4693  4251  5079  7354  4781  2735\n",
       " 1   9994   310  3831  4246  1438     2796  4500  9319  2137  1537  9507\n",
       " 1   9995  5475  1200  4340  9358     1534  3979  7316  8641  4485  9398\n",
       " 1   9996  1829   559  1765  8403      791  2027  8964  6854  9960  2308\n",
       " 1   9997  9374  2767  5726  3747  …  6352  9960  2903  5630  4304  6494\n",
       " 1   9998  2716  5339  8321  9964     6728  8329  1741  8870  9523  7327\n",
       " 1   9999  1522  6613  8841  1437     7448  3265  1100  3566  9768  3286\n",
       " 1  10000  5895  9017  1449  4134     5618  6683  8052  7303  7164  9559\n",
       " 1  10001  4364  3673  2889  4330     9960  2546  6762   791  7236  6220"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_states = Any[]\n",
    "next_states = Any[]\n",
    "\n",
    "num_samples = dtst.dataset_size\n",
    "\n",
    "for  (k, (obs, action, next_obs)) in enumerate(dtst)\n",
    "    \n",
    "    if k % 10 == 0\n",
    "        \n",
    "        println(\"Processed \", k ,\" batches\")\n",
    "        \n",
    "    end\n",
    "    #Obs => (50,50,3,100)\n",
    "    #Next obs => (50,50,3,100)\n",
    "    \n",
    "    pred_state = Array{Float32}(model(obs,action))\n",
    "    next_state = Array{Float32}(model(next_obs))\n",
    "    \n",
    "    #Pred-state => (2,5,100)\n",
    "    #Next state => (2,5,100)\n",
    "    #println(pred_state)\n",
    "    #println(next_state)\n",
    "    \n",
    "    push!(pred_states, pred_state)\n",
    "    push!(next_states, next_state)\n",
    "    \n",
    "end\n",
    "\n",
    "#Pred state cat => [2,5,10000]\n",
    "#Next state cat => [2,5,10000]\n",
    "pred_states = cat(pred_states...,dims=3)\n",
    "next_states = cat(next_states...,dims=3)\n",
    "    \n",
    "#Flatten object/feature dimensions\n",
    "pred_states = mat(pred_states)  #[10,10000]\n",
    "next_states = mat(next_states)  #[10,10000]\n",
    "\n",
    "#Calculate pairwise distances\n",
    "sizes_1 = (size(pred_states)...,1)\n",
    "sizes_2 = (sizes_1[1], sizes_1[3], sizes_1[2])\n",
    "\n",
    "pred_states = reshape(pred_states, sizes_1)\n",
    "next_states = reshape(next_states, sizes_2)\n",
    "pred_states = repeat(pred_states, outer=[1,1,10000])\n",
    "next_states = repeat(next_states, outer=[1,10000,1])\n",
    "\n",
    "pairwise_distance_matrix = sum((pred_states - next_states).^2, dims=1)[1,:,:]\n",
    "\n",
    "#Augment pairwise distance matrix\n",
    "diag_elements = diag(pairwise_distance_matrix)\n",
    "pairwise_distance_matrix = hcat(diag_elements, pairwise_distance_matrix)\n",
    "\n",
    "\n",
    "labels = ones(num_samples)\n",
    "hits_at_1 = 0\n",
    "\n",
    "indices = []\n",
    "\n",
    "for i=1:10000\n",
    "    \n",
    "    row = pairwise_distance_matrix[i,:]\n",
    "    ind = sortperm(row)\n",
    "    \n",
    "    push!(indices, ind)\n",
    "\n",
    "end\n",
    "\n",
    "indices = vcat(indices'...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits @ 1: 0.9892\n"
     ]
    }
   ],
   "source": [
    "num_matches = sum(labels .== indices[:,1])\n",
    "hits_at_1 += num_matches\n",
    "println(\"Hits @ 1: \", hits_at_1/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.99455\n"
     ]
    }
   ],
   "source": [
    "mxval, mxindx = findmax(indices .== labels,dims=2)\n",
    "ranks = [ i[2] for i in mxindx ]\n",
    "reciprocal_ranks = 1 ./ranks\n",
    "rr_sum = sum(reciprocal_ranks)\n",
    "println(\"MRR: \", rr_sum/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits @ 5: 1.0\n"
     ]
    }
   ],
   "source": [
    "num_matches = sum(labels .== indices[:,1:5])\n",
    "println(\"Hits @ 5: \", num_matches/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
