{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C-SWM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libs\n",
    "import Base: iterate, length, GC\n",
    "using HDF5\n",
    "using Knet\n",
    "using Statistics: mean,std\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using Images\n",
    "using Plots\n",
    "\n",
    "#Datatype\n",
    "atype=KnetArray{Float32}\n",
    "\n",
    "#Includes\n",
    "include(\"datasets.jl\")\n",
    "include(\"cswm.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Params\n",
    "input_ch = 3\n",
    "hidden_dim = 512\n",
    "num_objects = 5\n",
    "embedding_dim = 2\n",
    "action_dim = 4\n",
    "sigma = 0.5\n",
    "hinge = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MersenneTwister(UInt32[0x0000002a], Random.DSFMT.DSFMT_state(Int32[964434469, 1073036706, 1860149520, 1073503458, 1687169063, 1073083486, -399267803, 1072983952, -909620556, 1072836235  …  -293054293, 1073002412, -1300127419, 1073642642, 1917177374, -666058738, -337596527, 1830741494, 382, 0]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], UInt128[0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000  …  0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000], 1002, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knet.seed!(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContrastiveSWM(EncoderCNNSmall(Any[P(KnetArray{Float32,4}(10,10,3,32)), P(KnetArray{Float32,4}(1,1,32,5))], Any[P(KnetArray{Float32,4}(1,1,32,1)), P(KnetArray{Float32,4}(1,1,5,1))], Knet.sigm, NNlib.relu), EncoderMLP(Param{KnetArray{Float32,2}}[P(KnetArray{Float32,2}(512,25)), P(KnetArray{Float32,2}(512,512)), P(KnetArray{Float32,2}(2,512))], Param{KnetArray{Float32,1}}[P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(2))], NNlib.relu), TransitionGNN(EdgeMLP(Param{KnetArray{Float32,2}}[P(KnetArray{Float32,2}(512,4)), P(KnetArray{Float32,2}(512,512)), P(KnetArray{Float32,2}(512,512))], Param{KnetArray{Float32,1}}[P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512))], NNlib.relu), NodeMLP(Param{KnetArray{Float32,2}}[P(KnetArray{Float32,2}(512,518)), P(KnetArray{Float32,2}(512,512)), P(KnetArray{Float32,2}(2,512))], Param{KnetArray{Float32,1}}[P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(2))], NNlib.relu), false, false, 4, 2, nothing, 0), 0.5, 1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = initContrastiveSWMSmall(input_ch, hidden_dim, num_objects, embedding_dim, action_dim, sigma, hinge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Building dataset indexing...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATASET_PATH = \"/home/cagan/dev/datasets/moving_mnist/moving_mnist_grid_rgb_trn.h5\"\n",
    "TRAIN_BATCH_SIZE = 1024\n",
    "dtrn = buildStateTransitionDataset(TRAIN_DATASET_PATH, true, TRAIN_BATCH_SIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(KnetArray{Float32,4}(10,10,3,32))\n",
      "P(KnetArray{Float32,4}(1,1,32,5))\n",
      "P(KnetArray{Float32,4}(1,1,32,1))\n",
      "P(KnetArray{Float32,4}(1,1,5,1))\n",
      "P(KnetArray{Float32,2}(512,25))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,2}(2,512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(2))\n",
      "P(KnetArray{Float32,2}(512,4))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,2}(512,518))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,2}(2,512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(2))\n"
     ]
    }
   ],
   "source": [
    "function initopt!(model::ContrastiveSWM)\n",
    "    \n",
    "    for par in params(model)\n",
    "        par.opt = Adam(;lr=0.005, gclip=0, beta1=0.9, beta2=0.999, eps=1e-8)\n",
    "        println(par)\n",
    "    end\n",
    "    end;\n",
    "initopt!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch: 1, Iter: 10240/20000, Loss: 1.1251898\n",
      "Avg loss: 7.401552250510768\n",
      "Epoch: 2, Iter: 10240/20000, Loss: 1.0010705\n",
      "Avg loss: 1.002885313410508\n",
      "Epoch: 3, Iter: 10240/20000, Loss: 0.997013\n",
      "Avg loss: 0.9943950333093342\n",
      "Epoch: 4, Iter: 10240/20000, Loss: 0.8052949\n",
      "Avg loss: 0.9425167378626371\n",
      "Epoch: 5, Iter: 10240/20000, Loss: 0.9671768\n",
      "Avg loss: 1.3861488699913025\n",
      "Epoch: 6, Iter: 10240/20000, Loss: 0.7085877\n",
      "Avg loss: 0.694898900232817\n",
      "Epoch: 7, Iter: 10240/20000, Loss: 0.4142191\n",
      "Avg loss: 0.39922234729716655\n",
      "Epoch: 8, Iter: 10240/20000, Loss: 0.24154577\n",
      "Avg loss: 0.24851803638433156\n",
      "Epoch: 9, Iter: 10240/20000, Loss: 0.16342649\n",
      "Avg loss: 0.16281963022131668\n",
      "Epoch: 10, Iter: 10240/20000, Loss: 0.13602632\n",
      "Avg loss: 0.12938874567809858\n",
      "Epoch: 11, Iter: 10240/20000, Loss: 0.097419724\n",
      "Avg loss: 0.09888830663342225\n",
      "Epoch: 12, Iter: 10240/20000, Loss: 0.07952933\n",
      "Avg loss: 0.0807513041715873\n",
      "Epoch: 13, Iter: 10240/20000, Loss: 0.08100127\n",
      "Avg loss: 0.07866680269178591\n",
      "Epoch: 14, Iter: 10240/20000, Loss: 0.07746571\n",
      "Avg loss: 0.07716217833129983\n",
      "Epoch: 15, Iter: 10240/20000, Loss: 0.077197805\n",
      "Avg loss: 0.07484446426755503\n",
      "Epoch: 16, Iter: 10240/20000, Loss: 0.07539373\n",
      "Avg loss: 0.07426533416697853\n",
      "Epoch: 17, Iter: 10240/20000, Loss: 0.07556656\n",
      "Avg loss: 0.07481691790254492\n",
      "Epoch: 18, Iter: 10240/20000, Loss: 0.07164726\n",
      "Avg loss: 0.07298421036255986\n",
      "Epoch: 19, Iter: 10240/20000, Loss: 0.070284195\n",
      "Avg loss: 0.07191720800964456\n",
      "Epoch: 20, Iter: 10240/20000, Loss: 0.067734495\n",
      "Avg loss: 0.06595709174871445\n",
      "Epoch: 21, Iter: 10240/20000, Loss: 0.056593403\n",
      "Avg loss: 0.05978132529478324\n",
      "Epoch: 22, Iter: 10240/20000, Loss: 0.059436508\n",
      "Avg loss: 0.05746464568533396\n",
      "Epoch: 23, Iter: 10240/20000, Loss: 0.05447116\n",
      "Avg loss: 0.056364356883262336\n",
      "Epoch: 24, Iter: 10240/20000, Loss: 0.056635868\n",
      "Avg loss: 0.056306966041263784\n",
      "Epoch: 25, Iter: 10240/20000, Loss: 0.058046237\n",
      "Avg loss: 0.05590015002771428\n",
      "Epoch: 26, Iter: 10240/20000, Loss: 0.0555523\n",
      "Avg loss: 0.05594376141303464\n",
      "Epoch: 27, Iter: 10240/20000, Loss: 0.055276655\n",
      "Avg loss: 0.05535733013560897\n",
      "Epoch: 28, Iter: 10240/20000, Loss: 0.058179587\n",
      "Avg loss: 0.05690973467732731\n",
      "Epoch: 29, Iter: 10240/20000, Loss: 0.059439845\n",
      "Avg loss: 0.055837405943556837\n",
      "Epoch: 30, Iter: 10240/20000, Loss: 0.055419933\n",
      "Avg loss: 0.05470663544378782\n",
      "Epoch: 31, Iter: 10240/20000, Loss: 0.056615017\n",
      "Avg loss: 0.055732393931401406\n",
      "Epoch: 32, Iter: 10240/20000, Loss: 0.055569798\n",
      "Avg loss: 0.055342397015345726\n",
      "Epoch: 33, Iter: 10240/20000, Loss: 0.05472423\n",
      "Avg loss: 0.054948833035795314\n",
      "Epoch: 34, Iter: 10240/20000, Loss: 0.055021588\n",
      "Avg loss: 0.05635291651675576\n",
      "Epoch: 35, Iter: 10240/20000, Loss: 0.058295257\n",
      "Avg loss: 0.055751932098677286\n",
      "Epoch: 36, Iter: 10240/20000, Loss: 0.051989734\n",
      "Avg loss: 0.054484256396168156\n",
      "Epoch: 37, Iter: 10240/20000, Loss: 0.057402633\n",
      "Avg loss: 0.054842385022263775\n",
      "Epoch: 38, Iter: 10240/20000, Loss: 0.051761713\n",
      "Avg loss: 0.054674140912921804\n",
      "Epoch: 39, Iter: 10240/20000, Loss: 0.053289823\n",
      "Avg loss: 0.05486862851600898\n",
      "Epoch: 40, Iter: 10240/20000, Loss: 0.061610237\n",
      "Avg loss: 0.05513988356841238\n",
      "Epoch: 41, Iter: 10240/20000, Loss: 0.048945025\n",
      "Avg loss: 0.05507333223756991\n",
      "Epoch: 42, Iter: 10240/20000, Loss: 0.054018114\n",
      "Avg loss: 0.05453301495627353\n",
      "Epoch: 43, Iter: 10240/20000, Loss: 0.05411724\n",
      "Avg loss: 0.0538871090270971\n",
      "Epoch: 44, Iter: 10240/20000, Loss: 0.056730118\n",
      "Avg loss: 0.054782832139416746\n",
      "Epoch: 45, Iter: 10240/20000, Loss: 0.056673102\n",
      "Avg loss: 0.05339751490636876\n",
      "Epoch: 46, Iter: 10240/20000, Loss: 0.055660725\n",
      "Avg loss: 0.05402629547997525\n",
      "Epoch: 47, Iter: 10240/20000, Loss: 0.05657541\n",
      "Avg loss: 0.05396754980871552\n",
      "Epoch: 48, Iter: 10240/20000, Loss: 0.055085056\n",
      "Avg loss: 0.053468118764852225\n",
      "Epoch: 49, Iter: 10240/20000, Loss: 0.061014462\n",
      "Avg loss: 0.054257034863296305\n",
      "Epoch: 50, Iter: 10240/20000, Loss: 0.05327531\n",
      "Avg loss: 0.053384924013363685\n",
      "Epoch: 51, Iter: 10240/20000, Loss: 0.05083082\n",
      "Avg loss: 0.05353640706131333\n",
      "Epoch: 52, Iter: 10240/20000, Loss: 0.052411713\n",
      "Avg loss: 0.05219678051377598\n",
      "Epoch: 53, Iter: 10240/20000, Loss: 0.056507096\n",
      "Avg loss: 0.0529154156775851\n",
      "Epoch: 54, Iter: 10240/20000, Loss: 0.05694236\n",
      "Avg loss: 0.052604303744278456\n",
      "Epoch: 55, Iter: 10240/20000, Loss: 0.052134693\n",
      "Avg loss: 0.05363585956786808\n",
      "Epoch: 56, Iter: 10240/20000, Loss: 0.05222229\n",
      "Avg loss: 0.05231877710474165\n",
      "Epoch: 57, Iter: 10240/20000, Loss: 0.053430736\n",
      "Avg loss: 0.05168619908784565\n",
      "Epoch: 58, Iter: 10240/20000, Loss: 0.056037564\n",
      "Avg loss: 0.052649901689667454\n",
      "Epoch: 59, Iter: 10240/20000, Loss: 0.052671116\n",
      "Avg loss: 0.05124692050249953\n",
      "Epoch: 60, Iter: 10240/20000, Loss: 0.05232301\n",
      "Avg loss: 0.050810034533864575\n",
      "Epoch: 61, Iter: 10240/20000, Loss: 0.05306599\n",
      "Avg loss: 0.050601775512883536\n",
      "Epoch: 62, Iter: 10240/20000, Loss: 0.050108615\n",
      "Avg loss: 0.050678015539520664\n",
      "Epoch: 63, Iter: 10240/20000, Loss: 0.051491432\n",
      "Avg loss: 0.04994158564429534\n",
      "Epoch: 64, Iter: 10240/20000, Loss: 0.05389683\n",
      "Avg loss: 0.05023299373294178\n",
      "Epoch: 65, Iter: 10240/20000, Loss: 0.053806994\n",
      "Avg loss: 0.05084682804973502\n",
      "Epoch: 66, Iter: 10240/20000, Loss: 0.050378382\n",
      "Avg loss: 0.05077929441866122\n",
      "Epoch: 67, Iter: 10240/20000, Loss: 0.05477272\n",
      "Avg loss: 0.05053022346998516\n",
      "Epoch: 68, Iter: 10240/20000, Loss: 0.048395395\n",
      "Avg loss: 0.04846966678374692\n",
      "Epoch: 69, Iter: 10240/20000, Loss: 0.05000233\n",
      "Avg loss: 0.05005320573323652\n",
      "Epoch: 70, Iter: 10240/20000, Loss: 0.04700969\n",
      "Avg loss: 0.049198516497486515\n",
      "Epoch: 71, Iter: 10240/20000, Loss: 0.051732972\n",
      "Avg loss: 0.049441086618523845\n",
      "Epoch: 72, Iter: 10240/20000, Loss: 0.051168684\n",
      "Avg loss: 0.04846647068073875\n",
      "Epoch: 73, Iter: 10240/20000, Loss: 0.051536944\n",
      "Avg loss: 0.0479674384390053\n",
      "Epoch: 74, Iter: 10240/20000, Loss: 0.051660046\n",
      "Avg loss: 0.04855445321453245\n",
      "Epoch: 75, Iter: 10240/20000, Loss: 0.047653843\n",
      "Avg loss: 0.04920896103507594\n",
      "Epoch: 76, Iter: 10240/20000, Loss: 0.045776993\n",
      "Avg loss: 0.04807431407664951\n",
      "Epoch: 77, Iter: 10240/20000, Loss: 0.053164847\n",
      "Avg loss: 0.04815217832985677\n",
      "Epoch: 78, Iter: 10240/20000, Loss: 0.04887411\n",
      "Avg loss: 0.048332822754194864\n",
      "Epoch: 79, Iter: 10240/20000, Loss: 0.05840696\n",
      "Avg loss: 0.04786477884963939\n",
      "Epoch: 80, Iter: 10240/20000, Loss: 0.047297977\n",
      "Avg loss: 0.04743112800152678\n",
      "Epoch: 81, Iter: 10240/20000, Loss: 0.04529144\n",
      "Avg loss: 0.048082699312975534\n",
      "Epoch: 82, Iter: 10240/20000, Loss: 0.050447267\n",
      "Avg loss: 0.04820191997446512\n",
      "Epoch: 83, Iter: 10240/20000, Loss: 0.04914844\n",
      "Avg loss: 0.04688198531144544\n",
      "Epoch: 84, Iter: 10240/20000, Loss: 0.04913473\n",
      "Avg loss: 0.04834099211975148\n",
      "Epoch: 85, Iter: 10240/20000, Loss: 0.048243903\n",
      "Avg loss: 0.0471773206403381\n",
      "Epoch: 86, Iter: 10240/20000, Loss: 0.047857728\n",
      "Avg loss: 0.04841069504618645\n",
      "Epoch: 87, Iter: 10240/20000, Loss: 0.046519686\n",
      "Avg loss: 0.048724512520589326\n",
      "Epoch: 88, Iter: 10240/20000, Loss: 0.051647328\n",
      "Avg loss: 0.04869267638576658\n",
      "Epoch: 89, Iter: 10240/20000, Loss: 0.046589687\n",
      "Avg loss: 0.04770619324163387\n",
      "Epoch: 90, Iter: 10240/20000, Loss: 0.051035084\n",
      "Avg loss: 0.04865435785368869\n",
      "Epoch: 91, Iter: 10240/20000, Loss: 0.052043244\n",
      "Avg loss: 0.04806187984190489\n",
      "Epoch: 92, Iter: 10240/20000, Loss: 0.047994148\n",
      "Avg loss: 0.04699810888422163\n",
      "Epoch: 93, Iter: 10240/20000, Loss: 0.046955287\n",
      "Avg loss: 0.047523140711219686\n",
      "Epoch: 94, Iter: 10240/20000, Loss: 0.049690805\n",
      "Avg loss: 0.04812585327186083\n",
      "Epoch: 95, Iter: 10240/20000, Loss: 0.0489417\n",
      "Avg loss: 0.04736067099790824\n",
      "Epoch: 96, Iter: 10240/20000, Loss: 0.048293233\n",
      "Avg loss: 0.0472709852221765\n",
      "Epoch: 97, Iter: 10240/20000, Loss: 0.049215168\n",
      "Avg loss: 0.047333320504740664\n",
      "Epoch: 98, Iter: 10240/20000, Loss: 0.05443891\n",
      "Avg loss: 0.04763707244082501\n",
      "Epoch: 99, Iter: 10240/20000, Loss: 0.045272842\n",
      "Avg loss: 0.04614224088819403\n",
      "Epoch: 100, Iter: 10240/20000, Loss: 0.04873958\n",
      "Avg loss: 0.047639706221066024\n"
     ]
    }
   ],
   "source": [
    "#Verbose after x batches\n",
    "VERBOSE =  10\n",
    "\n",
    "#Define number of epochs\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "println(\"Starting training...\")\n",
    "\n",
    "for i in 1:NUM_EPOCHS\n",
    "    \n",
    "    avg_loss = 0.0\n",
    "    it = 0\n",
    "    for  (k, (obs, action, next_obs)) in enumerate(dtrn)\n",
    "\n",
    "        #Train by using contrastive loss\n",
    "        J = @diff model(obs,action,next_obs)\n",
    "        \n",
    "        for par in params(model)\n",
    "            g = grad(J, par)\n",
    "            update!(value(par), g, par.opt)\n",
    "        end\n",
    "        \n",
    "        batch_size = size(obs,4)\n",
    "\n",
    "        if k % VERBOSE == 0\n",
    "            \n",
    "            println(\"Epoch: \", i , \", Iter: \" , k*batch_size, \"/\", dtrn.num_steps, \", Loss: \", value(J))\n",
    "\n",
    "        end\n",
    "        \n",
    "        avg_loss += value(J)\n",
    "        it = k\n",
    "        \n",
    "    end\n",
    "    \n",
    "    avg_loss /= it\n",
    "    \n",
    "    println(\"Avg loss: \" , avg_loss)\n",
    "end\n",
    "\n",
    "#dtrn = nothing\n",
    "#Knet.gc()\n",
    "#GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrn = nothing\n",
    "Knet.gc()\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Knet.save(\"model_moving_mnist_2.jld2\", \"model\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Knet.load(\"model_2dshapes.jld2\", \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Params\n",
    "EVAL_DATASET_PATH = \"/home/cagan/dev/datasets/moving_mnist/moving_mnist_grid_rgb_tst.h5\"\n",
    "EVAL_BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst = buildPathDataset(EVAL_DATASET_PATH, EVAL_BATCH_SIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, action,next_obs = first(dtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000×1001 Array{Int64,2}:\n",
       " 1     2  466  353   400  465  765    3  …  544  520  136  522  839  901  521\n",
       " 1     3  353    4     2   39  352  805     492  544  803  494  931  493  521\n",
       " 1     4  352    3   805  171  485   51     544  813  130  522  324  204  931\n",
       " 1     5    6  349   106  805  353    4     324  839  931  521  204  522   55\n",
       " 1     6    5  106   634  349  768    7     324  374  753  840  378   55  839\n",
       " 1     7    8  483   970  288  634  106  …  625  883  375  887  374  204  839\n",
       " 1     8    7  288   540  289  969  577     411  378  412  377  208  625  626\n",
       " 1     9   10  110   241  109  434  771     715  681  680  730  625  729  626\n",
       " 1    10    9  771   241  577  109  578     160  715  625  680  134  729  626\n",
       " 1    11  947  481   944  541  543  542     986  729  699  701  626  261  160\n",
       " 1    12   52  854   533  243   14  935  …  160  987  986  626  637  157  258\n",
       " 1    13  249  449   448  446  238  711     637  258  405   45   64   43  640\n",
       " 1    14  347   12   449   13  286  963     150  157  986  158  160  261  626\n",
       " ⋮                          ⋮            ⋱         ⋮                        ⋮\n",
       " 1   990  991  992   993  862  439  440     392  189  593  744  688  183  394\n",
       " 1   991  990  992   403  310  193  994     421  781  593  688  942  797  950\n",
       " 1   992  993  990   439  403  991  440  …  392  631  689  394  621  681  688\n",
       " 1   993  992  439   403  440  990  438     283  689  688  394  621  680  681\n",
       " 1   994  995  831   812  862  985  915     798   65  950  969  797  592  617\n",
       " 1   995  994  739   724  636  116  329     593  591  943  785  165  969  592\n",
       " 1   996  862  831   997  912  994  642     531  285  521  681  901  631  729\n",
       " 1   997  912  862   996  809  998  401  …  521  383  181  669  180  382  901\n",
       " 1   998  997  843   918  401  298  912     729  382  180  521  669  753  901\n",
       " 1   999  925  924  1001  402   66  829     715  702  753  984  680  729  681\n",
       " 1  1000  673  317   516  672  239  363     160  136  680  141  521  134  803\n",
       " 1  1001   66  925   924   68  224  999     699  702  984  730  680  681  729"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_states = Any[]\n",
    "next_states = Any[]\n",
    "\n",
    "num_samples = dtst.dataset_size\n",
    "\n",
    "for  (k, (obs, action, next_obs)) in enumerate(dtst)\n",
    "    \n",
    "    if k % 10 == 0\n",
    "        \n",
    "        println(\"Processed \", k ,\" batches\")\n",
    "        \n",
    "    end\n",
    "    #Obs => (50,50,3,100)\n",
    "    #Next obs => (50,50,3,100)\n",
    "    \n",
    "    pred_state = Array{Float32}(model(obs,action))\n",
    "    next_state = Array{Float32}(model(next_obs))\n",
    "    \n",
    "    #Pred-state => (2,5,100)\n",
    "    #Next state => (2,5,100)\n",
    "    #println(pred_state)\n",
    "    #println(next_state)\n",
    "    \n",
    "    push!(pred_states, pred_state)\n",
    "    push!(next_states, next_state)\n",
    "    \n",
    "end\n",
    "\n",
    "#Pred state cat => [2,5,10000]\n",
    "#Next state cat => [2,5,10000]\n",
    "pred_states = cat(pred_states...,dims=3)\n",
    "next_states = cat(next_states...,dims=3)\n",
    "    \n",
    "#Flatten object/feature dimensions\n",
    "pred_states = mat(pred_states)  #[10,10000]\n",
    "next_states = mat(next_states)  #[10,10000]\n",
    "\n",
    "#Calculate pairwise distances\n",
    "sizes_1 = (size(pred_states)...,1)\n",
    "sizes_2 = (sizes_1[1], sizes_1[3], sizes_1[2])\n",
    "\n",
    "pred_states = reshape(pred_states, sizes_1)\n",
    "next_states = reshape(next_states, sizes_2)\n",
    "pred_states = repeat(pred_states, outer=[1,1,1000])\n",
    "next_states = repeat(next_states, outer=[1,1000,1])\n",
    "\n",
    "pairwise_distance_matrix = sum((pred_states - next_states).^2, dims=1)[1,:,:]\n",
    "\n",
    "#Augment pairwise distance matrix\n",
    "diag_elements = diag(pairwise_distance_matrix)\n",
    "pairwise_distance_matrix = hcat(diag_elements, pairwise_distance_matrix)\n",
    "\n",
    "\n",
    "labels = ones(num_samples)\n",
    "hits_at_1 = 0\n",
    "\n",
    "indices = []\n",
    "\n",
    "for i=1:1000\n",
    "    \n",
    "    row = pairwise_distance_matrix[i,:]\n",
    "    ind = sortperm(row)\n",
    "    \n",
    "    push!(indices, ind)\n",
    "\n",
    "end\n",
    "\n",
    "indices = vcat(indices'...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits @ 1: 0.996\n"
     ]
    }
   ],
   "source": [
    "num_matches = sum(labels .== indices[:,1])\n",
    "hits_at_1 += num_matches\n",
    "println(\"Hits @ 1: \", hits_at_1/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_matches = sum(labels .== indices[:,5])\n",
    "println(\"Hits @ 1: \", num_matches/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.998\n"
     ]
    }
   ],
   "source": [
    "mxval, mxindx = findmax(indices .== labels,dims=2)\n",
    "ranks = [ i[2] for i in mxindx ]\n",
    "reciprocal_ranks = 1 ./ranks\n",
    "rr_sum = sum(reciprocal_ranks)\n",
    "println(\"MRR: \", rr_sum/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
