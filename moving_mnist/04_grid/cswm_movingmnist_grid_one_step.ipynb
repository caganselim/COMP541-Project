{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C-SWM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libs\n",
    "import Base: iterate, length, GC\n",
    "using HDF5\n",
    "using Knet\n",
    "using Statistics: mean,std\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using Images\n",
    "using Plots\n",
    "\n",
    "#Datatype\n",
    "atype=KnetArray{Float32}\n",
    "\n",
    "#Includes\n",
    "include(\"datasets.jl\")\n",
    "include(\"cswm.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Params\n",
    "input_ch = 3\n",
    "hidden_dim = 512\n",
    "num_objects = 5\n",
    "embedding_dim = 2\n",
    "action_dim = 4\n",
    "sigma = 0.5\n",
    "hinge = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MersenneTwister(UInt32[0x0000002a], Random.DSFMT.DSFMT_state(Int32[964434469, 1073036706, 1860149520, 1073503458, 1687169063, 1073083486, -399267803, 1072983952, -909620556, 1072836235  …  -293054293, 1073002412, -1300127419, 1073642642, 1917177374, -666058738, -337596527, 1830741494, 382, 0]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], UInt128[0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000  …  0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000, 0x00000000000000000000000000000000], 1002, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Knet.seed!(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContrastiveSWM(EncoderCNNSmall(Any[P(KnetArray{Float32,4}(10,10,3,32)), P(KnetArray{Float32,4}(1,1,32,5))], Any[P(KnetArray{Float32,4}(1,1,32,1)), P(KnetArray{Float32,4}(1,1,5,1))], Any[Knet.BNMoments(0.1, nothing, nothing, zeros, ones), K32(64)[1.0⋯]], Knet.sigm, NNlib.relu), EncoderMLP(Param{KnetArray{Float32,2}}[P(KnetArray{Float32,2}(512,25)), P(KnetArray{Float32,2}(512,512)), P(KnetArray{Float32,2}(2,512))], Param{KnetArray{Float32,1}}[P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(2))], LayerNorm(P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), 1.0e-5), NNlib.relu), TransitionGNN(EdgeMLP(Param{KnetArray{Float32,2}}[P(KnetArray{Float32,2}(512,4)), P(KnetArray{Float32,2}(512,512)), P(KnetArray{Float32,2}(512,512))], Param{KnetArray{Float32,1}}[P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512))], LayerNorm(P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), 1.0e-5), NNlib.relu), NodeMLP(Param{KnetArray{Float32,2}}[P(KnetArray{Float32,2}(512,518)), P(KnetArray{Float32,2}(512,512)), P(KnetArray{Float32,2}(2,512))], Param{KnetArray{Float32,1}}[P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(2))], LayerNorm(P(KnetArray{Float32,1}(512)), P(KnetArray{Float32,1}(512)), 1.0e-5), NNlib.relu), false, false, 4, 2, nothing, 0), 0.5, 1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = initContrastiveSWMSmall(input_ch, hidden_dim, num_objects, embedding_dim, action_dim, sigma, hinge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Building dataset indexing...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATASET_PATH = \"/home/cagan/dev/datasets/moving_mnist/moving_mnist_grid_rgb_trn.h5\"\n",
    "TRAIN_BATCH_SIZE = 1024\n",
    "dtrn = buildStateTransitionDataset(TRAIN_DATASET_PATH, true, TRAIN_BATCH_SIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(KnetArray{Float32,4}(10,10,3,32))\n",
      "P(KnetArray{Float32,4}(1,1,32,5))\n",
      "P(KnetArray{Float32,4}(1,1,32,1))\n",
      "P(KnetArray{Float32,4}(1,1,5,1))\n",
      "P(KnetArray{Float32,2}(512,25))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,2}(2,512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(2))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,2}(512,4))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,2}(512,518))\n",
      "P(KnetArray{Float32,2}(512,512))\n",
      "P(KnetArray{Float32,2}(2,512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(2))\n",
      "P(KnetArray{Float32,1}(512))\n",
      "P(KnetArray{Float32,1}(512))\n"
     ]
    }
   ],
   "source": [
    "function initopt!(model::ContrastiveSWM)\n",
    "    \n",
    "    for par in params(model)\n",
    "        par.opt = Adam(;lr=0.005, gclip=0, beta1=0.9, beta2=0.999, eps=1e-8)\n",
    "        println(par)\n",
    "    end\n",
    "    end;\n",
    "initopt!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch: 1, Iter: 10240/20000, Loss: 0.9514172\n",
      "Avg loss: 6.863074688534987\n",
      "Epoch: 2, Iter: 10240/20000, Loss: 0.18139908\n",
      "Avg loss: 0.18826909833832792\n",
      "Epoch: 3, Iter: 10240/20000, Loss: 0.116789125\n",
      "Avg loss: 0.11346797527451265\n",
      "Epoch: 4, Iter: 10240/20000, Loss: 0.0963233\n",
      "Avg loss: 0.09704169434936423\n",
      "Epoch: 5, Iter: 10240/20000, Loss: 0.085077964\n",
      "Avg loss: 0.09010425680562069\n",
      "Epoch: 6, Iter: 10240/20000, Loss: 0.084278196\n",
      "Avg loss: 0.0870123070321585\n",
      "Epoch: 7, Iter: 10240/20000, Loss: 0.07985832\n",
      "Avg loss: 0.08373006001899116\n",
      "Epoch: 8, Iter: 10240/20000, Loss: 0.07813772\n",
      "Avg loss: 0.0811252394004872\n",
      "Epoch: 9, Iter: 10240/20000, Loss: 0.08114657\n",
      "Avg loss: 0.07777491839308488\n",
      "Epoch: 10, Iter: 10240/20000, Loss: 0.07449424\n",
      "Avg loss: 0.07450536991420545\n",
      "Epoch: 11, Iter: 10240/20000, Loss: 0.071430236\n",
      "Avg loss: 0.07321869660364955\n",
      "Epoch: 12, Iter: 10240/20000, Loss: 0.0686867\n",
      "Avg loss: 0.06911837740948326\n",
      "Epoch: 13, Iter: 10240/20000, Loss: 0.070095435\n",
      "Avg loss: 0.06832703359817204\n",
      "Epoch: 14, Iter: 10240/20000, Loss: 0.067254946\n",
      "Avg loss: 0.06701348074956943\n",
      "Epoch: 15, Iter: 10240/20000, Loss: 0.06752656\n",
      "Avg loss: 0.06344621216780261\n",
      "Epoch: 16, Iter: 10240/20000, Loss: 0.06664181\n",
      "Avg loss: 0.06266922052753598\n",
      "Epoch: 17, Iter: 10240/20000, Loss: 0.06646014\n",
      "Avg loss: 0.062475517000022684\n",
      "Epoch: 18, Iter: 10240/20000, Loss: 0.06477139\n",
      "Avg loss: 0.06390578750717013\n",
      "Epoch: 19, Iter: 10240/20000, Loss: 0.05945581\n",
      "Avg loss: 0.0635578926456602\n",
      "Epoch: 20, Iter: 10240/20000, Loss: 0.06359704\n",
      "Avg loss: 0.06269469680754762\n",
      "Epoch: 21, Iter: 10240/20000, Loss: 0.060606092\n",
      "Avg loss: 0.06101527221893009\n",
      "Epoch: 22, Iter: 10240/20000, Loss: 0.06531513\n",
      "Avg loss: 0.06228906641665258\n",
      "Epoch: 23, Iter: 10240/20000, Loss: 0.06059585\n",
      "Avg loss: 0.06182632379625973\n",
      "Epoch: 24, Iter: 10240/20000, Loss: 0.058972426\n",
      "Avg loss: 0.06169108124940019\n",
      "Epoch: 25, Iter: 10240/20000, Loss: 0.061588705\n",
      "Avg loss: 0.060459994956066736\n",
      "Epoch: 26, Iter: 10240/20000, Loss: 0.059985895\n",
      "Avg loss: 0.06021249392314961\n",
      "Epoch: 27, Iter: 10240/20000, Loss: 0.059931837\n",
      "Avg loss: 0.05959756005751459\n",
      "Epoch: 28, Iter: 10240/20000, Loss: 0.061163984\n",
      "Avg loss: 0.0606125614752895\n",
      "Epoch: 29, Iter: 10240/20000, Loss: 0.06356848\n",
      "Avg loss: 0.05956598626155602\n",
      "Epoch: 30, Iter: 10240/20000, Loss: 0.05637844\n",
      "Avg loss: 0.057448538510422954\n",
      "Epoch: 31, Iter: 10240/20000, Loss: 0.055245437\n",
      "Avg loss: 0.05770047754049301\n",
      "Epoch: 32, Iter: 10240/20000, Loss: 0.05630876\n",
      "Avg loss: 0.057380705679717814\n",
      "Epoch: 33, Iter: 10240/20000, Loss: 0.056194287\n",
      "Avg loss: 0.056419384322668374\n",
      "Epoch: 34, Iter: 10240/20000, Loss: 0.058517084\n",
      "Avg loss: 0.057523730946214574\n",
      "Epoch: 35, Iter: 10240/20000, Loss: 0.05973363\n",
      "Avg loss: 0.05893477660260702\n",
      "Epoch: 36, Iter: 10240/20000, Loss: 0.053013884\n",
      "Avg loss: 0.057102833531404794\n",
      "Epoch: 37, Iter: 10240/20000, Loss: 0.058187224\n",
      "Avg loss: 0.055894549739988225\n",
      "Epoch: 38, Iter: 10240/20000, Loss: 0.054385014\n",
      "Avg loss: 0.055720423593332895\n",
      "Epoch: 39, Iter: 10240/20000, Loss: 0.05344419\n",
      "Avg loss: 0.05521618221935473\n",
      "Epoch: 40, Iter: 10240/20000, Loss: 0.060760275\n",
      "Avg loss: 0.05527942333566515\n",
      "Epoch: 41, Iter: 10240/20000, Loss: 0.05208631\n",
      "Avg loss: 0.05563542482100035\n",
      "Epoch: 42, Iter: 10240/20000, Loss: 0.05456956\n",
      "Avg loss: 0.05579137998191934\n",
      "Epoch: 43, Iter: 10240/20000, Loss: 0.053909898\n",
      "Avg loss: 0.054882224845258815\n",
      "Epoch: 44, Iter: 10240/20000, Loss: 0.05768032\n",
      "Avg loss: 0.053930048683756275\n",
      "Epoch: 45, Iter: 10240/20000, Loss: 0.053860307\n",
      "Avg loss: 0.05232601357918037\n",
      "Epoch: 46, Iter: 10240/20000, Loss: 0.058506817\n",
      "Avg loss: 0.05462969035694474\n",
      "Epoch: 47, Iter: 10240/20000, Loss: 0.05723664\n",
      "Avg loss: 0.053318953827807776\n",
      "Epoch: 48, Iter: 10240/20000, Loss: 0.05453172\n",
      "Avg loss: 0.05201932121264307\n",
      "Epoch: 49, Iter: 10240/20000, Loss: 0.061155535\n",
      "Avg loss: 0.05282129464965118\n",
      "Epoch: 50, Iter: 10240/20000, Loss: 0.050921775\n",
      "Avg loss: 0.05170650917448496\n",
      "Epoch: 51, Iter: 10240/20000, Loss: 0.04893686\n",
      "Avg loss: 0.05157365238195971\n",
      "Epoch: 52, Iter: 10240/20000, Loss: 0.051417015\n",
      "Avg loss: 0.05061909144646243\n",
      "Epoch: 53, Iter: 10240/20000, Loss: 0.048926845\n",
      "Avg loss: 0.04986150876471871\n",
      "Epoch: 54, Iter: 10240/20000, Loss: 0.05256973\n",
      "Avg loss: 0.05007196609911166\n",
      "Epoch: 55, Iter: 10240/20000, Loss: 0.052083567\n",
      "Avg loss: 0.05113399166025614\n",
      "Epoch: 56, Iter: 10240/20000, Loss: 0.05303987\n",
      "Avg loss: 0.050681599464855696\n",
      "Epoch: 57, Iter: 10240/20000, Loss: 0.049207285\n",
      "Avg loss: 0.04949451728086723\n",
      "Epoch: 58, Iter: 10240/20000, Loss: 0.051277578\n",
      "Avg loss: 0.04983423473803621\n",
      "Epoch: 59, Iter: 10240/20000, Loss: 0.05217221\n",
      "Avg loss: 0.0475560142413566\n",
      "Epoch: 60, Iter: 10240/20000, Loss: 0.04869043\n",
      "Avg loss: 0.047522031358982385\n",
      "Epoch: 61, Iter: 10240/20000, Loss: 0.04916223\n",
      "Avg loss: 0.046248228730339756\n",
      "Epoch: 62, Iter: 10240/20000, Loss: 0.044759247\n",
      "Avg loss: 0.04577369458581272\n",
      "Epoch: 63, Iter: 10240/20000, Loss: 0.044884764\n",
      "Avg loss: 0.04390593814222436\n",
      "Epoch: 64, Iter: 10240/20000, Loss: 0.044812933\n",
      "Avg loss: 0.04256711802200267\n",
      "Epoch: 65, Iter: 10240/20000, Loss: 0.044178743\n",
      "Avg loss: 0.042266504741028735\n",
      "Epoch: 66, Iter: 10240/20000, Loss: 0.043075603\n",
      "Avg loss: 0.0463380892025797\n",
      "Epoch: 67, Iter: 10240/20000, Loss: 0.06785205\n",
      "Avg loss: 0.11711213855366957\n",
      "Epoch: 68, Iter: 10240/20000, Loss: 0.060254\n",
      "Avg loss: 0.082896980211923\n",
      "Epoch: 69, Iter: 10240/20000, Loss: 0.05041214\n",
      "Avg loss: 0.05049167553845205\n",
      "Epoch: 70, Iter: 10240/20000, Loss: 0.10166111\n",
      "Avg loss: 0.054048208813918266\n",
      "Epoch: 71, Iter: 10240/20000, Loss: 0.082015775\n",
      "Avg loss: 0.08043000651033301\n",
      "Epoch: 72, Iter: 10240/20000, Loss: 0.046683405\n",
      "Avg loss: 0.05583835393190384\n",
      "Epoch: 73, Iter: 10240/20000, Loss: 0.08710539\n",
      "Avg loss: 0.09137187839338654\n",
      "Epoch: 74, Iter: 10240/20000, Loss: 0.14432669\n",
      "Avg loss: 0.06987070821617779\n",
      "Epoch: 75, Iter: 10240/20000, Loss: 0.050484322\n",
      "Avg loss: 0.06547552288362854\n",
      "Epoch: 76, Iter: 10240/20000, Loss: 0.049263272\n",
      "Avg loss: 0.06131984058179354\n",
      "Epoch: 77, Iter: 10240/20000, Loss: 0.09273309\n",
      "Avg loss: 0.08148937986085289\n",
      "Epoch: 78, Iter: 10240/20000, Loss: 0.04838839\n",
      "Avg loss: 0.0546425100612013\n",
      "Epoch: 79, Iter: 10240/20000, Loss: 0.049985055\n",
      "Avg loss: 0.05543071443313047\n",
      "Epoch: 80, Iter: 10240/20000, Loss: 0.04855751\n",
      "Avg loss: 0.05092241791518111\n",
      "Epoch: 81, Iter: 10240/20000, Loss: 0.056972783\n",
      "Avg loss: 0.070297353949986\n",
      "Epoch: 82, Iter: 10240/20000, Loss: 0.056629635\n",
      "Avg loss: 0.061096923523827604\n",
      "Epoch: 83, Iter: 10240/20000, Loss: 0.049202863\n",
      "Avg loss: 0.048997262002606144\n",
      "Epoch: 84, Iter: 10240/20000, Loss: 0.057481863\n",
      "Avg loss: 0.053339497627396336\n",
      "Epoch: 85, Iter: 10240/20000, Loss: 0.047988676\n",
      "Avg loss: 0.0482161384271948\n",
      "Epoch: 86, Iter: 10240/20000, Loss: 0.03915728\n",
      "Avg loss: 0.04148777515480393\n",
      "Epoch: 87, Iter: 10240/20000, Loss: 0.038309187\n",
      "Avg loss: 0.04365199765092448\n",
      "Epoch: 88, Iter: 10240/20000, Loss: 0.04087779\n",
      "Avg loss: 0.045088785847550945\n",
      "Epoch: 89, Iter: 10240/20000, Loss: 0.04504939\n",
      "Avg loss: 0.04275417367094442\n",
      "Epoch: 90, Iter: 10240/20000, Loss: 0.06688088\n",
      "Avg loss: 0.06705764426212561\n",
      "Epoch: 91, Iter: 10240/20000, Loss: 0.057721652\n",
      "Avg loss: 0.059329357586408914\n",
      "Epoch: 92, Iter: 10240/20000, Loss: 0.041595563\n",
      "Avg loss: 0.0476980623053877\n",
      "Epoch: 93, Iter: 10240/20000, Loss: 0.044163816\n",
      "Avg loss: 0.04669805047543425\n",
      "Epoch: 94, Iter: 10240/20000, Loss: 0.045082226\n",
      "Avg loss: 0.04654428068744509\n",
      "Epoch: 95, Iter: 10240/20000, Loss: 0.043381456\n",
      "Avg loss: 0.04636048133436002\n",
      "Epoch: 96, Iter: 10240/20000, Loss: 0.041797496\n",
      "Avg loss: 0.04369390206901651\n",
      "Epoch: 97, Iter: 10240/20000, Loss: 0.038874034\n",
      "Avg loss: 0.03982133320287654\n",
      "Epoch: 98, Iter: 10240/20000, Loss: 0.056290355\n",
      "Avg loss: 0.04880699868264951\n",
      "Epoch: 99, Iter: 10240/20000, Loss: 0.045600943\n",
      "Avg loss: 0.04298236221075058\n",
      "Epoch: 100, Iter: 10240/20000, Loss: 0.038935438\n",
      "Avg loss: 0.04028157909449778\n"
     ]
    }
   ],
   "source": [
    "#Verbose after x batches\n",
    "VERBOSE =  10\n",
    "\n",
    "#Define number of epochs\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "println(\"Starting training...\")\n",
    "\n",
    "for i in 1:NUM_EPOCHS\n",
    "    \n",
    "    avg_loss = 0.0\n",
    "    it = 0\n",
    "    for  (k, (obs, action, next_obs)) in enumerate(dtrn)\n",
    "\n",
    "        #Train by using contrastive loss\n",
    "        J = @diff model(obs,action,next_obs)\n",
    "        \n",
    "        for par in params(model)\n",
    "            g = grad(J, par)\n",
    "            update!(value(par), g, par.opt)\n",
    "        end\n",
    "        \n",
    "        batch_size = size(obs,4)\n",
    "\n",
    "        if k % VERBOSE == 0\n",
    "            \n",
    "            println(\"Epoch: \", i , \", Iter: \" , k*batch_size, \"/\", dtrn.num_steps, \", Loss: \", value(J))\n",
    "\n",
    "        end\n",
    "        \n",
    "        avg_loss += value(J)\n",
    "        it = k\n",
    "        \n",
    "    end\n",
    "    \n",
    "    avg_loss /= it\n",
    "    \n",
    "    println(\"Avg loss: \" , avg_loss)\n",
    "end\n",
    "\n",
    "#dtrn = nothing\n",
    "#Knet.gc()\n",
    "#GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrn = nothing\n",
    "Knet.gc()\n",
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Knet.save(\"model_2dshapes_moving_mnist.jld2\", \"model\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Knet.load(\"model_2dshapes_moving_mnist.jld2\", \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Params\n",
    "EVAL_DATASET_PATH = \"/home/cagan/dev/datasets/moving_mnist/moving_mnist_grid_rgb_tst.h5\"\n",
    "EVAL_BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtst = buildPathDataset(EVAL_DATASET_PATH, EVAL_BATCH_SIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, action,next_obs = first(dtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000×1001 Array{Int64,2}:\n",
       "  1     2   466  976  890  467  465  …  530  802   89  930  803  849   55\n",
       "  1     3   771    4  485  577  308     614  931  530  616   57  803   55\n",
       "  1     4    96  475    3  602  485     204  165   57  130  931   55  628\n",
       "  1     5     6  107  421  353   82     930  522  204  130  374   55  628\n",
       "  1     6     5   82    4  634  305     930  130  204  931  374   55  628\n",
       "  1     7   970  805  422  293    8  …  376  871  204  235  374  375  628\n",
       "  1     8   288  978  749  287    7     376  204  857  375  612   61  628\n",
       "  1     9    10  945   11  287  111      90  625  148  521   89  626  628\n",
       "  1    10     9  288  946  287  945     803  196  529  521   90  628   89\n",
       "  1    11   542  968  543  947    9     628  197  626  637  196   89  148\n",
       "  1    12   935   11   52  941  243  …  295  626  154  986  160  637  148\n",
       "  1    13   446  482  238  497  448     778  788  766  298  637  148  640\n",
       "  1    14   749  249  946  286   11     130  609  160  803  627   89  628\n",
       "  ⋮                          ⋮       ⋱         ⋮                        ⋮\n",
       "  1   990   992  831  993  991  157     243  183   79  285  688  189  631\n",
       "  1   991   831  990  834   21  829     613   75  354  688  631  285  614\n",
       "  1   992   993  990  831  403  991  …  689  183  283  621  688  189  631\n",
       "  1   993   992  990  439  403  438     354  618  285  631  189  283  621\n",
       "  1   994   812  810  995   72  336     798  712  688  614  631  617  849\n",
       "  1   995   994  336  739  724  876     617  901  591   24  712  165  849\n",
       "  1   996   997  914  301  917  336     180  518  181  183  871  189  597\n",
       "  1   997   996  914  300  912  998  …  235  181  183  631  189  597  871\n",
       "  1   998   912  301  997  996  843     631  712  872  729  235  871  597\n",
       "  1   999   538  818  403  829  339     243  242  285  621  189   79  631\n",
       "  1  1000   576  333  966  443  575      89  798  134  849  136  715  803\n",
       " 66     1  1001  224  919   67  537     679  680  715  681  730  699  729"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_states = Any[]\n",
    "next_states = Any[]\n",
    "\n",
    "num_samples = dtst.dataset_size\n",
    "\n",
    "for  (k, (obs, action, next_obs)) in enumerate(dtst)\n",
    "    \n",
    "    if k % 10 == 0\n",
    "        \n",
    "        println(\"Processed \", k ,\" batches\")\n",
    "        \n",
    "    end\n",
    "    #Obs => (50,50,3,100)\n",
    "    #Next obs => (50,50,3,100)\n",
    "    \n",
    "    pred_state = Array{Float32}(model(obs,action))\n",
    "    next_state = Array{Float32}(model(next_obs))\n",
    "    \n",
    "    #Pred-state => (2,5,100)\n",
    "    #Next state => (2,5,100)\n",
    "    #println(pred_state)\n",
    "    #println(next_state)\n",
    "    \n",
    "    push!(pred_states, pred_state)\n",
    "    push!(next_states, next_state)\n",
    "    \n",
    "end\n",
    "\n",
    "#Pred state cat => [2,5,10000]\n",
    "#Next state cat => [2,5,10000]\n",
    "pred_states = cat(pred_states...,dims=3)\n",
    "next_states = cat(next_states...,dims=3)\n",
    "    \n",
    "#Flatten object/feature dimensions\n",
    "pred_states = mat(pred_states)  #[10,10000]\n",
    "next_states = mat(next_states)  #[10,10000]\n",
    "\n",
    "#Calculate pairwise distances\n",
    "sizes_1 = (size(pred_states)...,1)\n",
    "sizes_2 = (sizes_1[1], sizes_1[3], sizes_1[2])\n",
    "\n",
    "pred_states = reshape(pred_states, sizes_1)\n",
    "next_states = reshape(next_states, sizes_2)\n",
    "pred_states = repeat(pred_states, outer=[1,1,1000])\n",
    "next_states = repeat(next_states, outer=[1,1000,1])\n",
    "\n",
    "pairwise_distance_matrix = sum((pred_states - next_states).^2, dims=1)[1,:,:]\n",
    "\n",
    "#Augment pairwise distance matrix\n",
    "diag_elements = diag(pairwise_distance_matrix)\n",
    "pairwise_distance_matrix = hcat(diag_elements, pairwise_distance_matrix)\n",
    "\n",
    "\n",
    "labels = ones(num_samples)\n",
    "hits_at_1 = 0\n",
    "\n",
    "indices = []\n",
    "\n",
    "for i=1:1000\n",
    "    \n",
    "    row = pairwise_distance_matrix[i,:]\n",
    "    ind = sortperm(row)\n",
    "    \n",
    "    push!(indices, ind)\n",
    "\n",
    "end\n",
    "\n",
    "indices = vcat(indices'...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits @ 1: 0.994\n"
     ]
    }
   ],
   "source": [
    "num_matches = sum(labels .== indices[:,1])\n",
    "println(\"Hits @ 1: \", num_matches/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits @ 5: 1.0\n"
     ]
    }
   ],
   "source": [
    "num_matches = sum(labels .== indices[:,1:5])\n",
    "println(\"Hits @ 5: \", num_matches/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR: 0.997\n"
     ]
    }
   ],
   "source": [
    "mxval, mxindx = findmax(indices .== labels,dims=2)\n",
    "ranks = [ i[2] for i in mxindx ]\n",
    "reciprocal_ranks = 1 ./ranks\n",
    "rr_sum = sum(reciprocal_ranks)\n",
    "println(\"MRR: \", rr_sum/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
